{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_4=np.load('data_4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[255., 252., 255., ..., 255., 255., 255.],\n",
       "         [255., 255.,  63., ..., 255., 255., 255.],\n",
       "         [255., 244., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 254., 255., ..., 255., 255., 255.],\n",
       "         [255., 136., 255., ..., 255., 255., 255.],\n",
       "         [255., 198., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 253.,  33., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 254., 255., ..., 255., 255., 255.],\n",
       "         [255., 195., 255., ..., 251., 255., 255.],\n",
       "         [255., 254., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 252., 255., ..., 255., 255., 255.],\n",
       "         [255., 255.,  49., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 249., 255., ..., 255., 255., 255.],\n",
       "         [255., 250., 255., ..., 248., 255., 255.],\n",
       "         [255., 254., 240., ..., 255., 255., 248.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 255., 251., ..., 255., 255., 254.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 253., 249., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 252., 255., 255.],\n",
       "         [248., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 253., 201., ..., 255., 255., 254.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 254., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 246., 255., ..., 255., 255., 248.]],\n",
       "\n",
       "        [[255., 251., 123., ..., 255., 255., 255.],\n",
       "         [255., 253., 255., ..., 255., 255., 252.],\n",
       "         [255., 247., 197., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 247., ..., 252., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 254.],\n",
       "         [255., 202., 255., ..., 255., 255., 255.]]],\n",
       "\n",
       "\n",
       "       [[[255., 253., 255., ..., 255., 255., 255.],\n",
       "         [255., 253.,  38., ..., 255., 255., 255.],\n",
       "         [255., 254., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 131., 255., ..., 255., 255., 255.],\n",
       "         [255., 253., 251., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 252., 255., ..., 255., 255., 255.],\n",
       "         [255., 253.,  57., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 248., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255.,  53., ..., 255., 255., 255.],\n",
       "         [255., 251., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 255.,  48., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 247.],\n",
       "         [255., 255., 146., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 254., 240., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 247.]],\n",
       "\n",
       "        [[255., 255.,  52., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 251.],\n",
       "         [255., 247., 130., ..., 255., 255., 240.],\n",
       "         ...,\n",
       "         [251., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255.,  47., ..., 255., 255., 245.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.],\n",
       "         [255., 255.,  53., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 251.]]],\n",
       "\n",
       "\n",
       "       [[[255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 250.,  48., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 133., 255., ..., 255., 255., 255.],\n",
       "         [255., 255.,  72., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255.,  48., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 242., 169., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 236.],\n",
       "         [255., 252.,  48., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 249.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 255.,  46., ..., 255., 255., 250.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255.,  40., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [243., 254., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 254.]],\n",
       "\n",
       "        [[255., 252.,  50., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 254.],\n",
       "         [255., 255.,  41., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 193., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 253.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255.,  47., ..., 255., 255., 255.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.],\n",
       "         [255., 254.,  44., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [252., 255., 123., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 250.],\n",
       "         [255., 255., 255., ..., 255., 255., 251.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[255., 254., 255., ..., 255., 255., 255.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 134., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 252., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 252., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 246., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 253., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 250., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 208., ..., 255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 252.],\n",
       "         [255., 254., 255., ..., 255., 255., 255.],\n",
       "         [255., 242., 246., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 127., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 252.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 249., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 254.],\n",
       "         [255., 249., 253., ..., 255., 255., 252.],\n",
       "         ...,\n",
       "         [255., 255., 137., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 253., 230., ..., 255., 255., 255.],\n",
       "         [255., 252., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 192., ..., 255., 255., 252.],\n",
       "         ...,\n",
       "         [249., 253., 250., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 247., 255., ..., 255., 255., 255.]]],\n",
       "\n",
       "\n",
       "       [[[255., 252., 255., ..., 255., 255., 255.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 134., 255., ..., 255., 255., 254.],\n",
       "         [255., 255., 125., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 252., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 248., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 252.],\n",
       "         [255., 255.,  51., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 254.],\n",
       "         [255., 255., 249., ..., 255., 255., 255.],\n",
       "         [255., 247., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255.,  33., ..., 255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 255., 253., ..., 255., 255., 255.],\n",
       "         [255., 252., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 254., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [245., 255., 136., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 251.],\n",
       "         [255., 254., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 250., 255., ..., 255., 255., 252.],\n",
       "         [255., 255., 255., ..., 255., 255., 250.],\n",
       "         ...,\n",
       "         [239., 255.,  41., ..., 255., 255., 252.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 253., 255., ..., 255., 255., 250.],\n",
       "         [255., 255., 255., ..., 255., 255., 253.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 253.,  54., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 246.]]],\n",
       "\n",
       "\n",
       "       [[[255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 253., 251., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 168., 255., ..., 255., 255., 255.],\n",
       "         [255., 249.,  51., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 252., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 247., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 250., 199., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255., ..., 255., 255., 252.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 253., 255., ..., 255., 251., 255.],\n",
       "         [255., 254., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 252.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 255., 248., ..., 255., 255., 252.],\n",
       "         [255., 254., 255., ..., 255., 255., 255.],\n",
       "         [255., 255., 255., ..., 255., 255., 252.],\n",
       "         ...,\n",
       "         [255., 249., 255., ..., 255., 255., 250.],\n",
       "         [255., 253., 255., ..., 255., 255., 254.],\n",
       "         [255., 255., 255., ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 254., ..., 255., 255., 253.],\n",
       "         [255., 250., 255., ..., 255., 255., 252.],\n",
       "         [255., 190., 255., ..., 255., 255., 252.],\n",
       "         ...,\n",
       "         [255., 255., 204., ..., 255., 255., 255.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.],\n",
       "         [255., 251., 255., ..., 255., 255., 253.]],\n",
       "\n",
       "        [[255., 253., 255., ..., 255., 255., 254.],\n",
       "         [255., 255., 255., ..., 255., 255., 253.],\n",
       "         [255., 128., 255., ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [245., 255., 181., ..., 255., 255., 255.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.],\n",
       "         [255., 253., 255., ..., 255., 255., 255.]]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 50, 9, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "for i in range (0,9):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(data_4[:,:,i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "for i in range (0,9):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(data_4[:,:,i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from con1 import train_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0705 20:19:00.027164 140132129281856 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/twobyt/con1.py:21: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0705 20:19:00.047680 140132129281856 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/twobyt/con1.py:27: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0705 20:19:00.102933 140132129281856 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/twobyt/convo.py:11: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0705 20:19:00.110770 140132129281856 deprecation.py:506] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/twobyt/convo.py:38: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0705 20:19:00.124468 140132129281856 deprecation.py:323] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/twobyt/con1.py:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0705 20:19:00.149935 140132129281856 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/twobyt/con1.py:50: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0705 20:19:00.294089 140132129281856 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/twobyt/con1.py:59: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0705 20:19:00.296138 140132129281856 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/twobyt/con1.py:69: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 24714.1387, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 19259.7305, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 6731.3179, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 13665.1230, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 19471.5352, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 16990.2363, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 13658.4385, Train Accuracy= 0.000\n",
      "Step 9, Minibatch Loss= 9978.6719, Train Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 7394.3066, Train Accuracy= 0.000\n",
      "Step 11, Minibatch Loss= 4062.7861, Train Accuracy= 0.000\n",
      "Step 12, Minibatch Loss= 2700.0312, Train Accuracy= 0.000\n",
      "Step 13, Minibatch Loss= 4457.9717, Train Accuracy= 0.000\n",
      "Step 14, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_4=np.load('data_4.npy')\n",
    "m=[0,3,5,6,7,8]\n",
    "w1,w2,Num=train_cov(data_4[:,:,m,0],200,3,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 278.8708, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 83.3724, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 76.2207, Train Accuracy= 0.250\n",
      "Step 4, Minibatch Loss= 69.7726, Train Accuracy= 0.250\n",
      "Step 5, Minibatch Loss= 125.8362, Train Accuracy= 0.250\n",
      "Step 6, Minibatch Loss= 56.2700, Train Accuracy= 0.500\n",
      "Step 7, Minibatch Loss= 147.3511, Train Accuracy= 0.125\n",
      "Step 8, Minibatch Loss= 42.7079, Train Accuracy= 0.250\n",
      "Step 9, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 62.9504, Train Accuracy= 0.375\n",
      "Step 11, Minibatch Loss= 52.5046, Train Accuracy= 0.000\n",
      "Step 12, Minibatch Loss= 40.9427, Train Accuracy= 0.000\n",
      "Step 13, Minibatch Loss= 14.7438, Train Accuracy= 0.750\n",
      "Step 14, Minibatch Loss= 18.7372, Train Accuracy= 0.125\n",
      "Step 15, Minibatch Loss= 7.6433, Train Accuracy= 0.125\n",
      "Step 16, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 17, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 18, Minibatch Loss= 0.0000, Train Accuracy= 0.750\n",
      "Step 19, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 21, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 22, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 23, Minibatch Loss= 0.0000, Train Accuracy= 0.750\n",
      "Step 24, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 25, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 26, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 27, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 28, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 29, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 31, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 32, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 33, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 34, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 35, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 36, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 37, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 38, Minibatch Loss= 0.0000, Train Accuracy= 0.750\n",
      "Step 39, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 40, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 41, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 42, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 43, Minibatch Loss= 0.0000, Train Accuracy= 0.750\n",
      "Step 44, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 45, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 46, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 47, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 48, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 49, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 50, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n"
     ]
    }
   ],
   "source": [
    "from fcon_1 import train_fcon\n",
    "wf1,bf1,Num=train_fcon(data_4[:,:,:,0],w1[:,:,:,:],w2[:,:,:,:],50,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gene import forward\n",
    "forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 44553.6875, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 122130.9531, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 2805.9492, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 110436.1406, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 6063.1387, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 12888.5508, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 4100.3018, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 2823.6079, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 2072.0354, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 2708.3762, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 774.9719, Train Accuracy= 0.000\n",
      "Step 9, Minibatch Loss= 128.1932, Train Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 110.8450, Train Accuracy= 0.000\n",
      "Step 11, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 32467.1055, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 11755.0117, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 12972.9941, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 14506.1602, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 1860.8452, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 831.3413, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 43182.1172, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 36361.2305, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 65676.5469, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 1238.2637, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 18368.4941, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 12522.3682, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 53982.8789, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 10349.0801, Train Accuracy= 0.000\n",
      "Step 9, Minibatch Loss= 2119.3584, Train Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 8108.8623, Train Accuracy= 0.000\n",
      "Step 11, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 8334.5527, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 6241.8057, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 22875.7520, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 9225.5625, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 19155.2344, Train Accuracy= 0.000\n",
      "Step 9, Minibatch Loss= 7418.8042, Train Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 6171.9531, Train Accuracy= 0.000\n",
      "Step 11, Minibatch Loss= 13546.0195, Train Accuracy= 0.000\n",
      "Step 12, Minibatch Loss= 10404.0918, Train Accuracy= 0.000\n",
      "Step 13, Minibatch Loss= 5245.0854, Train Accuracy= 0.000\n",
      "Step 14, Minibatch Loss= 4216.9790, Train Accuracy= 0.000\n",
      "Step 15, Minibatch Loss= 585.1472, Train Accuracy= 0.000\n",
      "Step 16, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 138.0009, Train Accuracy= 0.375\n",
      "Step 2, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 3, Minibatch Loss= 47.2166, Train Accuracy= 0.250\n",
      "Step 4, Minibatch Loss= 105.8215, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 25.0828, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 14.1270, Train Accuracy= 0.125\n",
      "Step 7, Minibatch Loss= 5.4260, Train Accuracy= 0.125\n",
      "Step 8, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 9, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 10, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 11, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 12, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 13, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 14, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 15, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 16, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 17, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 18, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 19, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 21, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 22, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 23, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 24, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 25, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 26, Minibatch Loss= 0.0000, Train Accuracy= 0.000\n",
      "Step 27, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 28, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 29, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 31, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 32, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 33, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 34, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 35, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 36, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 37, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 38, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 39, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 40, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 41, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 42, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 43, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 44, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 45, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 46, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 47, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 48, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 49, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 50, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 2.6983, Train Accuracy= 0.875\n",
      "Step 2, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 10.7515, Train Accuracy= 0.875\n",
      "Step 2, Minibatch Loss= 24.4711, Train Accuracy= 0.500\n",
      "Step 3, Minibatch Loss= 2.4549, Train Accuracy= 0.625\n",
      "Step 4, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 155.0809, Train Accuracy= 0.250\n",
      "Step 2, Minibatch Loss= 77.0910, Train Accuracy= 0.375\n",
      "Step 3, Minibatch Loss= 75.2144, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 35.5325, Train Accuracy= 0.250\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 6, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 7, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 8, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 9, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 11, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 12, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 13, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 14, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 15, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 16, Minibatch Loss= 0.0000, Train Accuracy= 0.000\n",
      "Step 17, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 18, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 19, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 21, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 22, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 23, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 24, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 25, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 26, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 27, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 28, Minibatch Loss= 0.0000, Train Accuracy= 0.000\n",
      "Step 29, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 31, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 32, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 33, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 34, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 35, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 36, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 37, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 38, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 39, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 40, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 41, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 42, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 43, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 44, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 45, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 46, Minibatch Loss= 0.0000, Train Accuracy= 0.750\n",
      "Step 47, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 48, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 49, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 50, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 1, Minibatch Loss= 322.3988, Train Accuracy= 0.125\n",
      "Step 2, Minibatch Loss= 465.0717, Train Accuracy= 0.375\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 145.5317, Train Accuracy= 0.250\n",
      "Step 5, Minibatch Loss= 416.5755, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 132.6528, Train Accuracy= 0.125\n",
      "Step 7, Minibatch Loss= 126.9194, Train Accuracy= 0.125\n",
      "Step 8, Minibatch Loss= 121.3031, Train Accuracy= 0.125\n",
      "Step 9, Minibatch Loss= 115.2722, Train Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 11, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 12, Minibatch Loss= 99.7180, Train Accuracy= 0.375\n",
      "Step 13, Minibatch Loss= 372.1288, Train Accuracy= 0.125\n",
      "Step 14, Minibatch Loss= 86.2234, Train Accuracy= 0.375\n",
      "Step 15, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 16, Minibatch Loss= 73.7821, Train Accuracy= 0.375\n",
      "Step 17, Minibatch Loss= 133.6947, Train Accuracy= 0.125\n",
      "Step 18, Minibatch Loss= 59.8198, Train Accuracy= 0.375\n",
      "Step 19, Minibatch Loss= 52.7194, Train Accuracy= 0.375\n",
      "Step 20, Minibatch Loss= 45.9763, Train Accuracy= 0.125\n",
      "Step 21, Minibatch Loss= 40.7016, Train Accuracy= 0.500\n",
      "Step 22, Minibatch Loss= 106.8718, Train Accuracy= 0.000\n",
      "Step 23, Minibatch Loss= 60.1886, Train Accuracy= 0.125\n",
      "Step 24, Minibatch Loss= 0.0000, Train Accuracy= 0.000\n",
      "Step 25, Minibatch Loss= 19.7327, Train Accuracy= 0.375\n",
      "Step 26, Minibatch Loss= 28.0122, Train Accuracy= 0.250\n",
      "Step 27, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 28, Minibatch Loss= 10.1153, Train Accuracy= 0.125\n",
      "Step 29, Minibatch Loss= 0.0000, Train Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 31, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 32, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 33, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 34, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 35, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 36, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 37, Minibatch Loss= 0.0000, Train Accuracy= 0.125\n",
      "Step 38, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 39, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 40, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 41, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 42, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "Step 43, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 44, Minibatch Loss= 0.0000, Train Accuracy= 0.000\n",
      "Step 45, Minibatch Loss= 0.0000, Train Accuracy= 0.250\n",
      "Step 46, Minibatch Loss= 0.0000, Train Accuracy= 0.625\n",
      "Step 47, Minibatch Loss= 0.0000, Train Accuracy= 0.750\n",
      "Step 48, Minibatch Loss= 0.0000, Train Accuracy= 0.375\n",
      "Step 49, Minibatch Loss= 0.0000, Train Accuracy= 0.750\n",
      "Step 50, Minibatch Loss= 0.0000, Train Accuracy= 0.500\n",
      "x direction error: [1 5 3 4 2 0]\n",
      "y direction error: [1 5 3 4 2 0]\n",
      "normalized correct x direction error: 0.3247514801167407\n",
      "normalized correct y direction error: 0.3247514801167407\n",
      "sum error: [1 5 3 4 2 0]\n",
      "normalized correct sum error: 0.3247514801167407\n",
      "number of correct trials, x: [1. 1. 1. 1. 1.]\n",
      "number of correct trials, y: [1. 1. 1. 1. 1.]\n",
      "2\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/0_cweight1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c81083b9a3e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrun_foward_error\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfoward_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfoward_error\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'0_c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/experiment/twobyt/run_foward_error.py\u001b[0m in \u001b[0;36mfoward_error\u001b[0;34m(n, m, ans, N_str)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number of correct trials, y:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'weight1.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'weight2.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'weightf.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/0_cweight1.npy'"
     ]
    }
   ],
   "source": [
    "from run_foward_error import foward_error\n",
    "foward_error (0,m,1,'0_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x direction error: 3\n"
     ]
    }
   ],
   "source": [
    "a=3\n",
    "print('x direction error:',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wf1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8fa975e0c482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'weight1.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'weight2.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'weightf.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'biasf.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Error.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wf1' is not defined"
     ]
    }
   ],
   "source": [
    "N_str='0_c'\n",
    "np.save('Data/'+str(N_str)+'weight1.npy',w1)\n",
    "np.save('Data/'+str(N_str)+'weight2.npy',w2)\n",
    "np.save('Data/'+str(N_str)+'weightf.npy',wf1)\n",
    "np.save('Data/'+str(N_str)+'biasf.npy',bf1)\n",
    "np.save('Data/'+str(N_str)+'Error.npy',EE)\n",
    "np.save('Data/'+str(N_str)+'Termination.npy',T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 3, 4, 2, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "EE=np.load('Data/1_cError.npy')\n",
    "np.argsort(np.average(EE,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 3, 4, 2, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "EE=np.load('Data/2_cError.npy')\n",
    "np.argsort(np.average(EE,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[-0.47310576, -1.10834885, -0.90142429,  0.10573062,\n",
       "           -0.05252514],\n",
       "          [-1.10531116,  0.08917154,  2.4814949 ,  1.78245068,\n",
       "           -0.56798851],\n",
       "          [ 0.66577554, -0.24126068, -1.42300546,  0.36424646,\n",
       "           -1.85631907]]],\n",
       "\n",
       "\n",
       "        [[[ 0.55085218,  0.47894692,  2.15617681,  0.23521908,\n",
       "            0.70390201],\n",
       "          [ 1.22417593,  0.59697717, -0.5828526 , -1.3243202 ,\n",
       "           -0.13128047],\n",
       "          [-0.44941738, -0.8264181 , -0.3616347 ,  0.37306723,\n",
       "           -0.26365864]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0940541 ,  0.8204335 , -0.32895616, -0.7256754 ,\n",
       "            0.50159585],\n",
       "          [-0.48749402,  0.10983108, -0.42670035,  0.78436816,\n",
       "           -0.09015916],\n",
       "          [-0.50944036,  0.01245948, -0.67557162,  0.5865587 ,\n",
       "            1.12974179]]],\n",
       "\n",
       "\n",
       "        [[[-0.96784395, -0.12803623,  1.85465455, -0.34772009,\n",
       "           -1.19683886],\n",
       "          [-1.12093842, -2.19543147, -0.68958992, -1.99703693,\n",
       "           -0.86747104],\n",
       "          [-0.20889479, -1.6937412 , -1.41665626, -1.32080138,\n",
       "            0.95090282]]],\n",
       "\n",
       "\n",
       "        [[[ 0.13254288,  0.37863648,  1.07998312,  1.30737352,\n",
       "           -0.23124233],\n",
       "          [-0.81045938,  0.35270447,  0.87527132,  1.09829509,\n",
       "           -0.05666158],\n",
       "          [-0.25222719, -0.23819092, -0.35232127,  1.55057085,\n",
       "           -0.46928588]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 0.4895606 , -0.81484652, -0.41100517,  0.04485618,\n",
       "           -0.64577013],\n",
       "          [ 0.08757969, -0.54143578,  0.0244437 ,  0.5109365 ,\n",
       "           -0.27079079],\n",
       "          [ 0.06724817, -0.32602295,  0.33426866,  0.43426633,\n",
       "            1.06731009]]],\n",
       "\n",
       "\n",
       "        [[[ 2.03917241,  0.16417944,  1.23030424,  0.13163468,\n",
       "           -1.80727315],\n",
       "          [-0.15286644, -0.151567  ,  0.31748953, -1.55499816,\n",
       "            0.2652055 ],\n",
       "          [ 0.47877926,  0.21893519,  1.64642179,  0.35964221,\n",
       "           -0.27395913]]],\n",
       "\n",
       "\n",
       "        [[[-2.1917007 ,  0.30498046, -1.50853944,  1.6753124 ,\n",
       "           -1.21430135],\n",
       "          [-0.30951333,  0.28319389,  0.61903423,  2.44050264,\n",
       "           -0.12146226],\n",
       "          [ 0.13020261, -0.49731034, -0.77518338,  2.46031857,\n",
       "            0.31853792]]],\n",
       "\n",
       "\n",
       "        [[[ 0.7245422 , -0.785353  ,  0.53754765, -0.11742112,\n",
       "            0.52668601],\n",
       "          [-0.30945614, -0.18016531, -1.96415877,  1.15656567,\n",
       "           -0.31750497],\n",
       "          [-0.87737501, -0.90919894,  1.23401439,  0.78423798,\n",
       "           -0.77629358]]],\n",
       "\n",
       "\n",
       "        [[[-0.33731824,  1.09835589,  0.36148766,  0.29989907,\n",
       "            1.67824757],\n",
       "          [ 1.9369216 ,  0.69886261, -2.04108882,  0.63472396,\n",
       "            2.07317734],\n",
       "          [ 0.08673154,  0.48449457, -0.60479993,  0.81994438,\n",
       "            1.55807102]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[-0.96622217,  1.24438953,  1.56291664, -0.90816188,\n",
       "            0.51480865],\n",
       "          [-1.096241  , -0.63337034,  1.49222946, -0.39599648,\n",
       "           -0.34120038],\n",
       "          [-0.41165486,  0.7668463 ,  1.1949445 ,  0.15875831,\n",
       "           -0.2229566 ]]],\n",
       "\n",
       "\n",
       "        [[[ 1.43543828,  0.58971179,  1.52136588,  1.60325837,\n",
       "            1.27822804],\n",
       "          [ 2.49114799, -0.66275078, -0.71672368,  0.56928593,\n",
       "            0.2060618 ],\n",
       "          [ 0.8588596 ,  0.45938939,  1.00790453,  1.73233533,\n",
       "           -0.56853306]]],\n",
       "\n",
       "\n",
       "        [[[-1.1825428 , -1.61081266, -0.03287632,  0.99672133,\n",
       "           -1.45381558],\n",
       "          [-1.0076952 , -1.48910284, -1.27854288,  0.34855515,\n",
       "            1.86108208],\n",
       "          [ 1.58914602, -2.12773061, -1.05995762,  0.08250643,\n",
       "           -0.53710461]]],\n",
       "\n",
       "\n",
       "        [[[ 0.47301847, -1.01666558,  0.43969771, -0.46581104,\n",
       "           -0.12638351],\n",
       "          [ 1.33726192, -1.20040524, -0.55008757,  0.03742394,\n",
       "           -0.71888661],\n",
       "          [ 0.69326311,  1.00903952,  0.78912044, -0.24602437,\n",
       "           -0.50239575]]],\n",
       "\n",
       "\n",
       "        [[[ 1.37770069, -0.21438032, -1.34039843,  1.22188604,\n",
       "            0.14883709],\n",
       "          [-0.64258111,  0.86523849,  1.58793128,  1.73352933,\n",
       "           -0.74516326],\n",
       "          [ 0.06586103, -0.07487085, -0.49615341, -0.35618487,\n",
       "            2.20739317]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 0.96297014,  0.20685449, -1.82909775,  1.15158451,\n",
       "           -0.39701837],\n",
       "          [-0.66542816,  0.08205435,  1.42116439, -1.1423049 ,\n",
       "            0.78936219],\n",
       "          [-0.90717995, -0.39117515,  0.81004816,  1.14131117,\n",
       "           -0.97152948]]],\n",
       "\n",
       "\n",
       "        [[[ 2.10697317, -2.07094598, -1.26330316, -0.6496172 ,\n",
       "           -0.79354173],\n",
       "          [ 1.13041866,  2.02265668,  0.65185624, -0.57369179,\n",
       "            0.45131803],\n",
       "          [ 0.74712211, -0.23367189,  0.20765321,  1.34723103,\n",
       "            0.14940551]]],\n",
       "\n",
       "\n",
       "        [[[ 1.87198782, -0.10162198,  0.89449531, -1.24166811,\n",
       "           -1.04068661],\n",
       "          [ 0.41529277,  0.90445024, -2.16834974, -0.60954231,\n",
       "           -0.54104108],\n",
       "          [ 0.88214946,  0.83503377,  1.43315041, -0.50850755,\n",
       "            0.62662154]]],\n",
       "\n",
       "\n",
       "        [[[-2.53436255, -0.63987672, -0.65842825, -0.02363535,\n",
       "            0.31669652],\n",
       "          [-0.21717268,  2.07270575, -0.13194723, -0.5020377 ,\n",
       "            1.87616098],\n",
       "          [ 0.17189753,  2.05424714, -0.28819385,  0.42288291,\n",
       "           -1.68750501]]],\n",
       "\n",
       "\n",
       "        [[[-0.70572042, -1.56514263, -0.1758206 ,  1.14282179,\n",
       "            2.38509274],\n",
       "          [ 0.30715209, -1.25878322, -0.30927911,  0.98980093,\n",
       "           -0.3185364 ],\n",
       "          [ 0.15951882,  0.11059295, -0.2630263 ,  0.99502653,\n",
       "            0.31051841]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 1.46636701, -0.22052352, -0.45312214,  0.14066821,\n",
       "           -0.40444434],\n",
       "          [-0.74220449,  0.30517685,  0.05834654, -1.57010806,\n",
       "           -0.88395154],\n",
       "          [ 0.95066869, -0.89059258, -0.86317056, -1.03000963,\n",
       "            0.48079717]]],\n",
       "\n",
       "\n",
       "        [[[-0.34230646,  0.37565309, -2.00473642, -0.4125796 ,\n",
       "           -0.78299099],\n",
       "          [-0.18310036,  0.65015429, -0.435184  , -0.65414989,\n",
       "            1.71884573],\n",
       "          [ 2.38234282,  1.14210618,  0.58334994,  0.49358028,\n",
       "           -0.85324049]]],\n",
       "\n",
       "\n",
       "        [[[-0.7814573 , -0.02148423,  0.16408139,  0.69156271,\n",
       "           -0.28871933],\n",
       "          [-0.26453793, -0.50973582,  1.10081601,  0.35154894,\n",
       "            0.98846626],\n",
       "          [ 1.54909909, -3.17886782, -1.54111242, -0.06238528,\n",
       "            0.55048913]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0519329 ,  0.99542183, -1.3425914 , -1.19680119,\n",
       "            0.14821707],\n",
       "          [-0.99698257,  1.70327067,  0.68655396, -0.38518241,\n",
       "            0.02907671],\n",
       "          [ 1.37992311, -1.11555648,  0.03437119,  0.08286031,\n",
       "            0.2199835 ]]],\n",
       "\n",
       "\n",
       "        [[[ 0.28828818,  1.60147965, -0.29194927,  1.1043129 ,\n",
       "           -0.57151508],\n",
       "          [ 0.0308584 , -0.94897091,  0.56180763, -0.64149308,\n",
       "            1.73309004],\n",
       "          [ 0.83619511, -0.64383239, -0.27878386,  0.73428613,\n",
       "            0.37407762]]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load('Data/1_cweight1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,7):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

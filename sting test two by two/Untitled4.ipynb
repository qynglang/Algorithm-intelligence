{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 3., 3., 3., 3., 4., 5., 5., 5., 5., 5., 6., 7., 7., 7.,\n",
       "        7., 7., 8.]), array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smg import generator6\n",
    "generator6([20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.80000000e+01, 2.80000000e+01, 2.80000000e+01, ...,\n",
       "         2.80000000e+01, 2.80000000e+01, 2.80000000e+01],\n",
       "        [2.10000000e+01, 2.20000000e+01, 2.10000000e+01, ...,\n",
       "         2.20000000e+01, 2.10000000e+01, 2.20000000e+01],\n",
       "        [2.70000000e+01, 2.80000000e+01, 2.90000000e+01, ...,\n",
       "         2.04000000e+02, 2.05000000e+02, 2.06000000e+02],\n",
       "        ...,\n",
       "        [2.90000000e+01, 3.00000000e+01, 3.10000000e+01, ...,\n",
       "         5.00000000e+01, 4.80000000e+01, 4.90000000e+01],\n",
       "        [2.80000000e+01, 2.80000000e+01, 2.90000000e+01, ...,\n",
       "         7.08459392e+36, 1.14631138e+37, 1.85477077e+37],\n",
       "        [2.00000000e+01, 2.20000000e+01, 2.40000000e+01, ...,\n",
       "         3.74000000e+02, 3.76000000e+02, 3.78000000e+02]]),\n",
       " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smg import load_test\n",
    "load_test([180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 16:32:08.318917 140312703637312 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0807 16:32:08.336493 140312703637312 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:44: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0807 16:32:08.391148 140312703637312 deprecation.py:506] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:14: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0807 16:32:08.428787 140312703637312 deprecation.py:323] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:66: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0807 16:32:08.451290 140312703637312 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:67: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0807 16:32:08.669237 140312703637312 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:76: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0807 16:32:08.672037 140312703637312 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:77: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0807 16:32:08.700479 140312703637312 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:80: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 139745.4375, Train Accuracy= 0.516\n",
      "Step 100, Minibatch Loss= 2204.8042, Train Accuracy= 0.859\n",
      "Step 200, Minibatch Loss= 65.2987, Train Accuracy= 0.930\n",
      "Step 300, Minibatch Loss= 417.9880, Train Accuracy= 0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0807 16:32:16.258001 140312703637312 deprecation.py:323] From /afs/inf.ed.ac.uk/user/s18/s1883226/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.69999999, 0.5       ])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fcon_2 import train_fcon\n",
    "train_fcon(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 17391.2227, Train Accuracy= 0.438\n",
      "Step 100, Minibatch Loss= 64895.4805, Train Accuracy= 0.430\n",
      "Step 200, Minibatch Loss= 46497.0469, Train Accuracy= 0.469\n",
      "Step 300, Minibatch Loss= 2193.6074, Train Accuracy= 0.570\n",
      "Step 400, Minibatch Loss= 23.8099, Train Accuracy= 0.945\n",
      "Step 500, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 85811.4688, Train Accuracy= 0.492\n",
      "Step 100, Minibatch Loss= 29758.4922, Train Accuracy= 0.461\n",
      "Step 200, Minibatch Loss= 8819.3223, Train Accuracy= 0.555\n",
      "Step 300, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 103432.2344, Train Accuracy= 0.539\n",
      "Step 100, Minibatch Loss= 29978.4062, Train Accuracy= 0.664\n",
      "Step 200, Minibatch Loss= 11136.6406, Train Accuracy= 0.758\n",
      "Step 300, Minibatch Loss= 12536.4258, Train Accuracy= 0.648\n",
      "Step 400, Minibatch Loss= 5424.1973, Train Accuracy= 0.703\n",
      "Step 500, Minibatch Loss= 3119.7959, Train Accuracy= 0.703\n",
      "Step 600, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 395075.6562, Train Accuracy= 0.523\n",
      "Step 100, Minibatch Loss= 37341.7930, Train Accuracy= 0.516\n",
      "Step 200, Minibatch Loss= 1.0424, Train Accuracy= 0.984\n",
      "Step 300, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 150627.9688, Train Accuracy= 0.547\n",
      "Step 100, Minibatch Loss= 61952.8281, Train Accuracy= 0.570\n",
      "Step 200, Minibatch Loss= 10644.5322, Train Accuracy= 0.742\n",
      "Step 300, Minibatch Loss= 16476.8887, Train Accuracy= 0.625\n",
      "Step 400, Minibatch Loss= 5318.0479, Train Accuracy= 0.742\n",
      "Step 500, Minibatch Loss= 1826.0808, Train Accuracy= 0.766\n",
      "Step 600, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 156587.0000, Train Accuracy= 0.492\n",
      "Step 100, Minibatch Loss= 47771.0273, Train Accuracy= 0.492\n",
      "Step 200, Minibatch Loss= 864.6171, Train Accuracy= 0.562\n",
      "Step 300, Minibatch Loss= 9033.1211, Train Accuracy= 0.484\n",
      "Step 400, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 217164.7188, Train Accuracy= 0.500\n",
      "Step 100, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 356914.1250, Train Accuracy= 0.484\n",
      "Step 100, Minibatch Loss= 25474.3086, Train Accuracy= 0.750\n",
      "Step 200, Minibatch Loss= 11984.3428, Train Accuracy= 0.742\n",
      "Step 300, Minibatch Loss= 181.2446, Train Accuracy= 0.977\n",
      "Step 400, Minibatch Loss= 416.5095, Train Accuracy= 0.953\n",
      "Step 500, Minibatch Loss= 1573.7292, Train Accuracy= 0.852\n",
      "Step 600, Minibatch Loss= 500.2414, Train Accuracy= 0.945\n",
      "Step 700, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 358232.0938, Train Accuracy= 0.492\n",
      "Step 100, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 126229.9531, Train Accuracy= 0.492\n",
      "Step 100, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n"
     ]
    }
   ],
   "source": [
    "from fcon_2 import train_fcon\n",
    "import numpy as np\n",
    "#ac=np.zeros((50,2))\n",
    "# acc=np.zeros((50,5))\n",
    "# accc=np.zeros((50,8))\n",
    "# acccc=np.zeros((50,10))\n",
    "for i in range (10,20):\n",
    "    ac[i,:]=train_fcon(2)\n",
    "    if i%5==0:\n",
    "        np.save('Data/ac.npy',ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.89999998, 0.89999998],\n",
       "       [0.89999998, 0.89999998],\n",
       "       [0.5       , 0.40000001],\n",
       "       [0.40000001, 0.30000001],\n",
       "       [0.5       , 0.40000001],\n",
       "       [0.89999998, 0.89999998],\n",
       "       [0.80000001, 0.80000001],\n",
       "       [1.        , 1.        ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.40000001, 0.40000001],\n",
       "       [0.30000001, 0.30000001],\n",
       "       [0.5       , 0.60000002],\n",
       "       [0.60000002, 0.60000002],\n",
       "       [0.69999999, 0.60000002],\n",
       "       [0.5       , 0.5       ],\n",
       "       [1.        , 1.        ],\n",
       "       [0.80000001, 0.80000001],\n",
       "       [0.89999998, 0.89999998],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.655, 0.64 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(ac[0:20,:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 18:03:44.416276 140052054890304 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0807 18:03:44.434033 140052054890304 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:44: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0807 18:03:44.474068 140052054890304 deprecation.py:506] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:14: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0807 18:03:44.508157 140052054890304 deprecation.py:323] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:66: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0807 18:03:44.528518 140052054890304 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:67: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0807 18:03:44.713049 140052054890304 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:76: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0807 18:03:44.714520 140052054890304 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:77: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0807 18:03:44.744237 140052054890304 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/test/twobyt/fcon_2.py:80: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 5709615.5000, Train Accuracy= 0.133\n",
      "Step 100, Minibatch Loss= 172301.5625, Train Accuracy= 0.430\n",
      "Step 200, Minibatch Loss= 116536.9062, Train Accuracy= 0.578\n",
      "Step 300, Minibatch Loss= 87450.1016, Train Accuracy= 0.609\n",
      "Step 400, Minibatch Loss= 26140.7148, Train Accuracy= 0.742\n",
      "Step 500, Minibatch Loss= 11432.9648, Train Accuracy= 0.703\n",
      "Step 600, Minibatch Loss= 15998.0742, Train Accuracy= 0.766\n",
      "Step 700, Minibatch Loss= 10497.8027, Train Accuracy= 0.727\n",
      "Step 800, Minibatch Loss= 10927.3848, Train Accuracy= 0.695\n",
      "Step 900, Minibatch Loss= 6129.2437, Train Accuracy= 0.766\n",
      "Step 1000, Minibatch Loss= 4979.1992, Train Accuracy= 0.766\n",
      "Step 1100, Minibatch Loss= 12323.9199, Train Accuracy= 0.711\n",
      "Step 1200, Minibatch Loss= 4753.2622, Train Accuracy= 0.781\n",
      "Step 1300, Minibatch Loss= 7208.1787, Train Accuracy= 0.789\n",
      "Step 1400, Minibatch Loss= 3749.4124, Train Accuracy= 0.820\n",
      "Step 1500, Minibatch Loss= 4719.3687, Train Accuracy= 0.812\n",
      "Step 1600, Minibatch Loss= 1791.5833, Train Accuracy= 0.875\n",
      "Step 1700, Minibatch Loss= 1839.1770, Train Accuracy= 0.844\n",
      "Step 1800, Minibatch Loss= 2397.4419, Train Accuracy= 0.773\n",
      "Step 1900, Minibatch Loss= 4347.9097, Train Accuracy= 0.789\n",
      "Step 2000, Minibatch Loss= 1013.5112, Train Accuracy= 0.875\n",
      "Step 2100, Minibatch Loss= 1531.5828, Train Accuracy= 0.844\n",
      "Step 2200, Minibatch Loss= 1448.9196, Train Accuracy= 0.820\n",
      "Step 2300, Minibatch Loss= 1361.8993, Train Accuracy= 0.836\n",
      "Step 2400, Minibatch Loss= 752.1945, Train Accuracy= 0.836\n",
      "Step 2500, Minibatch Loss= 625.2101, Train Accuracy= 0.875\n",
      "Step 2600, Minibatch Loss= 291.2778, Train Accuracy= 0.914\n",
      "Step 2700, Minibatch Loss= 356.1403, Train Accuracy= 0.875\n",
      "Step 2800, Minibatch Loss= 369.4418, Train Accuracy= 0.852\n",
      "Step 2900, Minibatch Loss= 134.2977, Train Accuracy= 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0807 18:05:05.031961 140052054890304 deprecation.py:323] From /afs/inf.ed.ac.uk/user/s18/s1883226/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3000, Minibatch Loss= 260.5303, Train Accuracy= 0.883\n",
      "Step 1, Minibatch Loss= 1048671.7500, Train Accuracy= 0.203\n",
      "Step 100, Minibatch Loss= 143984.9531, Train Accuracy= 0.523\n",
      "Step 200, Minibatch Loss= 85431.4453, Train Accuracy= 0.617\n",
      "Step 300, Minibatch Loss= 75493.5625, Train Accuracy= 0.570\n",
      "Step 400, Minibatch Loss= 59589.2383, Train Accuracy= 0.602\n",
      "Step 500, Minibatch Loss= 23874.1211, Train Accuracy= 0.742\n",
      "Step 600, Minibatch Loss= 19564.6250, Train Accuracy= 0.766\n",
      "Step 700, Minibatch Loss= 27168.3848, Train Accuracy= 0.609\n",
      "Step 800, Minibatch Loss= 16779.2031, Train Accuracy= 0.766\n",
      "Step 900, Minibatch Loss= 13102.6494, Train Accuracy= 0.695\n",
      "Step 1000, Minibatch Loss= 9289.6738, Train Accuracy= 0.641\n",
      "Step 1100, Minibatch Loss= 8344.8135, Train Accuracy= 0.594\n",
      "Step 1200, Minibatch Loss= 6806.7129, Train Accuracy= 0.594\n",
      "Step 1300, Minibatch Loss= 3103.2297, Train Accuracy= 0.703\n",
      "Step 1400, Minibatch Loss= 3716.3972, Train Accuracy= 0.773\n",
      "Step 1500, Minibatch Loss= 3892.8472, Train Accuracy= 0.531\n",
      "Step 1600, Minibatch Loss= 3131.0110, Train Accuracy= 0.750\n",
      "Step 1700, Minibatch Loss= 1807.9397, Train Accuracy= 0.672\n",
      "Step 1800, Minibatch Loss= 1407.3398, Train Accuracy= 0.711\n",
      "Step 1900, Minibatch Loss= 753.9987, Train Accuracy= 0.820\n",
      "Step 2000, Minibatch Loss= 552.9405, Train Accuracy= 0.781\n",
      "Step 2100, Minibatch Loss= 219.1575, Train Accuracy= 0.875\n",
      "Step 2200, Minibatch Loss= 395.7842, Train Accuracy= 0.781\n",
      "Step 2300, Minibatch Loss= 245.2537, Train Accuracy= 0.859\n",
      "Step 2400, Minibatch Loss= 154.8506, Train Accuracy= 0.812\n",
      "Step 2500, Minibatch Loss= 111.1638, Train Accuracy= 0.820\n",
      "Step 2600, Minibatch Loss= 64.6628, Train Accuracy= 0.891\n",
      "Step 2700, Minibatch Loss= 50.0650, Train Accuracy= 0.867\n",
      "Step 2800, Minibatch Loss= 25.3742, Train Accuracy= 0.914\n",
      "Step 2900, Minibatch Loss= 98.9339, Train Accuracy= 0.820\n",
      "Step 3000, Minibatch Loss= 13.1363, Train Accuracy= 0.906\n",
      "Step 1, Minibatch Loss= 2346453.5000, Train Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 160465.3906, Train Accuracy= 0.555\n",
      "Step 200, Minibatch Loss= 149413.3438, Train Accuracy= 0.445\n",
      "Step 300, Minibatch Loss= 32579.6523, Train Accuracy= 0.555\n",
      "Step 400, Minibatch Loss= 34982.6445, Train Accuracy= 0.578\n",
      "Step 500, Minibatch Loss= 27275.0781, Train Accuracy= 0.547\n",
      "Step 600, Minibatch Loss= 20682.8086, Train Accuracy= 0.625\n",
      "Step 700, Minibatch Loss= 19715.1113, Train Accuracy= 0.617\n",
      "Step 800, Minibatch Loss= 22304.5234, Train Accuracy= 0.703\n",
      "Step 900, Minibatch Loss= 11403.0117, Train Accuracy= 0.766\n",
      "Step 1000, Minibatch Loss= 4883.7852, Train Accuracy= 0.680\n",
      "Step 1100, Minibatch Loss= 4245.7041, Train Accuracy= 0.805\n",
      "Step 1200, Minibatch Loss= 4276.5811, Train Accuracy= 0.820\n",
      "Step 1300, Minibatch Loss= 6763.4961, Train Accuracy= 0.711\n",
      "Step 1400, Minibatch Loss= 4906.9375, Train Accuracy= 0.727\n",
      "Step 1500, Minibatch Loss= 3319.8962, Train Accuracy= 0.805\n",
      "Step 1600, Minibatch Loss= 3958.4844, Train Accuracy= 0.688\n",
      "Step 1700, Minibatch Loss= 2076.6421, Train Accuracy= 0.648\n",
      "Step 1800, Minibatch Loss= 1019.8367, Train Accuracy= 0.758\n",
      "Step 1900, Minibatch Loss= 1388.0504, Train Accuracy= 0.656\n",
      "Step 2000, Minibatch Loss= 655.4863, Train Accuracy= 0.750\n",
      "Step 2100, Minibatch Loss= 593.3008, Train Accuracy= 0.758\n",
      "Step 2200, Minibatch Loss= 264.9048, Train Accuracy= 0.844\n",
      "Step 2300, Minibatch Loss= 600.0979, Train Accuracy= 0.773\n",
      "Step 2400, Minibatch Loss= 486.9156, Train Accuracy= 0.836\n",
      "Step 2500, Minibatch Loss= 224.9635, Train Accuracy= 0.852\n",
      "Step 2600, Minibatch Loss= 116.7054, Train Accuracy= 0.844\n",
      "Step 2700, Minibatch Loss= 82.5321, Train Accuracy= 0.828\n",
      "Step 2800, Minibatch Loss= 152.3332, Train Accuracy= 0.844\n",
      "Step 2900, Minibatch Loss= 149.4890, Train Accuracy= 0.781\n",
      "Step 3000, Minibatch Loss= 68.6709, Train Accuracy= 0.805\n",
      "Step 1, Minibatch Loss= 2707437.2500, Train Accuracy= 0.141\n",
      "Step 100, Minibatch Loss= 206076.1094, Train Accuracy= 0.430\n",
      "Step 200, Minibatch Loss= 100084.2344, Train Accuracy= 0.500\n",
      "Step 300, Minibatch Loss= 89705.5312, Train Accuracy= 0.531\n",
      "Step 400, Minibatch Loss= 27833.8301, Train Accuracy= 0.703\n",
      "Step 500, Minibatch Loss= 10504.0859, Train Accuracy= 0.680\n",
      "Step 600, Minibatch Loss= 27135.2812, Train Accuracy= 0.727\n",
      "Step 700, Minibatch Loss= 23434.7207, Train Accuracy= 0.586\n",
      "Step 800, Minibatch Loss= 19986.2480, Train Accuracy= 0.750\n",
      "Step 900, Minibatch Loss= 7308.6777, Train Accuracy= 0.688\n",
      "Step 1000, Minibatch Loss= 3841.8184, Train Accuracy= 0.828\n",
      "Step 1100, Minibatch Loss= 5637.1455, Train Accuracy= 0.797\n",
      "Step 1200, Minibatch Loss= 7823.1523, Train Accuracy= 0.648\n",
      "Step 1300, Minibatch Loss= 3282.8689, Train Accuracy= 0.820\n",
      "Step 1400, Minibatch Loss= 2558.0745, Train Accuracy= 0.828\n",
      "Step 1500, Minibatch Loss= 2646.3303, Train Accuracy= 0.820\n",
      "Step 1600, Minibatch Loss= 2311.1628, Train Accuracy= 0.805\n",
      "Step 1700, Minibatch Loss= 1208.5869, Train Accuracy= 0.883\n",
      "Step 1800, Minibatch Loss= 1010.7528, Train Accuracy= 0.875\n",
      "Step 1900, Minibatch Loss= 900.1688, Train Accuracy= 0.836\n",
      "Step 2000, Minibatch Loss= 834.4230, Train Accuracy= 0.867\n",
      "Step 2100, Minibatch Loss= 460.0629, Train Accuracy= 0.844\n",
      "Step 2200, Minibatch Loss= 353.6534, Train Accuracy= 0.883\n",
      "Step 2300, Minibatch Loss= 456.6441, Train Accuracy= 0.875\n",
      "Step 2400, Minibatch Loss= 158.6834, Train Accuracy= 0.898\n",
      "Step 2500, Minibatch Loss= 266.5383, Train Accuracy= 0.898\n",
      "Step 2600, Minibatch Loss= 84.9997, Train Accuracy= 0.953\n",
      "Step 2700, Minibatch Loss= 161.9955, Train Accuracy= 0.922\n",
      "Step 2800, Minibatch Loss= 72.5054, Train Accuracy= 0.781\n",
      "Step 2900, Minibatch Loss= 10.1857, Train Accuracy= 0.781\n",
      "Step 3000, Minibatch Loss= 4.8594, Train Accuracy= 0.797\n",
      "Step 1, Minibatch Loss= 4453050.5000, Train Accuracy= 0.109\n",
      "Step 100, Minibatch Loss= 227474.6562, Train Accuracy= 0.453\n",
      "Step 200, Minibatch Loss= 137105.0000, Train Accuracy= 0.484\n",
      "Step 300, Minibatch Loss= 92597.8594, Train Accuracy= 0.570\n",
      "Step 400, Minibatch Loss= 36973.1641, Train Accuracy= 0.625\n",
      "Step 500, Minibatch Loss= 34982.5195, Train Accuracy= 0.586\n",
      "Step 600, Minibatch Loss= 33303.4219, Train Accuracy= 0.602\n",
      "Step 700, Minibatch Loss= 21659.6895, Train Accuracy= 0.695\n",
      "Step 800, Minibatch Loss= 20772.5664, Train Accuracy= 0.578\n",
      "Step 900, Minibatch Loss= 17540.8164, Train Accuracy= 0.602\n",
      "Step 1000, Minibatch Loss= 11615.0957, Train Accuracy= 0.742\n",
      "Step 1100, Minibatch Loss= 6723.1118, Train Accuracy= 0.719\n",
      "Step 1200, Minibatch Loss= 4272.3091, Train Accuracy= 0.664\n",
      "Step 1300, Minibatch Loss= 5875.1260, Train Accuracy= 0.633\n",
      "Step 1400, Minibatch Loss= 7970.9570, Train Accuracy= 0.594\n",
      "Step 1500, Minibatch Loss= 3216.3911, Train Accuracy= 0.727\n",
      "Step 1600, Minibatch Loss= 3187.5083, Train Accuracy= 0.703\n",
      "Step 1700, Minibatch Loss= 3828.3801, Train Accuracy= 0.742\n",
      "Step 1800, Minibatch Loss= 1530.6587, Train Accuracy= 0.805\n",
      "Step 1900, Minibatch Loss= 1337.0328, Train Accuracy= 0.797\n",
      "Step 2000, Minibatch Loss= 1788.4651, Train Accuracy= 0.758\n",
      "Step 2100, Minibatch Loss= 1551.9766, Train Accuracy= 0.750\n",
      "Step 2200, Minibatch Loss= 971.2234, Train Accuracy= 0.797\n",
      "Step 2300, Minibatch Loss= 967.4142, Train Accuracy= 0.695\n",
      "Step 2400, Minibatch Loss= 724.0515, Train Accuracy= 0.781\n",
      "Step 2500, Minibatch Loss= 240.2918, Train Accuracy= 0.820\n",
      "Step 2600, Minibatch Loss= 514.9545, Train Accuracy= 0.773\n",
      "Step 2700, Minibatch Loss= 489.4972, Train Accuracy= 0.734\n",
      "Step 2800, Minibatch Loss= 290.5853, Train Accuracy= 0.836\n",
      "Step 2900, Minibatch Loss= 328.3021, Train Accuracy= 0.820\n",
      "Step 3000, Minibatch Loss= 196.2966, Train Accuracy= 0.844\n",
      "Step 1, Minibatch Loss= 2128469.5000, Train Accuracy= 0.109\n",
      "Step 100, Minibatch Loss= 130784.8125, Train Accuracy= 0.344\n",
      "Step 200, Minibatch Loss= 48417.0859, Train Accuracy= 0.617\n",
      "Step 300, Minibatch Loss= 33901.6250, Train Accuracy= 0.586\n",
      "Step 400, Minibatch Loss= 32152.3242, Train Accuracy= 0.562\n",
      "Step 500, Minibatch Loss= 20892.0703, Train Accuracy= 0.641\n",
      "Step 600, Minibatch Loss= 8588.1660, Train Accuracy= 0.641\n",
      "Step 700, Minibatch Loss= 8579.7900, Train Accuracy= 0.633\n",
      "Step 800, Minibatch Loss= 6597.8213, Train Accuracy= 0.719\n",
      "Step 900, Minibatch Loss= 4661.1494, Train Accuracy= 0.727\n",
      "Step 1000, Minibatch Loss= 8423.9756, Train Accuracy= 0.781\n",
      "Step 1100, Minibatch Loss= 5686.3950, Train Accuracy= 0.758\n",
      "Step 1200, Minibatch Loss= 3387.9089, Train Accuracy= 0.703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1300, Minibatch Loss= 1943.3396, Train Accuracy= 0.805\n",
      "Step 1400, Minibatch Loss= 2184.6602, Train Accuracy= 0.820\n",
      "Step 1500, Minibatch Loss= 3678.4556, Train Accuracy= 0.727\n",
      "Step 1600, Minibatch Loss= 3685.2019, Train Accuracy= 0.734\n",
      "Step 1700, Minibatch Loss= 2171.9651, Train Accuracy= 0.734\n",
      "Step 1800, Minibatch Loss= 885.9258, Train Accuracy= 0.836\n",
      "Step 1900, Minibatch Loss= 950.2587, Train Accuracy= 0.891\n",
      "Step 2000, Minibatch Loss= 1105.6628, Train Accuracy= 0.812\n",
      "Step 2100, Minibatch Loss= 723.7954, Train Accuracy= 0.867\n",
      "Step 2200, Minibatch Loss= 682.3273, Train Accuracy= 0.836\n",
      "Step 2300, Minibatch Loss= 221.2852, Train Accuracy= 0.898\n",
      "Step 2400, Minibatch Loss= 231.6333, Train Accuracy= 0.852\n",
      "Step 2500, Minibatch Loss= 317.1130, Train Accuracy= 0.883\n",
      "Step 2600, Minibatch Loss= 140.9123, Train Accuracy= 0.844\n",
      "Step 2700, Minibatch Loss= 191.5175, Train Accuracy= 0.867\n",
      "Step 2800, Minibatch Loss= 240.9745, Train Accuracy= 0.836\n",
      "Step 2900, Minibatch Loss= 69.2172, Train Accuracy= 0.875\n",
      "Step 3000, Minibatch Loss= 280.9696, Train Accuracy= 0.805\n",
      "Step 1, Minibatch Loss= 3003716.0000, Train Accuracy= 0.125\n",
      "Step 100, Minibatch Loss= 259210.7969, Train Accuracy= 0.391\n",
      "Step 200, Minibatch Loss= 138204.2031, Train Accuracy= 0.391\n",
      "Step 300, Minibatch Loss= 63327.3516, Train Accuracy= 0.445\n",
      "Step 400, Minibatch Loss= 30627.9531, Train Accuracy= 0.555\n",
      "Step 500, Minibatch Loss= 12262.0811, Train Accuracy= 0.602\n",
      "Step 600, Minibatch Loss= 7736.9995, Train Accuracy= 0.758\n",
      "Step 700, Minibatch Loss= 7953.3281, Train Accuracy= 0.742\n",
      "Step 800, Minibatch Loss= 10013.1699, Train Accuracy= 0.773\n",
      "Step 900, Minibatch Loss= 11752.5430, Train Accuracy= 0.727\n",
      "Step 1000, Minibatch Loss= 6905.8672, Train Accuracy= 0.664\n",
      "Step 1100, Minibatch Loss= 4867.9697, Train Accuracy= 0.789\n",
      "Step 1200, Minibatch Loss= 2783.8499, Train Accuracy= 0.852\n",
      "Step 1300, Minibatch Loss= 2996.2666, Train Accuracy= 0.781\n",
      "Step 1400, Minibatch Loss= 2336.6655, Train Accuracy= 0.789\n",
      "Step 1500, Minibatch Loss= 1389.3121, Train Accuracy= 0.828\n",
      "Step 1600, Minibatch Loss= 2342.3296, Train Accuracy= 0.789\n",
      "Step 1700, Minibatch Loss= 1942.8306, Train Accuracy= 0.773\n",
      "Step 1800, Minibatch Loss= 1027.5643, Train Accuracy= 0.828\n",
      "Step 1900, Minibatch Loss= 845.1815, Train Accuracy= 0.820\n",
      "Step 2000, Minibatch Loss= 720.9534, Train Accuracy= 0.820\n",
      "Step 2100, Minibatch Loss= 389.2010, Train Accuracy= 0.766\n",
      "Step 2200, Minibatch Loss= 247.7736, Train Accuracy= 0.859\n",
      "Step 2300, Minibatch Loss= 438.9291, Train Accuracy= 0.820\n",
      "Step 2400, Minibatch Loss= 554.4874, Train Accuracy= 0.820\n",
      "Step 2500, Minibatch Loss= 101.8098, Train Accuracy= 0.891\n",
      "Step 2600, Minibatch Loss= 268.0600, Train Accuracy= 0.836\n",
      "Step 2700, Minibatch Loss= 152.1057, Train Accuracy= 0.828\n",
      "Step 2800, Minibatch Loss= 154.7195, Train Accuracy= 0.836\n",
      "Step 2900, Minibatch Loss= 131.6401, Train Accuracy= 0.922\n",
      "Step 3000, Minibatch Loss= 130.2230, Train Accuracy= 0.859\n",
      "Step 1, Minibatch Loss= 3539007.5000, Train Accuracy= 0.117\n",
      "Step 100, Minibatch Loss= 178090.8750, Train Accuracy= 0.453\n",
      "Step 200, Minibatch Loss= 70730.8906, Train Accuracy= 0.469\n",
      "Step 300, Minibatch Loss= 38714.5859, Train Accuracy= 0.625\n",
      "Step 400, Minibatch Loss= 67184.2031, Train Accuracy= 0.500\n",
      "Step 500, Minibatch Loss= 35967.2383, Train Accuracy= 0.539\n",
      "Step 600, Minibatch Loss= 17618.0898, Train Accuracy= 0.602\n",
      "Step 700, Minibatch Loss= 5970.6055, Train Accuracy= 0.742\n",
      "Step 800, Minibatch Loss= 12237.2686, Train Accuracy= 0.711\n",
      "Step 900, Minibatch Loss= 6948.6274, Train Accuracy= 0.680\n",
      "Step 1000, Minibatch Loss= 10276.0420, Train Accuracy= 0.586\n",
      "Step 1100, Minibatch Loss= 4470.6196, Train Accuracy= 0.883\n",
      "Step 1200, Minibatch Loss= 5174.5303, Train Accuracy= 0.711\n",
      "Step 1300, Minibatch Loss= 3703.4272, Train Accuracy= 0.875\n",
      "Step 1400, Minibatch Loss= 3588.9453, Train Accuracy= 0.859\n",
      "Step 1500, Minibatch Loss= 2691.8171, Train Accuracy= 0.758\n",
      "Step 1600, Minibatch Loss= 2384.0818, Train Accuracy= 0.836\n",
      "Step 1700, Minibatch Loss= 1721.0828, Train Accuracy= 0.836\n",
      "Step 1800, Minibatch Loss= 1726.3817, Train Accuracy= 0.766\n",
      "Step 1900, Minibatch Loss= 1073.0884, Train Accuracy= 0.805\n",
      "Step 2000, Minibatch Loss= 923.7076, Train Accuracy= 0.820\n",
      "Step 2100, Minibatch Loss= 1321.9164, Train Accuracy= 0.820\n",
      "Step 2200, Minibatch Loss= 832.8291, Train Accuracy= 0.852\n",
      "Step 2300, Minibatch Loss= 613.0167, Train Accuracy= 0.844\n",
      "Step 2400, Minibatch Loss= 367.6236, Train Accuracy= 0.867\n",
      "Step 2500, Minibatch Loss= 310.7724, Train Accuracy= 0.836\n",
      "Step 2600, Minibatch Loss= 130.8116, Train Accuracy= 0.883\n",
      "Step 2700, Minibatch Loss= 180.3939, Train Accuracy= 0.820\n",
      "Step 2800, Minibatch Loss= 149.8463, Train Accuracy= 0.758\n",
      "Step 2900, Minibatch Loss= 183.6668, Train Accuracy= 0.828\n",
      "Step 3000, Minibatch Loss= 94.8271, Train Accuracy= 0.875\n",
      "Step 1, Minibatch Loss= 4149335.0000, Train Accuracy= 0.164\n",
      "Step 100, Minibatch Loss= 223981.3750, Train Accuracy= 0.461\n",
      "Step 200, Minibatch Loss= 52399.7500, Train Accuracy= 0.594\n",
      "Step 300, Minibatch Loss= 20157.5605, Train Accuracy= 0.570\n",
      "Step 400, Minibatch Loss= 23862.8008, Train Accuracy= 0.570\n",
      "Step 500, Minibatch Loss= 22731.5762, Train Accuracy= 0.656\n",
      "Step 600, Minibatch Loss= 17516.2754, Train Accuracy= 0.609\n",
      "Step 700, Minibatch Loss= 12914.8662, Train Accuracy= 0.656\n",
      "Step 800, Minibatch Loss= 8366.0771, Train Accuracy= 0.742\n",
      "Step 900, Minibatch Loss= 17213.3516, Train Accuracy= 0.594\n",
      "Step 1000, Minibatch Loss= 7104.2021, Train Accuracy= 0.758\n",
      "Step 1100, Minibatch Loss= 6774.0635, Train Accuracy= 0.734\n",
      "Step 1200, Minibatch Loss= 6826.2295, Train Accuracy= 0.711\n",
      "Step 1300, Minibatch Loss= 5768.4141, Train Accuracy= 0.719\n",
      "Step 1400, Minibatch Loss= 5271.5928, Train Accuracy= 0.781\n",
      "Step 1500, Minibatch Loss= 2417.1775, Train Accuracy= 0.852\n",
      "Step 1600, Minibatch Loss= 2799.6943, Train Accuracy= 0.812\n",
      "Step 1700, Minibatch Loss= 4279.5225, Train Accuracy= 0.781\n",
      "Step 1800, Minibatch Loss= 1893.6743, Train Accuracy= 0.781\n",
      "Step 1900, Minibatch Loss= 1229.1808, Train Accuracy= 0.820\n",
      "Step 2000, Minibatch Loss= 1678.7422, Train Accuracy= 0.859\n",
      "Step 2100, Minibatch Loss= 675.2040, Train Accuracy= 0.891\n",
      "Step 2200, Minibatch Loss= 1140.1936, Train Accuracy= 0.828\n",
      "Step 2300, Minibatch Loss= 794.9151, Train Accuracy= 0.812\n",
      "Step 2400, Minibatch Loss= 1001.3452, Train Accuracy= 0.867\n",
      "Step 2500, Minibatch Loss= 591.2529, Train Accuracy= 0.875\n",
      "Step 2600, Minibatch Loss= 755.1574, Train Accuracy= 0.852\n",
      "Step 2700, Minibatch Loss= 1032.0580, Train Accuracy= 0.867\n",
      "Step 2800, Minibatch Loss= 770.7672, Train Accuracy= 0.898\n",
      "Step 2900, Minibatch Loss= 326.9869, Train Accuracy= 0.922\n",
      "Step 3000, Minibatch Loss= 11.8472, Train Accuracy= 0.789\n",
      "Step 1, Minibatch Loss= 1542581.5000, Train Accuracy= 0.273\n",
      "Step 100, Minibatch Loss= 228296.0000, Train Accuracy= 0.445\n",
      "Step 200, Minibatch Loss= 42880.9062, Train Accuracy= 0.523\n",
      "Step 300, Minibatch Loss= 18864.9180, Train Accuracy= 0.672\n",
      "Step 400, Minibatch Loss= 15567.4053, Train Accuracy= 0.719\n",
      "Step 500, Minibatch Loss= 16458.8223, Train Accuracy= 0.727\n",
      "Step 600, Minibatch Loss= 28862.8438, Train Accuracy= 0.625\n",
      "Step 700, Minibatch Loss= 15196.0078, Train Accuracy= 0.664\n",
      "Step 800, Minibatch Loss= 11610.1982, Train Accuracy= 0.711\n",
      "Step 900, Minibatch Loss= 6700.1504, Train Accuracy= 0.742\n",
      "Step 1000, Minibatch Loss= 6171.9502, Train Accuracy= 0.719\n",
      "Step 1100, Minibatch Loss= 4850.4199, Train Accuracy= 0.719\n",
      "Step 1200, Minibatch Loss= 7329.1538, Train Accuracy= 0.695\n",
      "Step 1300, Minibatch Loss= 4271.8984, Train Accuracy= 0.734\n",
      "Step 1400, Minibatch Loss= 4597.5693, Train Accuracy= 0.688\n",
      "Step 1500, Minibatch Loss= 2160.7725, Train Accuracy= 0.789\n",
      "Step 1600, Minibatch Loss= 2051.7905, Train Accuracy= 0.789\n",
      "Step 1700, Minibatch Loss= 2181.6279, Train Accuracy= 0.719\n",
      "Step 1800, Minibatch Loss= 1061.8743, Train Accuracy= 0.742\n",
      "Step 1900, Minibatch Loss= 1357.9878, Train Accuracy= 0.805\n",
      "Step 2000, Minibatch Loss= 1088.1016, Train Accuracy= 0.766\n",
      "Step 2100, Minibatch Loss= 501.1963, Train Accuracy= 0.797\n",
      "Step 2200, Minibatch Loss= 449.8390, Train Accuracy= 0.781\n",
      "Step 2300, Minibatch Loss= 290.8826, Train Accuracy= 0.852\n",
      "Step 2400, Minibatch Loss= 484.2180, Train Accuracy= 0.828\n",
      "Step 2500, Minibatch Loss= 428.4763, Train Accuracy= 0.781\n",
      "Step 2600, Minibatch Loss= 128.5197, Train Accuracy= 0.867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2700, Minibatch Loss= 246.1412, Train Accuracy= 0.781\n",
      "Step 2800, Minibatch Loss= 126.2048, Train Accuracy= 0.844\n",
      "Step 2900, Minibatch Loss= 66.7783, Train Accuracy= 0.906\n",
      "Step 3000, Minibatch Loss= 212.5807, Train Accuracy= 0.812\n",
      "Step 1, Minibatch Loss= 1352821.6250, Train Accuracy= 0.227\n",
      "Step 100, Minibatch Loss= 207287.8594, Train Accuracy= 0.445\n",
      "Step 200, Minibatch Loss= 35820.0938, Train Accuracy= 0.820\n",
      "Step 300, Minibatch Loss= 29225.6562, Train Accuracy= 0.523\n",
      "Step 400, Minibatch Loss= 15118.1943, Train Accuracy= 0.750\n",
      "Step 500, Minibatch Loss= 34056.5625, Train Accuracy= 0.672\n",
      "Step 600, Minibatch Loss= 16620.0898, Train Accuracy= 0.633\n",
      "Step 700, Minibatch Loss= 9805.5352, Train Accuracy= 0.742\n",
      "Step 800, Minibatch Loss= 4529.2656, Train Accuracy= 0.781\n",
      "Step 900, Minibatch Loss= 11708.4336, Train Accuracy= 0.758\n",
      "Step 1000, Minibatch Loss= 4398.2529, Train Accuracy= 0.734\n",
      "Step 1100, Minibatch Loss= 5433.2510, Train Accuracy= 0.727\n",
      "Step 1200, Minibatch Loss= 2669.1809, Train Accuracy= 0.781\n",
      "Step 1300, Minibatch Loss= 3160.2373, Train Accuracy= 0.797\n",
      "Step 1400, Minibatch Loss= 550.4200, Train Accuracy= 0.930\n",
      "Step 1500, Minibatch Loss= 2042.3584, Train Accuracy= 0.820\n",
      "Step 1600, Minibatch Loss= 2165.8633, Train Accuracy= 0.836\n",
      "Step 1700, Minibatch Loss= 3286.5903, Train Accuracy= 0.773\n",
      "Step 1800, Minibatch Loss= 743.9567, Train Accuracy= 0.906\n",
      "Step 1900, Minibatch Loss= 484.4403, Train Accuracy= 0.867\n",
      "Step 2000, Minibatch Loss= 1536.4420, Train Accuracy= 0.852\n",
      "Step 2100, Minibatch Loss= 1256.3544, Train Accuracy= 0.820\n",
      "Step 2200, Minibatch Loss= 988.5214, Train Accuracy= 0.844\n",
      "Step 2300, Minibatch Loss= 272.4060, Train Accuracy= 0.875\n",
      "Step 2400, Minibatch Loss= 722.2838, Train Accuracy= 0.867\n",
      "Step 2500, Minibatch Loss= 568.2679, Train Accuracy= 0.852\n",
      "Step 2600, Minibatch Loss= 1002.6572, Train Accuracy= 0.852\n",
      "Step 2700, Minibatch Loss= 585.9618, Train Accuracy= 0.898\n",
      "Step 2800, Minibatch Loss= 58.8251, Train Accuracy= 0.727\n",
      "Step 2900, Minibatch Loss= 28.4046, Train Accuracy= 0.891\n",
      "Step 3000, Minibatch Loss= 3.1190, Train Accuracy= 0.820\n",
      "Step 1, Minibatch Loss= 5005328.5000, Train Accuracy= 0.148\n",
      "Step 100, Minibatch Loss= 460076.5938, Train Accuracy= 0.391\n",
      "Step 200, Minibatch Loss= 81281.5312, Train Accuracy= 0.594\n",
      "Step 300, Minibatch Loss= 38714.3750, Train Accuracy= 0.648\n",
      "Step 400, Minibatch Loss= 17550.7070, Train Accuracy= 0.797\n",
      "Step 500, Minibatch Loss= 17814.8965, Train Accuracy= 0.812\n",
      "Step 600, Minibatch Loss= 12224.5625, Train Accuracy= 0.727\n",
      "Step 700, Minibatch Loss= 10083.0000, Train Accuracy= 0.797\n",
      "Step 800, Minibatch Loss= 17516.9727, Train Accuracy= 0.773\n",
      "Step 900, Minibatch Loss= 8888.5527, Train Accuracy= 0.680\n",
      "Step 1000, Minibatch Loss= 5950.8672, Train Accuracy= 0.719\n",
      "Step 1100, Minibatch Loss= 7253.5591, Train Accuracy= 0.711\n",
      "Step 1200, Minibatch Loss= 4485.0947, Train Accuracy= 0.750\n",
      "Step 1300, Minibatch Loss= 4393.9170, Train Accuracy= 0.820\n",
      "Step 1400, Minibatch Loss= 5945.9736, Train Accuracy= 0.766\n",
      "Step 1500, Minibatch Loss= 2924.6533, Train Accuracy= 0.820\n",
      "Step 1600, Minibatch Loss= 2575.4417, Train Accuracy= 0.828\n",
      "Step 1700, Minibatch Loss= 3068.7874, Train Accuracy= 0.781\n",
      "Step 1800, Minibatch Loss= 1968.9736, Train Accuracy= 0.844\n",
      "Step 1900, Minibatch Loss= 1560.3104, Train Accuracy= 0.852\n",
      "Step 2000, Minibatch Loss= 339.9329, Train Accuracy= 0.906\n",
      "Step 2100, Minibatch Loss= 330.9786, Train Accuracy= 0.883\n",
      "Step 2200, Minibatch Loss= 460.1233, Train Accuracy= 0.867\n",
      "Step 2300, Minibatch Loss= 860.1254, Train Accuracy= 0.844\n",
      "Step 2400, Minibatch Loss= 546.8101, Train Accuracy= 0.867\n",
      "Step 2500, Minibatch Loss= 378.8722, Train Accuracy= 0.844\n",
      "Step 2600, Minibatch Loss= 200.8902, Train Accuracy= 0.859\n",
      "Step 2700, Minibatch Loss= 339.0891, Train Accuracy= 0.875\n",
      "Step 2800, Minibatch Loss= 183.0161, Train Accuracy= 0.867\n",
      "Step 2900, Minibatch Loss= 260.0349, Train Accuracy= 0.883\n",
      "Step 3000, Minibatch Loss= 320.8899, Train Accuracy= 0.867\n",
      "Step 1, Minibatch Loss= 1075659.0000, Train Accuracy= 0.266\n",
      "Step 100, Minibatch Loss= 189353.7969, Train Accuracy= 0.562\n",
      "Step 200, Minibatch Loss= 50296.1641, Train Accuracy= 0.625\n",
      "Step 300, Minibatch Loss= 46947.6562, Train Accuracy= 0.609\n",
      "Step 400, Minibatch Loss= 39551.3984, Train Accuracy= 0.602\n",
      "Step 500, Minibatch Loss= 29695.5215, Train Accuracy= 0.633\n",
      "Step 600, Minibatch Loss= 33531.3516, Train Accuracy= 0.547\n",
      "Step 700, Minibatch Loss= 37275.7422, Train Accuracy= 0.641\n",
      "Step 800, Minibatch Loss= 23545.4766, Train Accuracy= 0.633\n",
      "Step 900, Minibatch Loss= 15576.5605, Train Accuracy= 0.594\n",
      "Step 1000, Minibatch Loss= 13664.9023, Train Accuracy= 0.609\n",
      "Step 1100, Minibatch Loss= 6141.0332, Train Accuracy= 0.625\n",
      "Step 1200, Minibatch Loss= 4776.9458, Train Accuracy= 0.820\n",
      "Step 1300, Minibatch Loss= 6271.3477, Train Accuracy= 0.695\n",
      "Step 1400, Minibatch Loss= 2533.4055, Train Accuracy= 0.805\n",
      "Step 1500, Minibatch Loss= 883.1278, Train Accuracy= 0.875\n",
      "Step 1600, Minibatch Loss= 3490.2349, Train Accuracy= 0.820\n",
      "Step 1700, Minibatch Loss= 2510.6978, Train Accuracy= 0.797\n",
      "Step 1800, Minibatch Loss= 1518.3745, Train Accuracy= 0.758\n",
      "Step 1900, Minibatch Loss= 548.8671, Train Accuracy= 0.789\n",
      "Step 2000, Minibatch Loss= 1454.2146, Train Accuracy= 0.766\n",
      "Step 2100, Minibatch Loss= 967.7540, Train Accuracy= 0.797\n",
      "Step 2200, Minibatch Loss= 642.2280, Train Accuracy= 0.891\n",
      "Step 2300, Minibatch Loss= 841.3500, Train Accuracy= 0.859\n",
      "Step 2400, Minibatch Loss= 1386.3599, Train Accuracy= 0.828\n",
      "Step 2500, Minibatch Loss= 1100.1077, Train Accuracy= 0.836\n",
      "Step 2600, Minibatch Loss= 529.6467, Train Accuracy= 0.898\n",
      "Step 2700, Minibatch Loss= 1010.0685, Train Accuracy= 0.844\n",
      "Step 2800, Minibatch Loss= 303.3642, Train Accuracy= 0.875\n",
      "Step 2900, Minibatch Loss= 109.8381, Train Accuracy= 0.844\n",
      "Step 3000, Minibatch Loss= 1.8240, Train Accuracy= 0.836\n",
      "Step 1, Minibatch Loss= 2765584.0000, Train Accuracy= 0.195\n",
      "Step 100, Minibatch Loss= 141887.4219, Train Accuracy= 0.383\n",
      "Step 200, Minibatch Loss= 33505.5547, Train Accuracy= 0.625\n",
      "Step 300, Minibatch Loss= 45119.5508, Train Accuracy= 0.633\n",
      "Step 400, Minibatch Loss= 26082.4805, Train Accuracy= 0.828\n",
      "Step 500, Minibatch Loss= 33199.5039, Train Accuracy= 0.727\n",
      "Step 600, Minibatch Loss= 26870.6172, Train Accuracy= 0.633\n",
      "Step 700, Minibatch Loss= 13152.9805, Train Accuracy= 0.688\n",
      "Step 800, Minibatch Loss= 12563.0820, Train Accuracy= 0.648\n",
      "Step 900, Minibatch Loss= 8554.2539, Train Accuracy= 0.773\n",
      "Step 1000, Minibatch Loss= 8332.2070, Train Accuracy= 0.750\n",
      "Step 1100, Minibatch Loss= 6598.4453, Train Accuracy= 0.836\n",
      "Step 1200, Minibatch Loss= 4169.7417, Train Accuracy= 0.820\n",
      "Step 1300, Minibatch Loss= 5184.6709, Train Accuracy= 0.812\n",
      "Step 1400, Minibatch Loss= 2454.1826, Train Accuracy= 0.820\n",
      "Step 1500, Minibatch Loss= 2083.4106, Train Accuracy= 0.828\n",
      "Step 1600, Minibatch Loss= 1093.4159, Train Accuracy= 0.859\n",
      "Step 1700, Minibatch Loss= 1168.3752, Train Accuracy= 0.812\n",
      "Step 1800, Minibatch Loss= 1690.5452, Train Accuracy= 0.820\n",
      "Step 1900, Minibatch Loss= 869.0847, Train Accuracy= 0.836\n",
      "Step 2000, Minibatch Loss= 486.1724, Train Accuracy= 0.867\n",
      "Step 2100, Minibatch Loss= 548.9587, Train Accuracy= 0.820\n",
      "Step 2200, Minibatch Loss= 523.0229, Train Accuracy= 0.844\n",
      "Step 2300, Minibatch Loss= 238.4063, Train Accuracy= 0.836\n",
      "Step 2400, Minibatch Loss= 226.8458, Train Accuracy= 0.859\n",
      "Step 2500, Minibatch Loss= 170.0575, Train Accuracy= 0.883\n",
      "Step 2600, Minibatch Loss= 110.4806, Train Accuracy= 0.891\n",
      "Step 2700, Minibatch Loss= 115.8344, Train Accuracy= 0.859\n",
      "Step 2800, Minibatch Loss= 109.7744, Train Accuracy= 0.883\n",
      "Step 2900, Minibatch Loss= 257.5111, Train Accuracy= 0.852\n",
      "Step 3000, Minibatch Loss= 94.7240, Train Accuracy= 0.883\n",
      "Step 1, Minibatch Loss= 1885584.2500, Train Accuracy= 0.117\n",
      "Step 100, Minibatch Loss= 288687.9688, Train Accuracy= 0.398\n",
      "Step 200, Minibatch Loss= 95298.3750, Train Accuracy= 0.539\n",
      "Step 300, Minibatch Loss= 54320.5000, Train Accuracy= 0.555\n",
      "Step 400, Minibatch Loss= 15236.5137, Train Accuracy= 0.750\n",
      "Step 500, Minibatch Loss= 16750.3594, Train Accuracy= 0.547\n",
      "Step 600, Minibatch Loss= 23684.0293, Train Accuracy= 0.539\n",
      "Step 700, Minibatch Loss= 17499.9512, Train Accuracy= 0.578\n",
      "Step 800, Minibatch Loss= 19393.8535, Train Accuracy= 0.602\n",
      "Step 900, Minibatch Loss= 10672.0332, Train Accuracy= 0.781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000, Minibatch Loss= 7136.9707, Train Accuracy= 0.734\n",
      "Step 1100, Minibatch Loss= 8876.8125, Train Accuracy= 0.812\n",
      "Step 1200, Minibatch Loss= 6734.3311, Train Accuracy= 0.781\n",
      "Step 1300, Minibatch Loss= 2394.2678, Train Accuracy= 0.836\n",
      "Step 1400, Minibatch Loss= 3943.8726, Train Accuracy= 0.789\n",
      "Step 1500, Minibatch Loss= 3876.7427, Train Accuracy= 0.836\n",
      "Step 1600, Minibatch Loss= 3537.9016, Train Accuracy= 0.797\n",
      "Step 1700, Minibatch Loss= 3548.0486, Train Accuracy= 0.812\n",
      "Step 1800, Minibatch Loss= 1518.0386, Train Accuracy= 0.852\n",
      "Step 1900, Minibatch Loss= 1390.2645, Train Accuracy= 0.836\n",
      "Step 2000, Minibatch Loss= 1433.4532, Train Accuracy= 0.828\n",
      "Step 2100, Minibatch Loss= 1017.9874, Train Accuracy= 0.797\n",
      "Step 2200, Minibatch Loss= 925.8620, Train Accuracy= 0.828\n",
      "Step 2300, Minibatch Loss= 832.5416, Train Accuracy= 0.859\n",
      "Step 2400, Minibatch Loss= 416.5442, Train Accuracy= 0.883\n",
      "Step 2500, Minibatch Loss= 163.3933, Train Accuracy= 0.898\n",
      "Step 2600, Minibatch Loss= 231.6565, Train Accuracy= 0.852\n",
      "Step 2700, Minibatch Loss= 179.2518, Train Accuracy= 0.852\n",
      "Step 2800, Minibatch Loss= 89.9250, Train Accuracy= 0.906\n",
      "Step 2900, Minibatch Loss= 340.5698, Train Accuracy= 0.883\n",
      "Step 3000, Minibatch Loss= 89.9529, Train Accuracy= 0.891\n",
      "Step 1, Minibatch Loss= 3684553.0000, Train Accuracy= 0.109\n",
      "Step 100, Minibatch Loss= 197216.8125, Train Accuracy= 0.445\n",
      "Step 200, Minibatch Loss= 108390.6562, Train Accuracy= 0.672\n",
      "Step 300, Minibatch Loss= 23021.4961, Train Accuracy= 0.641\n",
      "Step 400, Minibatch Loss= 17277.0430, Train Accuracy= 0.641\n",
      "Step 500, Minibatch Loss= 14640.4551, Train Accuracy= 0.648\n",
      "Step 600, Minibatch Loss= 13667.6230, Train Accuracy= 0.625\n",
      "Step 700, Minibatch Loss= 11998.4082, Train Accuracy= 0.609\n",
      "Step 800, Minibatch Loss= 11341.4766, Train Accuracy= 0.680\n",
      "Step 900, Minibatch Loss= 6239.1353, Train Accuracy= 0.820\n",
      "Step 1000, Minibatch Loss= 5361.0430, Train Accuracy= 0.750\n",
      "Step 1100, Minibatch Loss= 3578.6980, Train Accuracy= 0.672\n",
      "Step 1200, Minibatch Loss= 5541.3867, Train Accuracy= 0.797\n",
      "Step 1300, Minibatch Loss= 4483.6685, Train Accuracy= 0.719\n",
      "Step 1400, Minibatch Loss= 5160.4580, Train Accuracy= 0.719\n",
      "Step 1500, Minibatch Loss= 1668.3020, Train Accuracy= 0.836\n",
      "Step 1600, Minibatch Loss= 1379.2943, Train Accuracy= 0.836\n",
      "Step 1700, Minibatch Loss= 1258.6538, Train Accuracy= 0.828\n",
      "Step 1800, Minibatch Loss= 1875.7559, Train Accuracy= 0.812\n",
      "Step 1900, Minibatch Loss= 1363.4802, Train Accuracy= 0.820\n",
      "Step 2000, Minibatch Loss= 558.3945, Train Accuracy= 0.852\n",
      "Step 2100, Minibatch Loss= 464.7131, Train Accuracy= 0.703\n",
      "Step 2200, Minibatch Loss= 1108.7379, Train Accuracy= 0.773\n",
      "Step 2300, Minibatch Loss= 455.2742, Train Accuracy= 0.898\n",
      "Step 2400, Minibatch Loss= 477.3157, Train Accuracy= 0.844\n",
      "Step 2500, Minibatch Loss= 251.7591, Train Accuracy= 0.797\n",
      "Step 2600, Minibatch Loss= 242.9553, Train Accuracy= 0.898\n",
      "Step 2700, Minibatch Loss= 81.5977, Train Accuracy= 0.883\n",
      "Step 2800, Minibatch Loss= 117.7000, Train Accuracy= 0.789\n",
      "Step 2900, Minibatch Loss= 55.0541, Train Accuracy= 0.859\n",
      "Step 3000, Minibatch Loss= 97.2187, Train Accuracy= 0.898\n",
      "Step 1, Minibatch Loss= 1261923.5000, Train Accuracy= 0.289\n",
      "Step 100, Minibatch Loss= 361972.5312, Train Accuracy= 0.523\n",
      "Step 200, Minibatch Loss= 79550.4062, Train Accuracy= 0.469\n",
      "Step 300, Minibatch Loss= 40121.5391, Train Accuracy= 0.523\n",
      "Step 400, Minibatch Loss= 43855.4648, Train Accuracy= 0.539\n",
      "Step 500, Minibatch Loss= 27044.4961, Train Accuracy= 0.578\n",
      "Step 600, Minibatch Loss= 11952.0293, Train Accuracy= 0.633\n",
      "Step 700, Minibatch Loss= 5291.6748, Train Accuracy= 0.727\n",
      "Step 800, Minibatch Loss= 8598.8438, Train Accuracy= 0.672\n",
      "Step 900, Minibatch Loss= 5001.1758, Train Accuracy= 0.758\n",
      "Step 1000, Minibatch Loss= 3739.3943, Train Accuracy= 0.867\n",
      "Step 1100, Minibatch Loss= 5725.7441, Train Accuracy= 0.836\n",
      "Step 1200, Minibatch Loss= 3026.8467, Train Accuracy= 0.859\n",
      "Step 1300, Minibatch Loss= 1775.8579, Train Accuracy= 0.805\n",
      "Step 1400, Minibatch Loss= 2607.0479, Train Accuracy= 0.867\n",
      "Step 1500, Minibatch Loss= 3826.0239, Train Accuracy= 0.797\n",
      "Step 1600, Minibatch Loss= 2700.7559, Train Accuracy= 0.828\n",
      "Step 1700, Minibatch Loss= 1358.5430, Train Accuracy= 0.883\n",
      "Step 1800, Minibatch Loss= 1747.5081, Train Accuracy= 0.828\n",
      "Step 1900, Minibatch Loss= 928.5037, Train Accuracy= 0.883\n",
      "Step 2000, Minibatch Loss= 1121.6135, Train Accuracy= 0.852\n",
      "Step 2100, Minibatch Loss= 929.1188, Train Accuracy= 0.867\n",
      "Step 2200, Minibatch Loss= 877.2067, Train Accuracy= 0.898\n",
      "Step 2300, Minibatch Loss= 299.0263, Train Accuracy= 0.906\n",
      "Step 2400, Minibatch Loss= 530.6565, Train Accuracy= 0.914\n",
      "Step 2500, Minibatch Loss= 110.2977, Train Accuracy= 0.906\n",
      "Step 2600, Minibatch Loss= 283.6694, Train Accuracy= 0.859\n",
      "Step 2700, Minibatch Loss= 147.2714, Train Accuracy= 0.922\n",
      "Step 2800, Minibatch Loss= 10.7092, Train Accuracy= 0.805\n",
      "Step 2900, Minibatch Loss= 5.7432, Train Accuracy= 0.688\n",
      "Step 3000, Minibatch Loss= 6.1737, Train Accuracy= 0.781\n",
      "Step 1, Minibatch Loss= 1771112.0000, Train Accuracy= 0.141\n",
      "Step 100, Minibatch Loss= 124472.5312, Train Accuracy= 0.422\n",
      "Step 200, Minibatch Loss= 53700.5664, Train Accuracy= 0.547\n",
      "Step 300, Minibatch Loss= 35611.3438, Train Accuracy= 0.641\n",
      "Step 400, Minibatch Loss= 27921.8945, Train Accuracy= 0.711\n",
      "Step 500, Minibatch Loss= 26264.1816, Train Accuracy= 0.695\n",
      "Step 600, Minibatch Loss= 18574.7461, Train Accuracy= 0.664\n",
      "Step 700, Minibatch Loss= 15644.3984, Train Accuracy= 0.664\n",
      "Step 800, Minibatch Loss= 8424.9023, Train Accuracy= 0.648\n",
      "Step 900, Minibatch Loss= 14713.7148, Train Accuracy= 0.664\n",
      "Step 1000, Minibatch Loss= 16663.9453, Train Accuracy= 0.633\n",
      "Step 1100, Minibatch Loss= 11016.5410, Train Accuracy= 0.641\n",
      "Step 1200, Minibatch Loss= 6790.0171, Train Accuracy= 0.680\n",
      "Step 1300, Minibatch Loss= 5735.4897, Train Accuracy= 0.695\n",
      "Step 1400, Minibatch Loss= 4602.3066, Train Accuracy= 0.727\n",
      "Step 1500, Minibatch Loss= 3538.2678, Train Accuracy= 0.727\n",
      "Step 1600, Minibatch Loss= 2879.6614, Train Accuracy= 0.664\n",
      "Step 1700, Minibatch Loss= 1920.7891, Train Accuracy= 0.703\n",
      "Step 1800, Minibatch Loss= 1182.3417, Train Accuracy= 0.773\n",
      "Step 1900, Minibatch Loss= 1292.3127, Train Accuracy= 0.703\n",
      "Step 2000, Minibatch Loss= 391.0279, Train Accuracy= 0.766\n",
      "Step 2100, Minibatch Loss= 618.0565, Train Accuracy= 0.711\n",
      "Step 2200, Minibatch Loss= 680.5443, Train Accuracy= 0.680\n",
      "Step 2300, Minibatch Loss= 706.8589, Train Accuracy= 0.789\n",
      "Step 2400, Minibatch Loss= 296.0461, Train Accuracy= 0.781\n",
      "Step 2500, Minibatch Loss= 309.2941, Train Accuracy= 0.844\n",
      "Step 2600, Minibatch Loss= 342.7726, Train Accuracy= 0.781\n",
      "Step 2700, Minibatch Loss= 249.0905, Train Accuracy= 0.781\n",
      "Step 2800, Minibatch Loss= 165.3893, Train Accuracy= 0.859\n",
      "Step 2900, Minibatch Loss= 179.9535, Train Accuracy= 0.766\n",
      "Step 3000, Minibatch Loss= 270.7407, Train Accuracy= 0.758\n",
      "Step 1, Minibatch Loss= 1690337.0000, Train Accuracy= 0.070\n",
      "Step 100, Minibatch Loss= 84255.5547, Train Accuracy= 0.570\n",
      "Step 200, Minibatch Loss= 21425.2109, Train Accuracy= 0.648\n",
      "Step 300, Minibatch Loss= 14196.1582, Train Accuracy= 0.656\n",
      "Step 400, Minibatch Loss= 28334.3789, Train Accuracy= 0.625\n",
      "Step 500, Minibatch Loss= 16921.4180, Train Accuracy= 0.742\n",
      "Step 600, Minibatch Loss= 22593.9688, Train Accuracy= 0.602\n",
      "Step 700, Minibatch Loss= 16117.8545, Train Accuracy= 0.656\n",
      "Step 800, Minibatch Loss= 19172.5820, Train Accuracy= 0.648\n",
      "Step 900, Minibatch Loss= 12379.0859, Train Accuracy= 0.719\n",
      "Step 1000, Minibatch Loss= 15503.6660, Train Accuracy= 0.680\n",
      "Step 1100, Minibatch Loss= 12279.1074, Train Accuracy= 0.664\n",
      "Step 1200, Minibatch Loss= 5065.9165, Train Accuracy= 0.758\n",
      "Step 1300, Minibatch Loss= 4654.4126, Train Accuracy= 0.766\n",
      "Step 1400, Minibatch Loss= 2335.8091, Train Accuracy= 0.812\n",
      "Step 1500, Minibatch Loss= 1828.3812, Train Accuracy= 0.820\n",
      "Step 1600, Minibatch Loss= 1792.8572, Train Accuracy= 0.805\n",
      "Step 1700, Minibatch Loss= 1249.9551, Train Accuracy= 0.883\n",
      "Step 1800, Minibatch Loss= 885.1017, Train Accuracy= 0.836\n",
      "Step 1900, Minibatch Loss= 1176.4956, Train Accuracy= 0.852\n",
      "Step 2000, Minibatch Loss= 622.8450, Train Accuracy= 0.883\n",
      "Step 2100, Minibatch Loss= 747.8027, Train Accuracy= 0.852\n",
      "Step 2200, Minibatch Loss= 1008.1808, Train Accuracy= 0.797\n",
      "Step 2300, Minibatch Loss= 578.3492, Train Accuracy= 0.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2400, Minibatch Loss= 325.3745, Train Accuracy= 0.914\n",
      "Step 2500, Minibatch Loss= 465.4109, Train Accuracy= 0.859\n",
      "Step 2600, Minibatch Loss= 399.1396, Train Accuracy= 0.812\n",
      "Step 2700, Minibatch Loss= 367.4223, Train Accuracy= 0.844\n",
      "Step 2800, Minibatch Loss= 240.8935, Train Accuracy= 0.852\n",
      "Step 2900, Minibatch Loss= 154.7968, Train Accuracy= 0.883\n",
      "Step 3000, Minibatch Loss= 199.2607, Train Accuracy= 0.891\n",
      "Step 1, Minibatch Loss= 3126892.5000, Train Accuracy= 0.125\n",
      "Step 100, Minibatch Loss= 110386.4609, Train Accuracy= 0.523\n",
      "Step 200, Minibatch Loss= 87999.9219, Train Accuracy= 0.570\n",
      "Step 300, Minibatch Loss= 24228.4414, Train Accuracy= 0.555\n",
      "Step 400, Minibatch Loss= 18196.3516, Train Accuracy= 0.672\n",
      "Step 500, Minibatch Loss= 22140.7598, Train Accuracy= 0.688\n",
      "Step 600, Minibatch Loss= 16281.3594, Train Accuracy= 0.648\n",
      "Step 700, Minibatch Loss= 12416.1611, Train Accuracy= 0.688\n",
      "Step 800, Minibatch Loss= 8429.9785, Train Accuracy= 0.719\n",
      "Step 900, Minibatch Loss= 6790.1143, Train Accuracy= 0.766\n",
      "Step 1000, Minibatch Loss= 5782.6436, Train Accuracy= 0.789\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3b04328136bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# acccc=np.zeros((50,10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0maccc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_fcon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/accc.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/experiment/test/twobyt/fcon_2.py\u001b[0m in \u001b[0;36mtrain_fcon\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m#batch_x, batch_y = g_error(pic,weight1,weight2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mv_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/experiment/test/twobyt/smg.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(shape, bs, m)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generator'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/experiment/test/twobyt/smg.py\u001b[0m in \u001b[0;36mgenerator8\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0manswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from fcon_2 import train_fcon\n",
    "import numpy as np\n",
    "#ac=np.zeros((50,2))\n",
    "# acc=np.zeros((50,5))\n",
    "accc=np.zeros((20,8))\n",
    "# acccc=np.zeros((50,10))\n",
    "for i in range (0,20):\n",
    "    accc[i,:]=train_fcon(8)\n",
    "    if i%5==0:\n",
    "        np.save('Data/accc.npy',accc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80000001, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "        0.69999999, 0.69999999, 0.69999999],\n",
       "       [0.80000001, 0.69999999, 0.80000001, 0.80000001, 0.69999999,\n",
       "        0.80000001, 0.80000001, 0.69999999],\n",
       "       [0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "        0.69999999, 0.69999999, 0.69999999],\n",
       "       [0.80000001, 0.80000001, 0.80000001, 0.80000001, 0.69999999,\n",
       "        0.80000001, 0.69999999, 0.69999999],\n",
       "       [0.69999999, 0.69999999, 0.69999999, 0.69999999, 0.69999999,\n",
       "        0.69999999, 0.69999999, 0.69999999],\n",
       "       [0.69999999, 0.80000001, 0.69999999, 0.80000001, 0.69999999,\n",
       "        0.69999999, 0.69999999, 0.80000001],\n",
       "       [0.80000001, 0.69999999, 0.69999999, 0.80000001, 0.80000001,\n",
       "        0.69999999, 0.80000001, 0.69999999],\n",
       "       [0.80000001, 0.80000001, 0.89999998, 0.80000001, 0.89999998,\n",
       "        0.80000001, 0.80000001, 0.80000001],\n",
       "       [0.69999999, 0.80000001, 0.69999999, 0.69999999, 0.69999999,\n",
       "        0.69999999, 0.69999999, 0.80000001],\n",
       "       [0.69999999, 0.80000001, 0.89999998, 0.89999998, 0.69999999,\n",
       "        0.80000001, 0.80000001, 0.80000001],\n",
       "       [0.69999999, 0.69999999, 0.60000002, 0.60000002, 0.69999999,\n",
       "        0.60000002, 0.69999999, 0.69999999],\n",
       "       [0.80000001, 0.80000001, 0.89999998, 0.80000001, 0.80000001,\n",
       "        0.69999999, 0.80000001, 0.89999998],\n",
       "       [0.80000001, 0.69999999, 0.80000001, 0.80000001, 0.80000001,\n",
       "        0.69999999, 0.69999999, 0.80000001],\n",
       "       [0.80000001, 0.69999999, 0.89999998, 0.80000001, 0.89999998,\n",
       "        0.69999999, 0.69999999, 0.80000001],\n",
       "       [0.89999998, 0.80000001, 0.89999998, 0.89999998, 0.80000001,\n",
       "        0.80000001, 0.69999999, 0.69999999],\n",
       "       [0.80000001, 0.80000001, 0.80000001, 0.80000001, 0.80000001,\n",
       "        0.69999999, 0.89999998, 0.69999999],\n",
       "       [0.80000001, 0.60000002, 0.80000001, 0.80000001, 0.69999999,\n",
       "        0.69999999, 0.80000001, 0.60000002],\n",
       "       [0.80000001, 0.80000001, 0.80000001, 0.80000001, 0.80000001,\n",
       "        0.80000001, 0.69999999, 0.80000001],\n",
       "       [0.80000001, 0.69999999, 0.80000001, 0.69999999, 0.80000001,\n",
       "        0.80000001, 0.89999998, 0.69999999],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorpack.train.config import TrainConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([0., 0., 1., 1., 0., 0., 0., 0.]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "an=np.zeros((50,8))\n",
    "an[0,:]=np.array([0., 0., 1., 1., 0., 0., 0., 0.])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

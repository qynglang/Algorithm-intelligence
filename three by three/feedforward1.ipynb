{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 3, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightt[:,:,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 541937.4375, Train Accuracy= 0.625\n",
      "Step 1, Minibatch Loss= 574581.0000, Valication Accuracy= 0.625\n",
      "Step 10, Minibatch Loss= 292487.8438, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 199546.2344, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 834.3711, Train Accuracy= 0.875\n",
      "Step 20, Minibatch Loss= 76824.3359, Valication Accuracy= 0.625\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 10777.5156, Valication Accuracy= 0.875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75\n",
      "Step 1, Minibatch Loss= 2747411.2500, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 2381254.5000, Valication Accuracy= 0.562\n",
      "Step 10, Minibatch Loss= 1105318.6250, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 1041303.7500, Valication Accuracy= 0.438\n",
      "Step 20, Minibatch Loss= 83596.1094, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 77998.4141, Valication Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 185031.2188, Train Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 148299.9375, Valication Accuracy= 0.562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 1495280.2500, Train Accuracy= 0.625\n",
      "Step 1, Minibatch Loss= 1990658.6250, Valication Accuracy= 0.562\n",
      "Step 10, Minibatch Loss= 288231.1250, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 383802.8125, Valication Accuracy= 0.438\n",
      "Step 20, Minibatch Loss= 87312.1875, Train Accuracy= 0.875\n",
      "Step 20, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 76595.5156, Valication Accuracy= 0.750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 501849.8125, Train Accuracy= 0.625\n",
      "Step 1, Minibatch Loss= 722643.6250, Valication Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 666331.1875, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 534895.4375, Valication Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 505517.4688, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 600790.0625, Valication Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 61344.2344, Train Accuracy= 0.750\n",
      "Step 30, Minibatch Loss= 142115.8438, Valication Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 801166.9375, Train Accuracy= 0.750\n",
      "Step 1, Minibatch Loss= 1138514.2500, Valication Accuracy= 0.438\n",
      "Step 10, Minibatch Loss= 907752.8750, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 582563.5000, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 842118.6250, Train Accuracy= 0.375\n",
      "Step 20, Minibatch Loss= 342285.7500, Valication Accuracy= 0.688\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 46429.1133, Valication Accuracy= 0.938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 2195214.2500, Train Accuracy= 0.125\n",
      "Step 1, Minibatch Loss= 1246186.6250, Valication Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 72124.0781, Train Accuracy= 0.625\n",
      "Step 10, Minibatch Loss= 320614.0000, Valication Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 13462.7930, Train Accuracy= 0.875\n",
      "Step 20, Minibatch Loss= 217218.5312, Valication Accuracy= 0.688\n",
      "Step 30, Minibatch Loss= 49723.1719, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 135922.3125, Valication Accuracy= 0.875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 792776.1250, Train Accuracy= 0.375\n",
      "Step 1, Minibatch Loss= 563226.6875, Valication Accuracy= 0.562\n",
      "Step 10, Minibatch Loss= 105919.7188, Train Accuracy= 0.625\n",
      "Step 10, Minibatch Loss= 82222.6094, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 294153.3438, Train Accuracy= 0.375\n",
      "Step 1, Minibatch Loss= 301096.1562, Valication Accuracy= 0.312\n",
      "Step 10, Minibatch Loss= 181126.5312, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 49158.2500, Valication Accuracy= 0.750\n",
      "Step 20, Minibatch Loss= 418730.5312, Train Accuracy= 0.125\n",
      "Step 20, Minibatch Loss= 332186.8750, Valication Accuracy= 0.312\n",
      "Step 30, Minibatch Loss= 123280.6953, Train Accuracy= 0.750\n",
      "Step 30, Minibatch Loss= 74792.5547, Valication Accuracy= 0.812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.25\n",
      "Step 1, Minibatch Loss= 216828.5938, Train Accuracy= 0.375\n",
      "Step 1, Minibatch Loss= 170006.4688, Valication Accuracy= 0.562\n",
      "Step 10, Minibatch Loss= 196079.7188, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 99249.5391, Valication Accuracy= 0.688\n",
      "Step 20, Minibatch Loss= 27265.3281, Train Accuracy= 0.750\n",
      "Step 20, Minibatch Loss= 27265.3281, Valication Accuracy= 0.750\n",
      "Step 30, Minibatch Loss= 2921.4375, Train Accuracy= 0.750\n",
      "Step 30, Minibatch Loss= 2921.4375, Valication Accuracy= 0.750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 387907.5000, Train Accuracy= 0.375\n",
      "Step 1, Minibatch Loss= 214866.2812, Valication Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 126291.6250, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 98911.7578, Valication Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 16143.5625, Valication Accuracy= 0.938\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 4702.6719, Valication Accuracy= 0.938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 656738.2500, Train Accuracy= 0.250\n",
      "Step 1, Minibatch Loss= 489028.0000, Valication Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 515333.2500, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 564628.8750, Valication Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 815683.3750, Train Accuracy= 0.250\n",
      "Step 20, Minibatch Loss= 547324.7500, Valication Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 9602.2969, Train Accuracy= 0.625\n",
      "Step 30, Minibatch Loss= 12675.9922, Valication Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 2397199.0000, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 1502055.2500, Valication Accuracy= 0.688\n",
      "Step 10, Minibatch Loss= 593747.7500, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 1504376.1250, Valication Accuracy= 0.312\n",
      "Step 20, Minibatch Loss= 216786.1406, Train Accuracy= 0.750\n",
      "Step 20, Minibatch Loss= 313805.0938, Valication Accuracy= 0.688\n",
      "Step 30, Minibatch Loss= 39883.6484, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 101691.2734, Valication Accuracy= 0.812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5\n",
      "Step 1, Minibatch Loss= 972047.6250, Train Accuracy= 0.250\n",
      "Step 1, Minibatch Loss= 898018.8750, Valication Accuracy= 0.312\n",
      "Step 10, Minibatch Loss= 120943.6250, Train Accuracy= 0.875\n",
      "Step 10, Minibatch Loss= 392372.8750, Valication Accuracy= 0.688\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 133890.0000, Valication Accuracy= 0.812\n",
      "Step 30, Minibatch Loss= 61385.9375, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 49377.0938, Valication Accuracy= 0.938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.625\n",
      "Step 1, Minibatch Loss= 222224.5000, Train Accuracy= 0.750\n",
      "Step 1, Minibatch Loss= 594030.4375, Valication Accuracy= 0.438\n",
      "Step 10, Minibatch Loss= 560469.8750, Train Accuracy= 0.625\n",
      "Step 10, Minibatch Loss= 701047.0000, Valication Accuracy= 0.562\n",
      "Step 20, Minibatch Loss= 173021.4062, Train Accuracy= 0.875\n",
      "Step 20, Minibatch Loss= 582334.8750, Valication Accuracy= 0.438\n",
      "Step 30, Minibatch Loss= 32198.5000, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 23672.3906, Valication Accuracy= 0.812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 1996669.2500, Train Accuracy= 0.250\n",
      "Step 1, Minibatch Loss= 1157110.3750, Valication Accuracy= 0.562\n",
      "Step 10, Minibatch Loss= 933029.4375, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 771563.6250, Valication Accuracy= 0.438\n",
      "Step 20, Minibatch Loss= 299962.6875, Train Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 340618.8438, Valication Accuracy= 0.562\n",
      "Step 30, Minibatch Loss= 329006.0312, Train Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 510573.5312, Valication Accuracy= 0.438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.125\n",
      "Step 1, Minibatch Loss= 6537104.0000, Train Accuracy= 0.125\n",
      "Step 1, Minibatch Loss= 3937817.0000, Valication Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, Minibatch Loss= 1254561.0000, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 1036032.2500, Valication Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 595498.6250, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 488519.6562, Valication Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 246242.0625, Train Accuracy= 0.625\n",
      "Step 30, Minibatch Loss= 188090.0625, Valication Accuracy= 0.438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 653971.2500, Train Accuracy= 0.375\n",
      "Step 1, Minibatch Loss= 617026.1250, Valication Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 162344.7344, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 84903.0000, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 392492.5000, Train Accuracy= 0.625\n",
      "Step 1, Minibatch Loss= 385168.0312, Valication Accuracy= 0.562\n",
      "Step 10, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 10, Minibatch Loss= 233858.4844, Valication Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 159078.5000, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 184568.6250, Valication Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 33665.8711, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 60641.5117, Valication Accuracy= 0.938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 223128.5000, Train Accuracy= 0.750\n",
      "Step 1, Minibatch Loss= 283767.2500, Valication Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 73971.5312, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 31231.5918, Valication Accuracy= 0.875\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 57467.6484, Valication Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 109826.9062, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 149167.5000, Valication Accuracy= 0.562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 1851227.7500, Train Accuracy= 0.375\n",
      "Step 1, Minibatch Loss= 810798.0000, Valication Accuracy= 0.625\n",
      "Step 10, Minibatch Loss= 2215462.0000, Train Accuracy= 0.125\n",
      "Step 10, Minibatch Loss= 1718303.2500, Valication Accuracy= 0.375\n",
      "Step 20, Minibatch Loss= 1884503.3750, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 1068844.8750, Valication Accuracy= 0.625\n",
      "Step 30, Minibatch Loss= 780584.1250, Train Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 1068578.3750, Valication Accuracy= 0.375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 164697.3125, Train Accuracy= 0.750\n",
      "Step 1, Minibatch Loss= 53101.8906, Valication Accuracy= 0.812\n",
      "Step 10, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 10, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 43719.1797, Train Accuracy= 0.750\n",
      "Step 20, Minibatch Loss= 12571.5352, Valication Accuracy= 0.938\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 260277.6250, Train Accuracy= 0.625\n",
      "Step 1, Minibatch Loss= 213747.6562, Valication Accuracy= 0.688\n",
      "Step 10, Minibatch Loss= 14642.5156, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 124253.2344, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 1398907.3750, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 1483264.5000, Valication Accuracy= 0.438\n",
      "Step 10, Minibatch Loss= 187424.4688, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 140476.1250, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 390067.9375, Train Accuracy= 0.125\n",
      "Step 20, Minibatch Loss= 249534.8750, Valication Accuracy= 0.438\n",
      "Step 30, Minibatch Loss= 834325.5000, Train Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 671475.8750, Valication Accuracy= 0.562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.125\n",
      "Step 1, Minibatch Loss= 396910.4688, Train Accuracy= 0.250\n",
      "Step 1, Minibatch Loss= 138277.9062, Valication Accuracy= 0.688\n",
      "Step 10, Minibatch Loss= 448083.7812, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 199335.5625, Valication Accuracy= 0.688\n",
      "Step 20, Minibatch Loss= 34631.8438, Train Accuracy= 0.875\n",
      "Step 20, Minibatch Loss= 3080.5000, Valication Accuracy= 0.938\n",
      "Step 30, Minibatch Loss= 152610.9219, Train Accuracy= 0.625\n",
      "Step 30, Minibatch Loss= 61226.4766, Valication Accuracy= 0.812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 178047.2344, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 164393.5625, Valication Accuracy= 0.562\n",
      "Step 10, Minibatch Loss= 227408.9219, Train Accuracy= 0.125\n",
      "Step 10, Minibatch Loss= 76324.8203, Valication Accuracy= 0.562\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 42978.0156, Valication Accuracy= 0.812\n",
      "Step 30, Minibatch Loss= 263348.1250, Train Accuracy= 0.125\n",
      "Step 30, Minibatch Loss= 112190.2891, Valication Accuracy= 0.562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 748928.3125, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 1181152.7500, Valication Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 237478.5781, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 181453.4062, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 6763.3984, Valication Accuracy= 0.938\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 42866.5312, Valication Accuracy= 0.938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 370645.7500, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 514281.9688, Valication Accuracy= 0.438\n",
      "Step 10, Minibatch Loss= 213268.5938, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 106069.6719, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 30400.8281, Train Accuracy= 0.750\n",
      "Step 20, Minibatch Loss= 147030.8750, Valication Accuracy= 0.562\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 1321506.6250, Train Accuracy= 0.625\n",
      "Step 1, Minibatch Loss= 1581671.6250, Valication Accuracy= 0.562\n",
      "Step 10, Minibatch Loss= 258244.4688, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 717807.3750, Valication Accuracy= 0.438\n",
      "Step 20, Minibatch Loss= 265051.6875, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 522993.8125, Valication Accuracy= 0.562\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 142627.5625, Valication Accuracy= 0.750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 200100.9062, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 188716.4531, Valication Accuracy= 0.312\n",
      "Step 10, Minibatch Loss= 232083.7969, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 55605.7148, Valication Accuracy= 0.812\n",
      "Step 20, Minibatch Loss= 39934.4922, Train Accuracy= 0.250\n",
      "Step 20, Minibatch Loss= 27614.9023, Valication Accuracy= 0.375\n",
      "Step 30, Minibatch Loss= 34192.8086, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 342910.2812, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 717760.1875, Valication Accuracy= 0.438\n",
      "Step 10, Minibatch Loss= 453148.0625, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 737382.8750, Valication Accuracy= 0.562\n",
      "Step 20, Minibatch Loss= 503386.2812, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 892185.7500, Valication Accuracy= 0.438\n",
      "Step 30, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 90014.4609, Valication Accuracy= 0.688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 460268.9375, Train Accuracy= 0.500\n",
      "Step 1, Minibatch Loss= 386387.2500, Valication Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 210673.2500, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 484570.6562, Valication Accuracy= 0.438\n",
      "Step 20, Minibatch Loss= 336956.4375, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 271493.3750, Valication Accuracy= 0.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 30, Minibatch Loss= 347552.0000, Train Accuracy= 0.625\n",
      "Step 30, Minibatch Loss= 152224.2656, Valication Accuracy= 0.750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75\n",
      "Step 1, Minibatch Loss= 1223398.7500, Train Accuracy= 0.750\n",
      "Step 1, Minibatch Loss= 3170468.5000, Valication Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 1724767.6250, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 1410134.5000, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 483694.7500, Train Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 829138.7500, Valication Accuracy= 0.375\n",
      "Step 30, Minibatch Loss= 136048.9219, Train Accuracy= 0.625\n",
      "Step 30, Minibatch Loss= 103910.5625, Valication Accuracy= 0.750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 114280.0781, Train Accuracy= 0.750\n",
      "Step 1, Minibatch Loss= 109741.3828, Valication Accuracy= 0.688\n",
      "Step 10, Minibatch Loss= 104621.1094, Train Accuracy= 0.250\n",
      "Step 10, Minibatch Loss= 49472.4453, Valication Accuracy= 0.562\n",
      "Step 20, Minibatch Loss= 1936.2812, Train Accuracy= 0.750\n",
      "Step 20, Minibatch Loss= 3388.4922, Valication Accuracy= 0.562\n",
      "Step 30, Minibatch Loss= 206125.2656, Train Accuracy= 0.375\n",
      "Step 30, Minibatch Loss= 297098.7500, Valication Accuracy= 0.312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 566784.8750, Train Accuracy= 0.375\n",
      "Step 1, Minibatch Loss= 511080.5000, Valication Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 159680.3750, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 186143.1719, Valication Accuracy= 0.562\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 16825.9688, Valication Accuracy= 0.938\n",
      "Step 30, Minibatch Loss= 103802.8750, Train Accuracy= 0.375\n",
      "Step 30, Minibatch Loss= 73749.1250, Valication Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 260841.6719, Train Accuracy= 0.750\n",
      "Step 1, Minibatch Loss= 652104.1875, Valication Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 548517.1250, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 275344.7812, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 28273.3867, Train Accuracy= 0.875\n",
      "Step 20, Minibatch Loss= 70683.4688, Valication Accuracy= 0.688\n",
      "Step 30, Minibatch Loss= 42589.5078, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 0.0000, Valication Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 4947054.5000, Train Accuracy= 0.250\n",
      "Step 1, Minibatch Loss= 4126269.5000, Valication Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 2568154.0000, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 1652293.1250, Valication Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 256169.0625, Train Accuracy= 0.250\n",
      "Step 20, Minibatch Loss= 173878.0000, Valication Accuracy= 0.375\n",
      "Step 30, Minibatch Loss= 52124.7188, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 1514.8438, Valication Accuracy= 0.938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from convo import conv2d,maxpool2d,conv_net\n",
    "import tensorflow as tf\n",
    "from prepare import prep\n",
    "from pic_n import pic3,pic3_2\n",
    "from t import gentest\n",
    "from fcon import train_fcon\n",
    "#from con import train_cov\n",
    "data=np.load('data.npy')\n",
    "weight=np.load('weight.npy')\n",
    "weightt=np.load('weightt.npy')\n",
    "answer=np.load('ans.npy')\n",
    "#M,A=pic3(data[:,:,:,0].reshape(28,28,16),weight,weightt)\n",
    "#T,An=gentest(data[:,:,:,0].reshape(28,28,16),weight,weightt,answer[0])\n",
    "# ll=np.zeros((8,2,36))\n",
    "# pp=np.zeros((8,2,36))\n",
    "for i in range (0,36):\n",
    "    ll[:,:,i],pp[:,:,i]=train_fcon(data[:,:,:,i].reshape(28,28,16),weight[:,:,:,:,i].reshape(5,5,1,3,1),weightt[:,:,:,:,i].reshape(5,5,3,6,1),answer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weight[:,:,:,:,j,i],weightt[:,:,:,:,j,i]=train_cov(data[:,:,j,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ll.npy',ll)\n",
    "np.save('pp.npy',pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.29328617e+05,  5.43219688e+05, -7.39196953e+04,\n",
       "         -1.55233838e+06, -2.82798312e+05, -8.21456328e+04,\n",
       "         -6.70000438e+05,  1.05708488e+06, -1.24271775e+06,\n",
       "         -1.91652638e+06, -2.24753500e+06, -1.32307662e+06,\n",
       "         -3.31085625e+06, -2.53190075e+06,  2.49427300e+06,\n",
       "         -5.88158450e+06, -9.36131562e+05, -1.22530750e+06,\n",
       "         -1.17603800e+06, -4.13497700e+06, -1.41806362e+06,\n",
       "          1.92814406e+05,  9.56101812e+05, -2.85885700e+06,\n",
       "          8.29336500e+05, -5.63380898e+04, -1.56802875e+06,\n",
       "         -1.16252675e+06,  2.01841609e+05,  7.86877938e+05,\n",
       "         -2.24499075e+06, -4.19550969e+05,  7.60893438e+05,\n",
       "          2.68193775e+06, -4.80842062e+05,  3.07247175e+06],\n",
       "        [ 2.42629766e+05,  8.50148438e+05,  1.21815225e+06,\n",
       "         -8.16822312e+05,  2.07090025e+06,  1.14290450e+06,\n",
       "          2.14960266e+05,  6.32695938e+05, -5.24158938e+05,\n",
       "         -7.51033875e+05, -4.05632312e+05, -1.04405706e+06,\n",
       "         -2.99489050e+06, -1.93510900e+06,  1.75871625e+06,\n",
       "         -3.98897950e+06, -6.07016797e+04,  7.71226062e+05,\n",
       "          6.42400500e+05,  4.83875375e+05, -2.09947422e+05,\n",
       "          7.62079562e+05, -1.18240975e+06, -2.48872425e+06,\n",
       "          3.21144550e+06,  5.87288125e+05, -2.31408016e+05,\n",
       "         -3.10544531e+05,  7.88828625e+05,  1.06542475e+06,\n",
       "         -1.29226150e+06, -2.74117250e+05,  1.99343250e+06,\n",
       "          2.88382600e+06, -4.45723562e+05,  3.81186975e+06]],\n",
       "\n",
       "       [[ 1.50094375e+05,  6.19503750e+05, -4.50572562e+05,\n",
       "         -1.78067238e+06, -2.43228350e+06,  8.17377500e+05,\n",
       "         -3.63638594e+05,  1.35654512e+06, -1.56727088e+06,\n",
       "         -1.50982125e+06, -2.48554650e+06, -1.67550050e+06,\n",
       "         -3.54541950e+06, -2.57118425e+06,  2.57144525e+06,\n",
       "         -5.43639050e+06, -1.18623788e+06, -4.86156719e+05,\n",
       "         -9.77453750e+05, -3.99334000e+06, -1.45035312e+06,\n",
       "          9.04665527e+03,  8.68343188e+05, -3.06886200e+06,\n",
       "          8.87871875e+05,  5.51143312e+05, -2.23111125e+06,\n",
       "         -1.27416462e+06, -2.85425812e+05,  8.75679750e+05,\n",
       "         -2.91086875e+06, -6.49537812e+05,  8.53939375e+05,\n",
       "          2.50172175e+06, -3.12206000e+05,  3.17690775e+06],\n",
       "        [ 1.83546391e+05,  9.16515812e+05,  7.65556188e+05,\n",
       "         -9.23692000e+05,  1.98416438e+06,  3.39711975e+06,\n",
       "          1.40835906e+05,  9.51627062e+05, -2.77707375e+05,\n",
       "         -9.07553250e+05, -6.06942438e+05, -1.47715800e+06,\n",
       "         -2.37805475e+06, -1.36487125e+06,  1.36280950e+06,\n",
       "         -4.17092450e+06, -2.42557859e+05,  2.39753656e+05,\n",
       "          6.18184562e+05,  1.03595200e+06, -5.87728875e+05,\n",
       "          1.00424325e+06, -4.76416219e+05, -2.82770925e+06,\n",
       "          3.26655025e+06,  1.10021925e+06, -2.81366781e+05,\n",
       "         -5.24147094e+05,  1.22593550e+06,  1.01196488e+06,\n",
       "         -1.45562562e+06, -1.43800312e+05,  1.78703088e+06,\n",
       "          2.84699400e+06,  1.28931164e+05,  3.27580425e+06]],\n",
       "\n",
       "       [[ 7.66309922e+04,  6.31947500e+05, -7.15067688e+05,\n",
       "         -1.81117388e+06, -4.16095166e+03, -1.77572641e+05,\n",
       "         -5.85693875e+05,  1.10420212e+06, -1.00436219e+06,\n",
       "         -1.70835800e+06, -2.55225550e+06, -1.36011038e+06,\n",
       "         -3.39030225e+06, -2.66214525e+06,  2.38609975e+06,\n",
       "         -5.33951800e+06, -1.06138538e+06, -1.74990600e+06,\n",
       "         -6.91484875e+05, -2.56334975e+06, -1.65409775e+06,\n",
       "          3.07831281e+05,  7.81662312e+05, -2.94259800e+06,\n",
       "          9.44091312e+05,  2.07968438e+05, -1.56893475e+06,\n",
       "         -1.74691425e+06,  2.36577688e+05,  6.58610125e+05,\n",
       "         -2.22937275e+06, -7.78438875e+05,  8.49104938e+05,\n",
       "          2.40952475e+06, -5.09810906e+05,  2.56667700e+06],\n",
       "        [ 2.36005016e+05,  9.17799438e+05,  9.70129938e+05,\n",
       "         -9.48878500e+05,  2.11200550e+06,  3.08033275e+06,\n",
       "          3.30697281e+05,  1.16876938e+06, -7.30389375e+05,\n",
       "         -8.05289875e+05, -5.78795000e+05, -1.81590312e+06,\n",
       "         -2.70417550e+06, -2.10236825e+06,  2.02475850e+06,\n",
       "         -4.23001450e+06, -1.35557609e+05,  4.89944406e+05,\n",
       "          6.41759875e+05, -5.24145625e+05, -3.08371625e+05,\n",
       "          9.62265688e+05, -9.05411500e+05, -2.33335525e+06,\n",
       "          3.33062050e+06,  8.02936688e+05, -3.51048375e+05,\n",
       "         -9.65397109e+04,  8.26305938e+05,  1.12959750e+06,\n",
       "         -1.35093100e+06, -2.78053625e+05,  1.80595838e+06,\n",
       "          3.08507250e+06, -7.02126016e+04,  3.18112575e+06]],\n",
       "\n",
       "       [[ 1.84618688e+05,  1.10321588e+06, -6.49065039e+04,\n",
       "         -1.56527562e+06, -1.50335350e+06,  1.39453734e+05,\n",
       "         -6.14272938e+05,  1.32625312e+06, -1.35761838e+06,\n",
       "         -1.63576300e+06, -2.55961450e+06, -1.71709512e+06,\n",
       "         -3.17595225e+06, -2.44317650e+06,  2.51035825e+06,\n",
       "         -5.54267650e+06, -1.20992750e+06, -1.31448912e+06,\n",
       "         -1.02624519e+06, -3.88757625e+06, -1.29340275e+06,\n",
       "          1.80547656e+05,  1.08701162e+06, -2.73853700e+06,\n",
       "          6.95319250e+05, -3.60604656e+05, -2.16425225e+06,\n",
       "         -1.33963700e+06,  9.44830703e+04,  7.11426562e+05,\n",
       "         -1.84666812e+06, -5.10590031e+05,  9.44515562e+05,\n",
       "          2.37658550e+06, -6.12962500e+05,  2.56837975e+06],\n",
       "        [ 2.82702469e+05,  1.34299838e+06,  1.11155575e+06,\n",
       "         -7.92513438e+05,  2.51136300e+06,  2.49263325e+06,\n",
       "          3.77723938e+05,  1.12397600e+06, -5.71195750e+05,\n",
       "         -7.05955250e+05, -2.71706219e+05, -1.36215225e+06,\n",
       "         -2.58437050e+06, -1.91628725e+06,  2.11763325e+06,\n",
       "         -3.99891350e+06, -1.04932555e+05,  6.29197688e+05,\n",
       "          9.98667188e+05,  5.72580125e+05, -3.11993344e+05,\n",
       "          1.01639219e+06, -9.76024250e+05, -2.42936025e+06,\n",
       "          3.62904250e+06,  9.70645625e+05, -4.75303250e+05,\n",
       "         -8.27163359e+04,  8.03856000e+05,  9.33678375e+05,\n",
       "         -2.00820162e+06, -2.78575812e+05,  1.70664250e+06,\n",
       "          2.93807325e+06,  5.50920117e+03,  3.32071175e+06]],\n",
       "\n",
       "       [[ 4.11926938e+05,  5.35886750e+05, -6.58514000e+05,\n",
       "         -1.98774088e+06, -6.02021188e+05, -4.47893125e+05,\n",
       "         -5.02921406e+05,  1.51693925e+06, -1.43730612e+06,\n",
       "         -1.75032400e+06, -2.62405450e+06, -1.27790088e+06,\n",
       "         -3.58075575e+06, -2.87211300e+06,  2.55659925e+06,\n",
       "         -5.21462400e+06, -1.09995762e+06,  5.10727344e+03,\n",
       "         -1.43012200e+06, -3.54969125e+06, -1.76652662e+06,\n",
       "          3.43496156e+05,  7.91449500e+05, -3.02821150e+06,\n",
       "          1.54835812e+06, -1.43911844e+05, -1.85436012e+06,\n",
       "         -1.45946950e+06,  1.98882469e+05,  9.25759125e+05,\n",
       "         -2.46415225e+06, -3.76412406e+05,  9.00491562e+05,\n",
       "          2.69997000e+06, -4.27828406e+05,  2.85757575e+06],\n",
       "        [ 1.07584898e+05,  9.88351312e+05,  1.28489588e+06,\n",
       "         -8.41957000e+05,  1.73573650e+06,  2.79974325e+06,\n",
       "          1.80152094e+05,  1.04786400e+06, -4.85838875e+05,\n",
       "         -8.21174375e+05, -5.97518625e+05, -1.38150500e+06,\n",
       "         -2.59225675e+06, -1.61673925e+06,  1.84038650e+06,\n",
       "         -4.67620950e+06, -1.97256359e+05,  4.99017531e+05,\n",
       "          1.07852975e+06,  7.46930750e+05, -5.60651625e+05,\n",
       "          7.67834188e+05, -7.48353750e+05, -2.59314250e+06,\n",
       "          3.33927600e+06,  6.91426750e+05, -5.81086000e+05,\n",
       "         -5.76497109e+04,  7.30505688e+05,  9.90302375e+05,\n",
       "         -1.74306788e+06, -1.64860375e+05,  2.00200250e+06,\n",
       "          3.03580550e+06,  4.25997422e+04,  3.41585575e+06]],\n",
       "\n",
       "       [[ 2.46757125e+05,  7.05387875e+05, -1.42954500e+05,\n",
       "         -1.80281262e+06,  1.07249141e+05, -1.80201700e+06,\n",
       "         -7.30445875e+05,  1.28510825e+06, -1.15068150e+06,\n",
       "         -1.53778312e+06, -2.47215675e+06, -1.45261975e+06,\n",
       "         -3.38790275e+06, -2.50828250e+06,  2.74827175e+06,\n",
       "         -6.56421800e+06, -9.47203438e+05, -3.78071219e+05,\n",
       "         -1.40320888e+06, -3.73684225e+06, -1.52242475e+06,\n",
       "          2.11323156e+05,  8.54568062e+05, -3.05033600e+06,\n",
       "          1.15212188e+06,  1.11089188e+05, -2.37777500e+06,\n",
       "         -1.72202962e+06,  1.91003812e+05,  3.22060094e+05,\n",
       "         -2.40900825e+06, -5.41872375e+05,  7.15861312e+05,\n",
       "          2.52331050e+06, -4.07128812e+05,  2.70898950e+06],\n",
       "        [ 2.81371719e+05,  1.05605700e+06,  9.91007188e+05,\n",
       "         -8.79623875e+05,  1.24362188e+06,  4.25577700e+06,\n",
       "          3.21372844e+05,  9.22342625e+05, -4.78435062e+05,\n",
       "         -7.48664938e+05, -2.83347062e+05, -1.25158700e+06,\n",
       "         -2.55901850e+06, -1.55396412e+06,  1.17387075e+06,\n",
       "         -4.53382750e+06, -1.80693609e+05,  4.18213781e+05,\n",
       "          6.65419875e+05,  7.58783250e+05, -6.50630938e+05,\n",
       "          9.11979438e+05, -7.56257375e+05, -2.44403950e+06,\n",
       "          3.38287500e+06,  1.00319294e+06, -4.76930000e+05,\n",
       "          1.60146281e+05,  7.47104312e+05,  1.08284550e+06,\n",
       "         -1.25507588e+06,  6.12008828e+04,  1.92040825e+06,\n",
       "          2.90523550e+06, -1.40206750e+05,  3.54252075e+06]],\n",
       "\n",
       "       [[-7.21179453e+04,  6.23624500e+05, -2.55294344e+05,\n",
       "         -1.81118162e+06, -2.03145300e+06, -1.25818125e+06,\n",
       "         -5.13021562e+05,  1.50679500e+06, -1.10940700e+06,\n",
       "         -1.76793812e+06, -2.69468100e+06, -1.36551375e+06,\n",
       "         -3.00007475e+06, -3.14505650e+06,  2.38719075e+06,\n",
       "         -4.88179300e+06, -1.02197419e+06, -1.77975775e+06,\n",
       "         -1.16831388e+06, -3.34715400e+06, -1.91927425e+06,\n",
       "          7.17953027e+03,  8.07251438e+05, -3.03925900e+06,\n",
       "          1.24311725e+06,  2.12333812e+05, -2.02527438e+06,\n",
       "         -1.49882938e+06,  1.64277016e+05,  6.30488125e+05,\n",
       "         -2.36150000e+06,  4.19946602e+04,  9.04138312e+05,\n",
       "          2.68163000e+06, -5.59784938e+05,  2.69268475e+06],\n",
       "        [ 4.36483406e+05,  8.97969438e+05,  2.47998844e+05,\n",
       "         -7.78501500e+05,  1.38081038e+06,  2.90051275e+06,\n",
       "          2.94470781e+05,  7.42924250e+05, -6.54586938e+05,\n",
       "         -9.12707750e+05, -4.04669031e+05, -1.44460225e+06,\n",
       "         -3.42997300e+06, -2.34638075e+06,  1.30224875e+06,\n",
       "         -4.09776050e+06, -2.53611172e+05,  6.09157688e+05,\n",
       "          6.00090188e+05, -4.95142383e+04, -4.38623844e+05,\n",
       "          1.15155900e+06, -7.80008875e+05, -2.32972475e+06,\n",
       "          3.05841300e+06,  7.34860312e+05, -3.32628219e+05,\n",
       "         -1.56469156e+05,  7.69905312e+05,  1.27379288e+06,\n",
       "         -1.53088188e+06,  2.24498188e+05,  1.67838138e+06,\n",
       "          3.24231550e+06,  6.20776172e+04,  2.73501875e+06]],\n",
       "\n",
       "       [[ 1.31792688e+05,  5.63645438e+05, -1.03346258e+05,\n",
       "         -1.82447938e+06, -1.89851125e+06, -3.67052625e+05,\n",
       "         -4.99838562e+05,  1.50275400e+06, -1.12141025e+06,\n",
       "         -1.75130212e+06, -2.61245600e+06, -1.34458062e+06,\n",
       "         -2.91811750e+06, -2.56074775e+06,  2.73600550e+06,\n",
       "         -5.39012150e+06, -1.09094375e+06, -1.41762350e+06,\n",
       "         -1.42375075e+06, -3.61879575e+06, -1.59015475e+06,\n",
       "          8.19089062e+04,  1.08255275e+06, -3.05497075e+06,\n",
       "          1.09284238e+06,  6.74626562e+04, -1.66578262e+06,\n",
       "         -1.47875488e+06, -4.14811094e+04,  6.98818312e+05,\n",
       "         -2.18146125e+06, -6.24197688e+05,  7.48134250e+05,\n",
       "          2.68671000e+06, -5.82759750e+05,  2.79535225e+06],\n",
       "        [ 2.65798156e+05,  1.04006981e+06,  9.07531562e+05,\n",
       "         -9.77610625e+05,  1.52457125e+06,  1.88937975e+06,\n",
       "         -2.43688516e+04,  1.05592650e+06, -7.25577312e+05,\n",
       "         -8.66844688e+05, -1.78589492e+04, -1.27673075e+06,\n",
       "         -3.15597975e+06, -1.64842825e+06,  1.24033225e+06,\n",
       "         -3.99903450e+06, -2.85891531e+05,  4.90017156e+05,\n",
       "          7.20719625e+05,  7.37152875e+05, -5.27871375e+05,\n",
       "          6.51439750e+05, -9.95968500e+05, -2.24530150e+06,\n",
       "          3.37814200e+06,  7.61189000e+05, -3.69781500e+05,\n",
       "          1.26057852e+05,  9.20560812e+05,  1.06358100e+06,\n",
       "         -1.79148362e+06, -1.94158312e+05,  1.84967788e+06,\n",
       "          2.94482600e+06,  3.66772891e+04,  2.77360725e+06]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2, 36)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[-1., -1., -1., -1., -1., -1., -1., -1.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[-1., -1., -1., -1., -1.,  0., -1., -1.]],\n",
       "\n",
       "       [[-1.,  0., -1.,  0., -1., -1., -1., -1.]],\n",
       "\n",
       "       [[-1., -1., -1., -1., -1., -1., -1.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[-1., -1., -1., -1.,  0., -1., -1., -1.]],\n",
       "\n",
       "       [[-1., -1., -1., -1., -1., -1., -1., -1.]],\n",
       "\n",
       "       [[-1., -1.,  0., -1., -1., -1.,  0., -1.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[-1.,  0.,  0., -1., -1.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0., -1.,  0., -1.]],\n",
       "\n",
       "       [[ 0., -1.,  0.,  0.,  0.,  0.,  0., -1.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0., -1.,  0., -1., -1.,  0., -1., -1.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.zeros((36,1,8))\n",
    "for j in range (0,36):\n",
    "    for i in range (0,8):\n",
    "        a[j,0,i]=1/(np.exp(-pp[i,0,j])+1)-1/(np.exp(-pp[i,1,j])+1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [-1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1722ce4e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b=a[:,:,:].reshape(36,8).copy()\n",
    "b[:,]\n",
    "plt.imshow(a[:,:,:].reshape(36,8)+np.ones((36,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0. -1.  0.]] 7\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 1\n",
      "[[-1. -1. -1. -1. -1. -1. -1. -1.]] 2\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 7\n",
      "[[-1. -1. -1. -1. -1.  0. -1. -1.]] 6\n",
      "[[-1.  0. -1.  0. -1. -1. -1. -1.]] 3\n",
      "[[-1. -1. -1. -1. -1. -1. -1.  0.]] 4\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 0\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 6\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 5\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 0\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 1\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 2\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 3\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 2\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 6\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 7\n",
      "[[-1. -1. -1. -1.  0. -1. -1. -1.]] 5\n",
      "[[-1. -1. -1. -1. -1. -1. -1. -1.]] 4\n",
      "[[-1. -1.  0. -1. -1. -1.  0. -1.]] 3\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 0\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 1\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1.]] 4\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 4\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 6\n",
      "[[-1.  0.  0. -1. -1.  0.  0.  0.]] 5\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 7\n",
      "[[ 0.  0.  0.  0.  0. -1.  0. -1.]] 1\n",
      "[[ 0. -1.  0.  0.  0.  0.  0. -1.]] 0\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 4\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 1\n",
      "[[ 0.  0.  0.  0.  0. -1.  0.  0.]] 3\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 0\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 5\n",
      "[[ 0. -1.  0. -1. -1.  0. -1. -1.]] 2\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]] 1\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,36):\n",
    "    print (a[i,:,:],answer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=np.array([7,1,2,7,6,3,4,0,6,5,0,1,2,3,2,6,7,5,4,3,0,1,4,4,6,5,7,1,0,4,1,3,0,5,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ans.npy',answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from scipy.signal import convolve2d\n",
    "# def prep(pic,weight1,weight2):\n",
    "#     n=weight1.shape[4]\n",
    "#     M=np.zeros((n,pic.shape[2],294))\n",
    "#     with tf.Session() as sess:\n",
    "#         p=np.zeros((pic.shape[2],784))\n",
    "#         for i in range(0,pic.shape[2]):\n",
    "#             p[i,:]=pic[:,:,i].reshape(784,)\n",
    "#         p=tf.reshape(p, shape=[-1, 28, 28, 1])\n",
    "#         for k in range (0,n):\n",
    "#             I=conv2d(p, weight1[:,:,:,:,k].reshape(5,5,1,3))\n",
    "#             I=maxpool2d(I,k=2)\n",
    "#             I1 = conv2d(I, weight2[:,:,:,:,k].reshape(5,5,3,6))\n",
    "#         # Max Pooling (down-sampling)\n",
    "#             I1 = maxpool2d(I1, k=2)\n",
    "#             I1=tf.reshape(I1,[-1,294]).eval()\n",
    "#         M[k,:,:]=I1\n",
    "#     return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        ...,\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ]],\n",
       "\n",
       "       [[   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        ...,\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ]],\n",
       "\n",
       "       [[   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        ...,\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        ...,\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ]],\n",
       "\n",
       "       [[   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        ...,\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ,    0.        , ...,\n",
       "            0.        ,    0.        ,    0.        ]],\n",
       "\n",
       "       [[1214.55992122, 7726.51021154,    0.        , ...,\n",
       "         5803.62044333,  426.20250281,    0.        ],\n",
       "        [1202.08346432, 7749.68730643,    0.        , ...,\n",
       "         5803.62044333,  426.20250281,    0.        ],\n",
       "        [1157.10014045, 7789.47360876,    0.        , ...,\n",
       "         5803.62044333,  426.20250281,    0.        ],\n",
       "        ...,\n",
       "        [ 762.86510796, 6768.92195511,    0.        , ...,\n",
       "         5812.83698988,  650.76920473,    0.        ],\n",
       "        [1078.91915495, 7743.32982379,    0.        , ...,\n",
       "         5791.29317512,  378.63737679,    0.        ],\n",
       "        [   0.        , 7144.84436419,    0.        , ...,\n",
       "         5052.92919718, 1003.13888799,    0.        ]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fullnet(fc1, weights, biases, dropout):\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 30\n",
    "batch_size = 8\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 294*3*2 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 1+1 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n",
    "weights = {\n",
    "\n",
    "    'wd1': tf.Variable(tf.random_normal([294*3*2, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    \n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "# Construct model\n",
    "logits = fullnet(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

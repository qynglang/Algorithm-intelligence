{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('/afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/questions.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data=data.fillna(0)\n",
    "np.save('data.npy',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>size1</th>\n",
       "      <th>size2</th>\n",
       "      <th>size3</th>\n",
       "      <th>shape1</th>\n",
       "      <th>shape2</th>\n",
       "      <th>shape3</th>\n",
       "      <th>shape_other</th>\n",
       "      <th>position1</th>\n",
       "      <th>position2</th>\n",
       "      <th>position3</th>\n",
       "      <th>position_y_1</th>\n",
       "      <th>position_y_2</th>\n",
       "      <th>position_y_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  Unnamed: 1  size1  size2  size3  shape1  shape2  shape3  \\\n",
       "0       1.0         1.0    1.0    0.0    0.0     1.0     0.0     0.0   \n",
       "1       1.0         2.0    1.0    0.0    0.0     1.0     0.0     0.0   \n",
       "2       1.0         3.0    1.0    0.0    0.0     1.0     0.0     0.0   \n",
       "3       1.0         4.0    1.0    2.0    0.0     2.0     0.0     0.0   \n",
       "4       1.0         5.0    1.0    2.0    0.0     2.0     0.0     0.0   \n",
       "\n",
       "   shape_other  position1  position2  position3  position_y_1  position_y_2  \\\n",
       "0          0.0        1.0        0.0        0.0           1.0           0.0   \n",
       "1          0.0        1.0        0.0        0.0           1.0           0.0   \n",
       "2          0.0        1.0        0.0        0.0           1.0           0.0   \n",
       "3          0.0        2.0        0.0        0.0           1.0           0.0   \n",
       "4          0.0        2.0        0.0        0.0           1.0           0.0   \n",
       "\n",
       "   position_y_3  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.load('data.npy')\n",
    "q=data[data[:,0]==1]\n",
    "q=q[:,2:]\n",
    "q[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>size1</th>\n",
       "      <th>size2</th>\n",
       "      <th>size3</th>\n",
       "      <th>shape1</th>\n",
       "      <th>shape2</th>\n",
       "      <th>shape3</th>\n",
       "      <th>shape_other</th>\n",
       "      <th>position1</th>\n",
       "      <th>position2</th>\n",
       "      <th>position3</th>\n",
       "      <th>position_y_1</th>\n",
       "      <th>position_y_2</th>\n",
       "      <th>position_y_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question  Unnamed: 1  size1  size2  size3  shape1  shape2  shape3  \\\n",
       "0        1.0         1.0    1.0    0.0    0.0     1.0     0.0     0.0   \n",
       "1        1.0         2.0    1.0    0.0    0.0     1.0     0.0     0.0   \n",
       "2        1.0         3.0    1.0    0.0    0.0     1.0     0.0     0.0   \n",
       "3        1.0         4.0    1.0    2.0    0.0     2.0     0.0     0.0   \n",
       "4        1.0         5.0    1.0    2.0    0.0     2.0     0.0     0.0   \n",
       "5        1.0         6.0    1.0    2.0    0.0     2.0     0.0     0.0   \n",
       "6        1.0         7.0    1.0    2.0    3.0     3.0     0.0     0.0   \n",
       "7        1.0         8.0    1.0    2.0    3.0     3.0     0.0     0.0   \n",
       "8        1.0         9.0    0.0    2.5    3.0     2.0     0.0     0.0   \n",
       "9        1.0        10.0    1.0    2.0    3.0     5.0     0.0     0.0   \n",
       "10       1.0        11.0    1.0    2.0    0.0     2.0     0.0     0.0   \n",
       "11       1.0        12.0    1.0    0.0    0.0     1.0     0.0     0.0   \n",
       "12       1.0        13.0    1.0    0.0    3.0     2.0     0.0     0.0   \n",
       "13       1.0        14.0    0.0    0.0    3.0     1.0     0.0     0.0   \n",
       "14       1.0        15.0    0.0    2.0    0.0     1.0     0.0     0.0   \n",
       "15       1.0        16.0    1.0    2.0    3.0     3.0     0.0     0.0   \n",
       "\n",
       "    shape_other  position1  position2  position3  position_y_1  position_y_2  \\\n",
       "0           0.0        1.0        0.0        0.0           1.0           0.0   \n",
       "1           0.0        1.0        0.0        0.0           1.0           0.0   \n",
       "2           0.0        1.0        0.0        0.0           1.0           0.0   \n",
       "3           0.0        2.0        0.0        0.0           1.0           0.0   \n",
       "4           0.0        2.0        0.0        0.0           1.0           0.0   \n",
       "5           0.0        2.0        0.0        0.0           1.0           0.0   \n",
       "6           0.0        3.0        0.0        0.0           1.0           0.0   \n",
       "7           0.0        3.0        0.0        0.0           1.0           0.0   \n",
       "8           0.0        2.0        0.0        0.0           1.0           0.0   \n",
       "9           0.0        5.0        0.0        0.0           1.0           0.0   \n",
       "10          0.0        2.0        0.0        0.0           1.0           0.0   \n",
       "11          0.0        1.0        0.0        0.0           1.0           0.0   \n",
       "12          0.0        2.0        0.0        0.0           1.0           0.0   \n",
       "13          0.0        1.0        0.0        0.0           1.0           0.0   \n",
       "14          0.0        1.0        0.0        0.0           1.0           0.0   \n",
       "15          0.0        3.0        0.0        0.0           1.0           0.0   \n",
       "\n",
       "    position_y_3  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "5            0.0  \n",
       "6            0.0  \n",
       "7            0.0  \n",
       "8            0.0  \n",
       "9            0.0  \n",
       "10           0.0  \n",
       "11           0.0  \n",
       "12           0.0  \n",
       "13           0.0  \n",
       "14           0.0  \n",
       "15           0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "np.random.randint(2,size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_r import gen_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,a=gen_r(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_r import gen_r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1. ,  0.5,  0. , -1. ,  0. ,  0. ,  0. , -1. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [-1. ,  0.5,  0. , -1. ,  0. ,  0. ,  0. , -1. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ,  2. ,  0. ,  0. ,  0. ,  2. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ,  2. ,  0. ,  0. ,  0. ,  2. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. ,  0. , -3. , -1. ,  0. ,  0. ,  0. , -1. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. ,  0. , -3. , -1. ,  0. ,  0. ,  0. , -1. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. , -2. , -3. , -2. ,  0. ,  0. ,  0. , -2. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. , -2. , -3. , -2. ,  0. ,  0. ,  0. , -2. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. , -2. ,  0. , -1. ,  0. ,  0. ,  0. , -1. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. , -2. ,  0. , -1. ,  0. ,  0. ,  0. , -1. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [-1. , -2. ,  0. , -2. ,  0. ,  0. ,  0. , -2. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [-1. , -2. ,  0. , -2. ,  0. ,  0. ,  0. , -2. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [-1. ,  0. , -3. , -2. ,  0. ,  0. ,  0. , -2. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [-1. ,  0. , -3. , -2. ,  0. ,  0. ,  0. , -2. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ],\n",
       "        [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "          0. ,  0. ]]), array([[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_r_test(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_r import gen_r_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t,a=gen_r_ref(1)\n",
    "t[t!=0].shape[0]>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcon_rep import train_fcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0730 19:34:55.424888 139944149321536 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:29: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0730 19:34:55.445516 139944149321536 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:34: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0730 19:34:55.473867 139944149321536 deprecation.py:506] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:11: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0730 19:34:55.487723 139944149321536 deprecation.py:323] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:50: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0730 19:34:55.513957 139944149321536 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:51: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0730 19:34:55.649319 139944149321536 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:60: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0730 19:34:55.651127 139944149321536 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:63: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 60.9584, Train Accuracy= 0.086\n",
      "Step 2, Minibatch Loss= 53.7653, Train Accuracy= 0.172\n",
      "Step 3, Minibatch Loss= 59.3163, Train Accuracy= 0.078\n",
      "Step 4, Minibatch Loss= 53.5966, Train Accuracy= 0.156\n",
      "Step 5, Minibatch Loss= 56.5039, Train Accuracy= 0.141\n",
      "Step 6, Minibatch Loss= 44.7340, Train Accuracy= 0.203\n",
      "Step 7, Minibatch Loss= 51.6570, Train Accuracy= 0.086\n",
      "Step 8, Minibatch Loss= 54.7764, Train Accuracy= 0.141\n",
      "Step 9, Minibatch Loss= 51.8812, Train Accuracy= 0.109\n",
      "Step 10, Minibatch Loss= 42.2508, Train Accuracy= 0.117\n",
      "Step 11, Minibatch Loss= 51.0835, Train Accuracy= 0.133\n",
      "Step 12, Minibatch Loss= 51.4897, Train Accuracy= 0.133\n",
      "Step 13, Minibatch Loss= 37.0440, Train Accuracy= 0.133\n",
      "Step 14, Minibatch Loss= 39.9110, Train Accuracy= 0.125\n",
      "Step 15, Minibatch Loss= 41.3103, Train Accuracy= 0.141\n",
      "Step 16, Minibatch Loss= 38.3279, Train Accuracy= 0.117\n",
      "Step 17, Minibatch Loss= 40.3058, Train Accuracy= 0.117\n",
      "Step 18, Minibatch Loss= 37.0739, Train Accuracy= 0.070\n",
      "Step 19, Minibatch Loss= 36.6861, Train Accuracy= 0.117\n",
      "Step 20, Minibatch Loss= 33.1971, Train Accuracy= 0.156\n",
      "Step 21, Minibatch Loss= 30.6221, Train Accuracy= 0.156\n",
      "Step 22, Minibatch Loss= 35.5229, Train Accuracy= 0.141\n",
      "Step 23, Minibatch Loss= 29.6086, Train Accuracy= 0.141\n",
      "Step 24, Minibatch Loss= 27.5984, Train Accuracy= 0.156\n",
      "Step 25, Minibatch Loss= 27.4158, Train Accuracy= 0.148\n",
      "Step 26, Minibatch Loss= 28.9157, Train Accuracy= 0.117\n",
      "Step 27, Minibatch Loss= 27.1027, Train Accuracy= 0.164\n",
      "Step 28, Minibatch Loss= 24.8772, Train Accuracy= 0.133\n",
      "Step 29, Minibatch Loss= 25.6021, Train Accuracy= 0.148\n",
      "Step 30, Minibatch Loss= 23.7492, Train Accuracy= 0.117\n",
      "Step 31, Minibatch Loss= 20.5553, Train Accuracy= 0.141\n",
      "Step 32, Minibatch Loss= 20.9475, Train Accuracy= 0.148\n",
      "Step 33, Minibatch Loss= 22.9363, Train Accuracy= 0.078\n",
      "Step 34, Minibatch Loss= 22.1774, Train Accuracy= 0.117\n",
      "Step 35, Minibatch Loss= 18.1795, Train Accuracy= 0.125\n",
      "Step 36, Minibatch Loss= 20.2549, Train Accuracy= 0.109\n",
      "Step 37, Minibatch Loss= 18.7549, Train Accuracy= 0.125\n",
      "Step 38, Minibatch Loss= 19.1594, Train Accuracy= 0.141\n",
      "Step 39, Minibatch Loss= 15.7284, Train Accuracy= 0.125\n",
      "Step 40, Minibatch Loss= 17.9939, Train Accuracy= 0.094\n",
      "Step 41, Minibatch Loss= 16.5030, Train Accuracy= 0.133\n",
      "Step 42, Minibatch Loss= 13.3871, Train Accuracy= 0.188\n",
      "Step 43, Minibatch Loss= 13.5792, Train Accuracy= 0.164\n",
      "Step 44, Minibatch Loss= 15.2687, Train Accuracy= 0.133\n",
      "Step 45, Minibatch Loss= 13.1507, Train Accuracy= 0.148\n",
      "Step 46, Minibatch Loss= 14.2707, Train Accuracy= 0.117\n",
      "Step 47, Minibatch Loss= 14.6968, Train Accuracy= 0.156\n",
      "Step 48, Minibatch Loss= 12.1966, Train Accuracy= 0.125\n",
      "Step 49, Minibatch Loss= 13.0193, Train Accuracy= 0.148\n",
      "Step 50, Minibatch Loss= 12.0563, Train Accuracy= 0.133\n",
      "Step 51, Minibatch Loss= 11.8192, Train Accuracy= 0.141\n",
      "Step 52, Minibatch Loss= 10.1009, Train Accuracy= 0.195\n",
      "Step 53, Minibatch Loss= 10.8826, Train Accuracy= 0.156\n",
      "Step 54, Minibatch Loss= 10.6692, Train Accuracy= 0.156\n",
      "Step 55, Minibatch Loss= 11.4195, Train Accuracy= 0.164\n",
      "Step 56, Minibatch Loss= 9.4314, Train Accuracy= 0.141\n",
      "Step 57, Minibatch Loss= 8.2107, Train Accuracy= 0.195\n",
      "Step 58, Minibatch Loss= 9.0707, Train Accuracy= 0.141\n",
      "Step 59, Minibatch Loss= 7.9659, Train Accuracy= 0.180\n",
      "Step 60, Minibatch Loss= 7.9132, Train Accuracy= 0.180\n",
      "Step 61, Minibatch Loss= 8.2297, Train Accuracy= 0.195\n",
      "Step 62, Minibatch Loss= 7.8041, Train Accuracy= 0.125\n",
      "Step 63, Minibatch Loss= 8.2962, Train Accuracy= 0.125\n",
      "Step 64, Minibatch Loss= 7.6524, Train Accuracy= 0.141\n",
      "Step 65, Minibatch Loss= 6.4403, Train Accuracy= 0.156\n",
      "Step 66, Minibatch Loss= 7.3849, Train Accuracy= 0.125\n",
      "Step 67, Minibatch Loss= 6.3564, Train Accuracy= 0.211\n",
      "Step 68, Minibatch Loss= 6.5995, Train Accuracy= 0.078\n",
      "Step 69, Minibatch Loss= 6.0223, Train Accuracy= 0.156\n",
      "Step 70, Minibatch Loss= 6.7129, Train Accuracy= 0.117\n",
      "Step 71, Minibatch Loss= 6.0971, Train Accuracy= 0.188\n",
      "Step 72, Minibatch Loss= 6.3583, Train Accuracy= 0.180\n",
      "Step 73, Minibatch Loss= 5.6739, Train Accuracy= 0.125\n",
      "Step 74, Minibatch Loss= 5.5216, Train Accuracy= 0.180\n",
      "Step 75, Minibatch Loss= 5.4701, Train Accuracy= 0.133\n",
      "Step 76, Minibatch Loss= 5.0610, Train Accuracy= 0.195\n",
      "Step 77, Minibatch Loss= 4.8741, Train Accuracy= 0.195\n",
      "Step 78, Minibatch Loss= 5.3275, Train Accuracy= 0.117\n",
      "Step 79, Minibatch Loss= 5.1834, Train Accuracy= 0.133\n",
      "Step 80, Minibatch Loss= 5.3531, Train Accuracy= 0.109\n",
      "Step 81, Minibatch Loss= 4.9081, Train Accuracy= 0.125\n",
      "Step 82, Minibatch Loss= 4.7328, Train Accuracy= 0.156\n",
      "Step 83, Minibatch Loss= 4.6130, Train Accuracy= 0.133\n",
      "Step 84, Minibatch Loss= 4.6149, Train Accuracy= 0.117\n",
      "Step 85, Minibatch Loss= 4.3808, Train Accuracy= 0.125\n",
      "Step 86, Minibatch Loss= 4.5567, Train Accuracy= 0.156\n",
      "Step 87, Minibatch Loss= 4.3829, Train Accuracy= 0.086\n",
      "Step 88, Minibatch Loss= 4.0522, Train Accuracy= 0.164\n",
      "Step 89, Minibatch Loss= 4.0603, Train Accuracy= 0.164\n",
      "Step 90, Minibatch Loss= 4.4535, Train Accuracy= 0.078\n",
      "Step 91, Minibatch Loss= 3.5822, Train Accuracy= 0.141\n",
      "Step 92, Minibatch Loss= 3.7557, Train Accuracy= 0.156\n",
      "Step 93, Minibatch Loss= 4.1587, Train Accuracy= 0.109\n",
      "Step 94, Minibatch Loss= 4.0247, Train Accuracy= 0.117\n",
      "Step 95, Minibatch Loss= 3.8138, Train Accuracy= 0.141\n",
      "Step 96, Minibatch Loss= 3.5863, Train Accuracy= 0.156\n",
      "Step 97, Minibatch Loss= 3.7693, Train Accuracy= 0.156\n",
      "Step 98, Minibatch Loss= 3.9692, Train Accuracy= 0.148\n",
      "Step 99, Minibatch Loss= 3.5880, Train Accuracy= 0.148\n",
      "Step 100, Minibatch Loss= 3.5609, Train Accuracy= 0.094\n",
      "Step 101, Minibatch Loss= 3.6721, Train Accuracy= 0.141\n",
      "Step 102, Minibatch Loss= 3.6668, Train Accuracy= 0.125\n",
      "Step 103, Minibatch Loss= 3.5698, Train Accuracy= 0.156\n",
      "Step 104, Minibatch Loss= 3.9920, Train Accuracy= 0.070\n",
      "Step 105, Minibatch Loss= 3.7696, Train Accuracy= 0.102\n",
      "Step 106, Minibatch Loss= 3.9371, Train Accuracy= 0.117\n",
      "Step 107, Minibatch Loss= 3.6046, Train Accuracy= 0.133\n",
      "Step 108, Minibatch Loss= 3.6711, Train Accuracy= 0.125\n",
      "Step 109, Minibatch Loss= 3.6388, Train Accuracy= 0.117\n",
      "Step 110, Minibatch Loss= 3.1207, Train Accuracy= 0.164\n",
      "Step 111, Minibatch Loss= 3.2778, Train Accuracy= 0.133\n",
      "Step 112, Minibatch Loss= 2.7269, Train Accuracy= 0.203\n",
      "Step 113, Minibatch Loss= 3.3329, Train Accuracy= 0.133\n",
      "Step 114, Minibatch Loss= 3.0627, Train Accuracy= 0.133\n",
      "Step 115, Minibatch Loss= 3.1149, Train Accuracy= 0.133\n",
      "Step 116, Minibatch Loss= 3.0062, Train Accuracy= 0.117\n",
      "Step 117, Minibatch Loss= 2.7963, Train Accuracy= 0.141\n",
      "Step 118, Minibatch Loss= 2.5386, Train Accuracy= 0.141\n",
      "Step 119, Minibatch Loss= 2.7697, Train Accuracy= 0.156\n",
      "Step 120, Minibatch Loss= 2.6195, Train Accuracy= 0.188\n",
      "Step 121, Minibatch Loss= 2.5227, Train Accuracy= 0.125\n",
      "Step 122, Minibatch Loss= 2.4450, Train Accuracy= 0.148\n",
      "Step 123, Minibatch Loss= 2.5436, Train Accuracy= 0.148\n",
      "Step 124, Minibatch Loss= 2.3428, Train Accuracy= 0.125\n",
      "Step 125, Minibatch Loss= 2.6346, Train Accuracy= 0.070\n",
      "Step 126, Minibatch Loss= 2.3913, Train Accuracy= 0.117\n",
      "Step 127, Minibatch Loss= 2.2384, Train Accuracy= 0.109\n",
      "Step 128, Minibatch Loss= 2.2386, Train Accuracy= 0.188\n",
      "Step 129, Minibatch Loss= 2.1120, Train Accuracy= 0.164\n",
      "Step 130, Minibatch Loss= 2.2783, Train Accuracy= 0.148\n",
      "Step 131, Minibatch Loss= 2.2878, Train Accuracy= 0.148\n",
      "Step 132, Minibatch Loss= 2.1222, Train Accuracy= 0.102\n",
      "Step 133, Minibatch Loss= 2.4066, Train Accuracy= 0.070\n",
      "Step 134, Minibatch Loss= 2.5104, Train Accuracy= 0.125\n",
      "Step 135, Minibatch Loss= 2.3809, Train Accuracy= 0.117\n",
      "Step 136, Minibatch Loss= 2.2006, Train Accuracy= 0.109\n",
      "Step 137, Minibatch Loss= 2.3885, Train Accuracy= 0.148\n",
      "Step 138, Minibatch Loss= 2.1225, Train Accuracy= 0.156\n",
      "Step 139, Minibatch Loss= 2.1774, Train Accuracy= 0.070\n",
      "Step 140, Minibatch Loss= 2.2188, Train Accuracy= 0.109\n",
      "Step 141, Minibatch Loss= 1.9439, Train Accuracy= 0.125\n",
      "Step 142, Minibatch Loss= 1.9010, Train Accuracy= 0.125\n",
      "Step 143, Minibatch Loss= 1.8897, Train Accuracy= 0.164\n",
      "Step 144, Minibatch Loss= 1.9988, Train Accuracy= 0.133\n",
      "Step 145, Minibatch Loss= 1.9844, Train Accuracy= 0.102\n",
      "Step 146, Minibatch Loss= 1.8761, Train Accuracy= 0.094\n",
      "Step 147, Minibatch Loss= 1.8267, Train Accuracy= 0.109\n",
      "Step 148, Minibatch Loss= 1.7464, Train Accuracy= 0.125\n",
      "Step 149, Minibatch Loss= 1.8394, Train Accuracy= 0.156\n",
      "Step 150, Minibatch Loss= 1.7926, Train Accuracy= 0.180\n",
      "Step 151, Minibatch Loss= 1.6687, Train Accuracy= 0.258\n",
      "Step 152, Minibatch Loss= 1.5722, Train Accuracy= 0.273\n",
      "Step 153, Minibatch Loss= 1.4452, Train Accuracy= 0.195\n",
      "Step 154, Minibatch Loss= 1.3636, Train Accuracy= 0.273\n",
      "Step 155, Minibatch Loss= 1.5769, Train Accuracy= 0.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 156, Minibatch Loss= 1.4911, Train Accuracy= 0.227\n",
      "Step 157, Minibatch Loss= 1.5879, Train Accuracy= 0.242\n",
      "Step 158, Minibatch Loss= 1.4332, Train Accuracy= 0.305\n",
      "Step 159, Minibatch Loss= 1.3679, Train Accuracy= 0.328\n",
      "Step 160, Minibatch Loss= 1.6098, Train Accuracy= 0.188\n",
      "Step 161, Minibatch Loss= 1.6433, Train Accuracy= 0.219\n",
      "Step 162, Minibatch Loss= 1.4079, Train Accuracy= 0.266\n",
      "Step 163, Minibatch Loss= 1.5147, Train Accuracy= 0.297\n",
      "Step 164, Minibatch Loss= 1.3680, Train Accuracy= 0.234\n",
      "Step 165, Minibatch Loss= 1.7363, Train Accuracy= 0.266\n",
      "Step 166, Minibatch Loss= 1.4201, Train Accuracy= 0.250\n",
      "Step 167, Minibatch Loss= 1.4099, Train Accuracy= 0.289\n",
      "Step 168, Minibatch Loss= 1.4383, Train Accuracy= 0.273\n",
      "Step 169, Minibatch Loss= 1.4147, Train Accuracy= 0.250\n",
      "Step 170, Minibatch Loss= 1.6281, Train Accuracy= 0.305\n",
      "Step 171, Minibatch Loss= 1.5053, Train Accuracy= 0.273\n",
      "Step 172, Minibatch Loss= 1.7548, Train Accuracy= 0.180\n",
      "Step 173, Minibatch Loss= 1.6914, Train Accuracy= 0.281\n",
      "Step 174, Minibatch Loss= 1.7722, Train Accuracy= 0.281\n",
      "Step 175, Minibatch Loss= 1.9018, Train Accuracy= 0.195\n",
      "Step 176, Minibatch Loss= 1.7355, Train Accuracy= 0.312\n",
      "Step 177, Minibatch Loss= 2.1776, Train Accuracy= 0.234\n",
      "Step 178, Minibatch Loss= 2.3248, Train Accuracy= 0.250\n",
      "Step 179, Minibatch Loss= 2.1182, Train Accuracy= 0.273\n",
      "Step 180, Minibatch Loss= 2.3590, Train Accuracy= 0.234\n",
      "Step 181, Minibatch Loss= 2.4677, Train Accuracy= 0.273\n",
      "Step 182, Minibatch Loss= 2.2977, Train Accuracy= 0.352\n",
      "Step 183, Minibatch Loss= 2.4737, Train Accuracy= 0.281\n",
      "Step 184, Minibatch Loss= 2.5585, Train Accuracy= 0.258\n",
      "Step 185, Minibatch Loss= 2.6188, Train Accuracy= 0.258\n",
      "Step 186, Minibatch Loss= 2.8724, Train Accuracy= 0.250\n",
      "Step 187, Minibatch Loss= 2.9250, Train Accuracy= 0.242\n",
      "Step 188, Minibatch Loss= 2.7247, Train Accuracy= 0.258\n",
      "Step 189, Minibatch Loss= 2.7456, Train Accuracy= 0.266\n",
      "Step 190, Minibatch Loss= 2.7422, Train Accuracy= 0.227\n",
      "Step 191, Minibatch Loss= 2.6591, Train Accuracy= 0.211\n",
      "Step 192, Minibatch Loss= 2.3376, Train Accuracy= 0.172\n",
      "Step 193, Minibatch Loss= 2.4944, Train Accuracy= 0.211\n",
      "Step 194, Minibatch Loss= 1.9915, Train Accuracy= 0.258\n",
      "Step 195, Minibatch Loss= 1.7548, Train Accuracy= 0.375\n",
      "Step 196, Minibatch Loss= 1.9407, Train Accuracy= 0.297\n",
      "Step 197, Minibatch Loss= 2.2044, Train Accuracy= 0.258\n",
      "Step 198, Minibatch Loss= 1.9466, Train Accuracy= 0.359\n",
      "Step 199, Minibatch Loss= 1.7139, Train Accuracy= 0.305\n",
      "Step 200, Minibatch Loss= 1.7140, Train Accuracy= 0.336\n",
      "Step 201, Minibatch Loss= 1.9133, Train Accuracy= 0.289\n",
      "Step 202, Minibatch Loss= 2.2825, Train Accuracy= 0.227\n",
      "Step 203, Minibatch Loss= 1.8791, Train Accuracy= 0.281\n",
      "Step 204, Minibatch Loss= 1.8843, Train Accuracy= 0.250\n",
      "Step 205, Minibatch Loss= 2.0319, Train Accuracy= 0.281\n",
      "Step 206, Minibatch Loss= 2.0441, Train Accuracy= 0.242\n",
      "Step 207, Minibatch Loss= 2.0949, Train Accuracy= 0.227\n",
      "Step 208, Minibatch Loss= 2.0144, Train Accuracy= 0.227\n",
      "Step 209, Minibatch Loss= 1.8743, Train Accuracy= 0.289\n",
      "Step 210, Minibatch Loss= 1.7416, Train Accuracy= 0.250\n",
      "Step 211, Minibatch Loss= 1.8143, Train Accuracy= 0.227\n",
      "Step 212, Minibatch Loss= 1.4726, Train Accuracy= 0.320\n",
      "Step 213, Minibatch Loss= 1.5798, Train Accuracy= 0.250\n",
      "Step 214, Minibatch Loss= 1.7856, Train Accuracy= 0.266\n",
      "Step 215, Minibatch Loss= 1.6158, Train Accuracy= 0.312\n",
      "Step 216, Minibatch Loss= 1.6658, Train Accuracy= 0.297\n",
      "Step 217, Minibatch Loss= 1.5066, Train Accuracy= 0.352\n",
      "Step 218, Minibatch Loss= 2.0063, Train Accuracy= 0.203\n",
      "Step 219, Minibatch Loss= 1.3897, Train Accuracy= 0.289\n",
      "Step 220, Minibatch Loss= 1.7357, Train Accuracy= 0.242\n",
      "Step 221, Minibatch Loss= 1.5879, Train Accuracy= 0.281\n",
      "Step 222, Minibatch Loss= 1.4811, Train Accuracy= 0.258\n",
      "Step 223, Minibatch Loss= 1.3697, Train Accuracy= 0.297\n",
      "Step 224, Minibatch Loss= 1.6277, Train Accuracy= 0.227\n",
      "Step 225, Minibatch Loss= 1.6583, Train Accuracy= 0.219\n",
      "Step 226, Minibatch Loss= 1.5360, Train Accuracy= 0.227\n",
      "Step 227, Minibatch Loss= 1.5548, Train Accuracy= 0.234\n",
      "Step 228, Minibatch Loss= 1.4171, Train Accuracy= 0.273\n",
      "Step 229, Minibatch Loss= 1.5672, Train Accuracy= 0.289\n",
      "Step 230, Minibatch Loss= 1.4011, Train Accuracy= 0.297\n",
      "Step 231, Minibatch Loss= 1.5821, Train Accuracy= 0.172\n",
      "Step 232, Minibatch Loss= 1.3302, Train Accuracy= 0.281\n",
      "Step 233, Minibatch Loss= 1.2730, Train Accuracy= 0.289\n",
      "Step 234, Minibatch Loss= 1.2393, Train Accuracy= 0.289\n",
      "Step 235, Minibatch Loss= 1.3504, Train Accuracy= 0.242\n",
      "Step 236, Minibatch Loss= 1.2459, Train Accuracy= 0.227\n",
      "Step 237, Minibatch Loss= 1.3920, Train Accuracy= 0.289\n",
      "Step 238, Minibatch Loss= 1.4510, Train Accuracy= 0.227\n",
      "Step 239, Minibatch Loss= 1.3705, Train Accuracy= 0.328\n",
      "Step 240, Minibatch Loss= 1.3916, Train Accuracy= 0.289\n",
      "Step 241, Minibatch Loss= 1.3415, Train Accuracy= 0.297\n",
      "Step 242, Minibatch Loss= 1.2713, Train Accuracy= 0.250\n",
      "Step 243, Minibatch Loss= 1.4738, Train Accuracy= 0.211\n",
      "Step 244, Minibatch Loss= 1.4013, Train Accuracy= 0.211\n",
      "Step 245, Minibatch Loss= 1.4836, Train Accuracy= 0.242\n",
      "Step 246, Minibatch Loss= 1.3018, Train Accuracy= 0.297\n",
      "Step 247, Minibatch Loss= 1.4573, Train Accuracy= 0.242\n",
      "Step 248, Minibatch Loss= 1.5054, Train Accuracy= 0.180\n",
      "Step 249, Minibatch Loss= 1.5787, Train Accuracy= 0.164\n",
      "Step 250, Minibatch Loss= 1.4208, Train Accuracy= 0.242\n",
      "Step 251, Minibatch Loss= 1.3273, Train Accuracy= 0.289\n",
      "Step 252, Minibatch Loss= 1.2267, Train Accuracy= 0.273\n",
      "Step 253, Minibatch Loss= 1.1199, Train Accuracy= 0.344\n",
      "Step 254, Minibatch Loss= 1.4896, Train Accuracy= 0.258\n",
      "Step 255, Minibatch Loss= 1.5505, Train Accuracy= 0.195\n",
      "Step 256, Minibatch Loss= 1.4574, Train Accuracy= 0.227\n",
      "Step 257, Minibatch Loss= 1.4792, Train Accuracy= 0.211\n",
      "Step 258, Minibatch Loss= 1.5575, Train Accuracy= 0.219\n",
      "Step 259, Minibatch Loss= 1.5035, Train Accuracy= 0.250\n",
      "Step 260, Minibatch Loss= 1.6880, Train Accuracy= 0.242\n",
      "Step 261, Minibatch Loss= 1.4783, Train Accuracy= 0.242\n",
      "Step 262, Minibatch Loss= 1.4658, Train Accuracy= 0.289\n",
      "Step 263, Minibatch Loss= 1.8385, Train Accuracy= 0.297\n",
      "Step 264, Minibatch Loss= 2.0868, Train Accuracy= 0.203\n",
      "Step 265, Minibatch Loss= 2.0894, Train Accuracy= 0.234\n",
      "Step 266, Minibatch Loss= 2.1508, Train Accuracy= 0.258\n",
      "Step 267, Minibatch Loss= 1.8067, Train Accuracy= 0.289\n",
      "Step 268, Minibatch Loss= 1.8772, Train Accuracy= 0.242\n",
      "Step 269, Minibatch Loss= 2.2467, Train Accuracy= 0.203\n",
      "Step 270, Minibatch Loss= 1.9855, Train Accuracy= 0.289\n",
      "Step 271, Minibatch Loss= 2.3427, Train Accuracy= 0.195\n",
      "Step 272, Minibatch Loss= 1.9496, Train Accuracy= 0.289\n",
      "Step 273, Minibatch Loss= 2.0988, Train Accuracy= 0.211\n",
      "Step 274, Minibatch Loss= 1.8675, Train Accuracy= 0.242\n",
      "Step 275, Minibatch Loss= 1.8994, Train Accuracy= 0.227\n",
      "Step 276, Minibatch Loss= 1.6269, Train Accuracy= 0.234\n",
      "Step 277, Minibatch Loss= 1.7845, Train Accuracy= 0.242\n",
      "Step 278, Minibatch Loss= 1.4903, Train Accuracy= 0.312\n",
      "Step 279, Minibatch Loss= 1.9536, Train Accuracy= 0.219\n",
      "Step 280, Minibatch Loss= 1.9481, Train Accuracy= 0.219\n",
      "Step 281, Minibatch Loss= 1.7334, Train Accuracy= 0.234\n",
      "Step 282, Minibatch Loss= 1.7213, Train Accuracy= 0.312\n",
      "Step 283, Minibatch Loss= 1.8202, Train Accuracy= 0.289\n",
      "Step 284, Minibatch Loss= 1.9826, Train Accuracy= 0.289\n",
      "Step 285, Minibatch Loss= 1.9860, Train Accuracy= 0.297\n",
      "Step 286, Minibatch Loss= 1.9657, Train Accuracy= 0.352\n",
      "Step 287, Minibatch Loss= 2.3128, Train Accuracy= 0.258\n",
      "Step 288, Minibatch Loss= 2.4379, Train Accuracy= 0.297\n",
      "Step 289, Minibatch Loss= 2.2614, Train Accuracy= 0.273\n",
      "Step 290, Minibatch Loss= 2.9521, Train Accuracy= 0.234\n",
      "Step 291, Minibatch Loss= 2.5018, Train Accuracy= 0.227\n",
      "Step 292, Minibatch Loss= 2.4041, Train Accuracy= 0.383\n",
      "Step 293, Minibatch Loss= 2.6658, Train Accuracy= 0.250\n",
      "Step 294, Minibatch Loss= 2.4870, Train Accuracy= 0.305\n",
      "Step 295, Minibatch Loss= 2.8075, Train Accuracy= 0.289\n",
      "Step 296, Minibatch Loss= 2.8994, Train Accuracy= 0.203\n",
      "Step 297, Minibatch Loss= 2.6264, Train Accuracy= 0.250\n",
      "Step 298, Minibatch Loss= 2.2670, Train Accuracy= 0.227\n",
      "Step 299, Minibatch Loss= 2.3959, Train Accuracy= 0.281\n",
      "Step 300, Minibatch Loss= 2.2363, Train Accuracy= 0.266\n",
      "Step 301, Minibatch Loss= 2.5057, Train Accuracy= 0.227\n",
      "Step 302, Minibatch Loss= 2.1069, Train Accuracy= 0.273\n",
      "Step 303, Minibatch Loss= 1.8471, Train Accuracy= 0.305\n",
      "Step 304, Minibatch Loss= 2.0931, Train Accuracy= 0.281\n",
      "Step 305, Minibatch Loss= 2.1000, Train Accuracy= 0.195\n",
      "Step 306, Minibatch Loss= 1.8246, Train Accuracy= 0.195\n",
      "Step 307, Minibatch Loss= 2.1102, Train Accuracy= 0.242\n",
      "Step 308, Minibatch Loss= 1.6563, Train Accuracy= 0.219\n",
      "Step 309, Minibatch Loss= 1.5669, Train Accuracy= 0.203\n",
      "Step 310, Minibatch Loss= 1.4047, Train Accuracy= 0.305\n",
      "Step 311, Minibatch Loss= 1.4053, Train Accuracy= 0.250\n",
      "Step 312, Minibatch Loss= 1.5563, Train Accuracy= 0.203\n",
      "Step 313, Minibatch Loss= 1.3475, Train Accuracy= 0.266\n",
      "Step 314, Minibatch Loss= 1.2432, Train Accuracy= 0.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 315, Minibatch Loss= 1.4103, Train Accuracy= 0.250\n",
      "Step 316, Minibatch Loss= 1.6154, Train Accuracy= 0.219\n",
      "Step 317, Minibatch Loss= 1.4802, Train Accuracy= 0.250\n",
      "Step 318, Minibatch Loss= 1.3848, Train Accuracy= 0.250\n",
      "Step 319, Minibatch Loss= 1.4290, Train Accuracy= 0.273\n",
      "Step 320, Minibatch Loss= 1.4671, Train Accuracy= 0.250\n",
      "Step 321, Minibatch Loss= 1.5671, Train Accuracy= 0.227\n",
      "Step 322, Minibatch Loss= 1.7234, Train Accuracy= 0.188\n",
      "Step 323, Minibatch Loss= 1.2450, Train Accuracy= 0.391\n",
      "Step 324, Minibatch Loss= 1.6010, Train Accuracy= 0.211\n",
      "Step 325, Minibatch Loss= 1.6844, Train Accuracy= 0.266\n",
      "Step 326, Minibatch Loss= 1.4202, Train Accuracy= 0.336\n",
      "Step 327, Minibatch Loss= 1.5691, Train Accuracy= 0.273\n",
      "Step 328, Minibatch Loss= 1.7849, Train Accuracy= 0.203\n",
      "Step 329, Minibatch Loss= 1.6535, Train Accuracy= 0.281\n",
      "Step 330, Minibatch Loss= 1.6664, Train Accuracy= 0.273\n",
      "Step 331, Minibatch Loss= 1.7514, Train Accuracy= 0.266\n",
      "Step 332, Minibatch Loss= 2.0625, Train Accuracy= 0.188\n",
      "Step 333, Minibatch Loss= 1.8507, Train Accuracy= 0.266\n",
      "Step 334, Minibatch Loss= 1.8855, Train Accuracy= 0.242\n",
      "Step 335, Minibatch Loss= 1.8528, Train Accuracy= 0.266\n",
      "Step 336, Minibatch Loss= 1.9239, Train Accuracy= 0.156\n",
      "Step 337, Minibatch Loss= 1.7017, Train Accuracy= 0.203\n",
      "Step 338, Minibatch Loss= 1.6099, Train Accuracy= 0.297\n",
      "Step 339, Minibatch Loss= 1.5775, Train Accuracy= 0.227\n",
      "Step 340, Minibatch Loss= 1.7086, Train Accuracy= 0.219\n",
      "Step 341, Minibatch Loss= 1.6081, Train Accuracy= 0.188\n",
      "Step 342, Minibatch Loss= 1.4964, Train Accuracy= 0.297\n",
      "Step 343, Minibatch Loss= 1.4351, Train Accuracy= 0.234\n",
      "Step 344, Minibatch Loss= 1.4941, Train Accuracy= 0.258\n",
      "Step 345, Minibatch Loss= 1.6753, Train Accuracy= 0.289\n",
      "Step 346, Minibatch Loss= 1.8958, Train Accuracy= 0.219\n",
      "Step 347, Minibatch Loss= 1.8032, Train Accuracy= 0.242\n",
      "Step 348, Minibatch Loss= 1.6931, Train Accuracy= 0.297\n",
      "Step 349, Minibatch Loss= 1.8163, Train Accuracy= 0.227\n",
      "Step 350, Minibatch Loss= 1.5839, Train Accuracy= 0.258\n",
      "Step 351, Minibatch Loss= 1.5310, Train Accuracy= 0.273\n",
      "Step 352, Minibatch Loss= 1.7417, Train Accuracy= 0.219\n",
      "Step 353, Minibatch Loss= 1.5700, Train Accuracy= 0.266\n",
      "Step 354, Minibatch Loss= 1.5417, Train Accuracy= 0.250\n",
      "Step 355, Minibatch Loss= 1.7271, Train Accuracy= 0.203\n",
      "Step 356, Minibatch Loss= 1.4957, Train Accuracy= 0.234\n",
      "Step 357, Minibatch Loss= 1.3915, Train Accuracy= 0.250\n",
      "Step 358, Minibatch Loss= 1.4468, Train Accuracy= 0.312\n",
      "Step 359, Minibatch Loss= 1.4550, Train Accuracy= 0.281\n",
      "Step 360, Minibatch Loss= 1.5244, Train Accuracy= 0.242\n",
      "Step 361, Minibatch Loss= 1.6197, Train Accuracy= 0.203\n",
      "Step 362, Minibatch Loss= 1.5252, Train Accuracy= 0.242\n",
      "Step 363, Minibatch Loss= 1.5472, Train Accuracy= 0.211\n",
      "Step 364, Minibatch Loss= 1.3089, Train Accuracy= 0.305\n",
      "Step 365, Minibatch Loss= 1.7543, Train Accuracy= 0.219\n",
      "Step 366, Minibatch Loss= 1.5449, Train Accuracy= 0.273\n",
      "Step 367, Minibatch Loss= 1.6586, Train Accuracy= 0.219\n",
      "Step 368, Minibatch Loss= 1.5678, Train Accuracy= 0.258\n",
      "Step 369, Minibatch Loss= 1.6291, Train Accuracy= 0.273\n",
      "Step 370, Minibatch Loss= 1.5655, Train Accuracy= 0.258\n",
      "Step 371, Minibatch Loss= 1.4976, Train Accuracy= 0.258\n",
      "Step 372, Minibatch Loss= 1.5034, Train Accuracy= 0.258\n",
      "Step 373, Minibatch Loss= 1.5334, Train Accuracy= 0.273\n",
      "Step 374, Minibatch Loss= 1.5311, Train Accuracy= 0.234\n",
      "Step 375, Minibatch Loss= 1.6452, Train Accuracy= 0.258\n",
      "Step 376, Minibatch Loss= 1.6740, Train Accuracy= 0.273\n",
      "Step 377, Minibatch Loss= 1.9748, Train Accuracy= 0.219\n",
      "Step 378, Minibatch Loss= 2.0936, Train Accuracy= 0.234\n",
      "Step 379, Minibatch Loss= 1.6711, Train Accuracy= 0.281\n",
      "Step 380, Minibatch Loss= 1.7639, Train Accuracy= 0.320\n",
      "Step 381, Minibatch Loss= 1.8290, Train Accuracy= 0.312\n",
      "Step 382, Minibatch Loss= 1.9122, Train Accuracy= 0.289\n",
      "Step 383, Minibatch Loss= 2.3059, Train Accuracy= 0.242\n",
      "Step 384, Minibatch Loss= 2.3228, Train Accuracy= 0.281\n",
      "Step 385, Minibatch Loss= 2.3527, Train Accuracy= 0.258\n",
      "Step 386, Minibatch Loss= 2.2572, Train Accuracy= 0.297\n",
      "Step 387, Minibatch Loss= 2.4143, Train Accuracy= 0.250\n",
      "Step 388, Minibatch Loss= 2.4389, Train Accuracy= 0.258\n",
      "Step 389, Minibatch Loss= 2.3892, Train Accuracy= 0.281\n",
      "Step 390, Minibatch Loss= 2.4604, Train Accuracy= 0.195\n",
      "Step 391, Minibatch Loss= 2.7084, Train Accuracy= 0.203\n",
      "Step 392, Minibatch Loss= 2.1020, Train Accuracy= 0.273\n",
      "Step 393, Minibatch Loss= 2.1845, Train Accuracy= 0.273\n",
      "Step 394, Minibatch Loss= 2.2731, Train Accuracy= 0.172\n",
      "Step 395, Minibatch Loss= 2.0325, Train Accuracy= 0.242\n",
      "Step 396, Minibatch Loss= 2.1562, Train Accuracy= 0.273\n",
      "Step 397, Minibatch Loss= 1.8289, Train Accuracy= 0.273\n",
      "Step 398, Minibatch Loss= 2.2095, Train Accuracy= 0.289\n",
      "Step 399, Minibatch Loss= 2.2762, Train Accuracy= 0.258\n",
      "Step 400, Minibatch Loss= 1.8451, Train Accuracy= 0.297\n",
      "Step 401, Minibatch Loss= 2.6120, Train Accuracy= 0.242\n",
      "Step 402, Minibatch Loss= 2.8056, Train Accuracy= 0.289\n",
      "Step 403, Minibatch Loss= 3.0346, Train Accuracy= 0.211\n",
      "Step 404, Minibatch Loss= 2.7721, Train Accuracy= 0.180\n",
      "Step 405, Minibatch Loss= 2.7896, Train Accuracy= 0.250\n",
      "Step 406, Minibatch Loss= 2.8006, Train Accuracy= 0.203\n",
      "Step 407, Minibatch Loss= 2.3764, Train Accuracy= 0.211\n",
      "Step 408, Minibatch Loss= 2.2122, Train Accuracy= 0.258\n",
      "Step 409, Minibatch Loss= 1.7721, Train Accuracy= 0.258\n",
      "Step 410, Minibatch Loss= 1.8603, Train Accuracy= 0.180\n",
      "Step 411, Minibatch Loss= 1.6731, Train Accuracy= 0.273\n",
      "Step 412, Minibatch Loss= 1.3213, Train Accuracy= 0.305\n",
      "Step 413, Minibatch Loss= 1.5317, Train Accuracy= 0.258\n",
      "Step 414, Minibatch Loss= 1.2490, Train Accuracy= 0.375\n",
      "Step 415, Minibatch Loss= 1.4030, Train Accuracy= 0.320\n",
      "Step 416, Minibatch Loss= 1.2645, Train Accuracy= 0.320\n",
      "Step 417, Minibatch Loss= 1.3924, Train Accuracy= 0.227\n",
      "Step 418, Minibatch Loss= 1.3549, Train Accuracy= 0.281\n",
      "Step 419, Minibatch Loss= 1.3586, Train Accuracy= 0.266\n",
      "Step 420, Minibatch Loss= 1.5768, Train Accuracy= 0.211\n",
      "Step 421, Minibatch Loss= 1.2814, Train Accuracy= 0.281\n",
      "Step 422, Minibatch Loss= 1.3838, Train Accuracy= 0.227\n",
      "Step 423, Minibatch Loss= 1.3880, Train Accuracy= 0.273\n",
      "Step 424, Minibatch Loss= 1.4020, Train Accuracy= 0.289\n",
      "Step 425, Minibatch Loss= 1.6445, Train Accuracy= 0.211\n",
      "Step 426, Minibatch Loss= 1.3941, Train Accuracy= 0.273\n",
      "Step 427, Minibatch Loss= 1.3354, Train Accuracy= 0.297\n",
      "Step 428, Minibatch Loss= 1.4114, Train Accuracy= 0.219\n",
      "Step 429, Minibatch Loss= 1.4821, Train Accuracy= 0.336\n",
      "Step 430, Minibatch Loss= 1.6554, Train Accuracy= 0.227\n",
      "Step 431, Minibatch Loss= 1.5119, Train Accuracy= 0.250\n",
      "Step 432, Minibatch Loss= 1.7425, Train Accuracy= 0.211\n",
      "Step 433, Minibatch Loss= 1.4541, Train Accuracy= 0.266\n",
      "Step 434, Minibatch Loss= 1.5394, Train Accuracy= 0.367\n",
      "Step 435, Minibatch Loss= 1.8545, Train Accuracy= 0.289\n",
      "Step 436, Minibatch Loss= 2.0901, Train Accuracy= 0.289\n",
      "Step 437, Minibatch Loss= 2.3530, Train Accuracy= 0.234\n",
      "Step 438, Minibatch Loss= 1.9621, Train Accuracy= 0.336\n",
      "Step 439, Minibatch Loss= 2.1421, Train Accuracy= 0.258\n",
      "Step 440, Minibatch Loss= 2.4010, Train Accuracy= 0.219\n",
      "Step 441, Minibatch Loss= 2.3936, Train Accuracy= 0.234\n",
      "Step 442, Minibatch Loss= 2.1045, Train Accuracy= 0.273\n",
      "Step 443, Minibatch Loss= 2.1417, Train Accuracy= 0.281\n",
      "Step 444, Minibatch Loss= 2.0481, Train Accuracy= 0.273\n",
      "Step 445, Minibatch Loss= 2.1608, Train Accuracy= 0.195\n",
      "Step 446, Minibatch Loss= 1.7624, Train Accuracy= 0.312\n",
      "Step 447, Minibatch Loss= 1.8165, Train Accuracy= 0.188\n",
      "Step 448, Minibatch Loss= 1.5047, Train Accuracy= 0.312\n",
      "Step 449, Minibatch Loss= 1.5317, Train Accuracy= 0.273\n",
      "Step 450, Minibatch Loss= 1.3272, Train Accuracy= 0.305\n",
      "Step 451, Minibatch Loss= 1.4530, Train Accuracy= 0.211\n",
      "Step 452, Minibatch Loss= 1.4114, Train Accuracy= 0.281\n",
      "Step 453, Minibatch Loss= 1.2248, Train Accuracy= 0.188\n",
      "Step 454, Minibatch Loss= 1.3804, Train Accuracy= 0.258\n",
      "Step 455, Minibatch Loss= 1.2249, Train Accuracy= 0.219\n",
      "Step 456, Minibatch Loss= 1.2651, Train Accuracy= 0.203\n",
      "Step 457, Minibatch Loss= 1.2224, Train Accuracy= 0.227\n",
      "Step 458, Minibatch Loss= 1.1870, Train Accuracy= 0.188\n",
      "Step 459, Minibatch Loss= 1.1494, Train Accuracy= 0.258\n",
      "Step 460, Minibatch Loss= 1.2482, Train Accuracy= 0.273\n",
      "Step 461, Minibatch Loss= 1.3101, Train Accuracy= 0.250\n",
      "Step 462, Minibatch Loss= 1.1967, Train Accuracy= 0.266\n",
      "Step 463, Minibatch Loss= 1.4161, Train Accuracy= 0.266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 464, Minibatch Loss= 1.3916, Train Accuracy= 0.281\n",
      "Step 465, Minibatch Loss= 1.7268, Train Accuracy= 0.266\n",
      "Step 466, Minibatch Loss= 1.6223, Train Accuracy= 0.219\n",
      "Step 467, Minibatch Loss= 1.5525, Train Accuracy= 0.242\n",
      "Step 468, Minibatch Loss= 1.8523, Train Accuracy= 0.234\n",
      "Step 469, Minibatch Loss= 1.5246, Train Accuracy= 0.281\n",
      "Step 470, Minibatch Loss= 1.6160, Train Accuracy= 0.266\n",
      "Step 471, Minibatch Loss= 1.6019, Train Accuracy= 0.227\n",
      "Step 472, Minibatch Loss= 1.3629, Train Accuracy= 0.250\n",
      "Step 473, Minibatch Loss= 1.3064, Train Accuracy= 0.258\n",
      "Step 474, Minibatch Loss= 1.3653, Train Accuracy= 0.297\n",
      "Step 475, Minibatch Loss= 1.4051, Train Accuracy= 0.273\n",
      "Step 476, Minibatch Loss= 1.5149, Train Accuracy= 0.203\n",
      "Step 477, Minibatch Loss= 1.5244, Train Accuracy= 0.305\n",
      "Step 478, Minibatch Loss= 1.4469, Train Accuracy= 0.289\n",
      "Step 479, Minibatch Loss= 1.7579, Train Accuracy= 0.227\n",
      "Step 480, Minibatch Loss= 1.5721, Train Accuracy= 0.289\n",
      "Step 481, Minibatch Loss= 1.6620, Train Accuracy= 0.305\n",
      "Step 482, Minibatch Loss= 1.4925, Train Accuracy= 0.266\n",
      "Step 483, Minibatch Loss= 1.5432, Train Accuracy= 0.273\n",
      "Step 484, Minibatch Loss= 1.8095, Train Accuracy= 0.266\n",
      "Step 485, Minibatch Loss= 1.8228, Train Accuracy= 0.219\n",
      "Step 486, Minibatch Loss= 1.8280, Train Accuracy= 0.242\n",
      "Step 487, Minibatch Loss= 1.6409, Train Accuracy= 0.289\n",
      "Step 488, Minibatch Loss= 1.6917, Train Accuracy= 0.273\n",
      "Step 489, Minibatch Loss= 1.5711, Train Accuracy= 0.281\n",
      "Step 490, Minibatch Loss= 1.6269, Train Accuracy= 0.258\n",
      "Step 491, Minibatch Loss= 1.6263, Train Accuracy= 0.250\n",
      "Step 492, Minibatch Loss= 1.6368, Train Accuracy= 0.211\n",
      "Step 493, Minibatch Loss= 1.5668, Train Accuracy= 0.211\n",
      "Step 494, Minibatch Loss= 1.4406, Train Accuracy= 0.180\n",
      "Step 495, Minibatch Loss= 1.2330, Train Accuracy= 0.258\n",
      "Step 496, Minibatch Loss= 1.2415, Train Accuracy= 0.211\n",
      "Step 497, Minibatch Loss= 1.2555, Train Accuracy= 0.219\n",
      "Step 498, Minibatch Loss= 1.2764, Train Accuracy= 0.156\n",
      "Step 499, Minibatch Loss= 1.1066, Train Accuracy= 0.320\n",
      "Step 500, Minibatch Loss= 1.3845, Train Accuracy= 0.258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1561.84964998,    0.        ,  821.25884779,  622.57299223,\n",
       "         985.98966653,  727.96294416, 1192.44169218,  985.98966653]),\n",
       " array([1649.30494919,    0.        ,  897.26954963,  630.50182213,\n",
       "        1059.24977041,  756.26498041, 1278.12210479, 1059.24977041]),\n",
       " array([1591.00141638,    0.        ,  846.5957484 ,  625.21593553,\n",
       "        1010.40970116,  737.39695624, 1221.00182972, 1010.40970116]),\n",
       " 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fcon(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_f_rep import run_f_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0730 21:00:42.958361 140554664703808 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:29: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0730 21:00:43.008900 140554664703808 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:34: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0730 21:00:43.101291 140554664703808 deprecation.py:506] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:11: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0730 21:00:43.149108 140554664703808 deprecation.py:323] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:50: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0730 21:00:43.221107 140554664703808 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:51: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0730 21:00:43.478136 140554664703808 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:60: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0730 21:00:43.480207 140554664703808 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/fcon_rep.py:63: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_f_ref(1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "50\n",
      "7\n",
      "50\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "ans=7\n",
    "import numpy as np\n",
    "EEE1=np.load('Data/'+str(i)+'_EEE1.npy')\n",
    "EEE2=np.load('Data/'+str(i)+'_EEE2.npy')\n",
    "EEE=np.load('Data/'+str(i)+'_EEE.npy')\n",
    "Num=np.load('Data/'+str(i)+'_Numm.npy')\n",
    "print(np.argmin(np.average(EEE1,axis=1)))\n",
    "n=np.zeros(50)\n",
    "for i in range (0,50):\n",
    "    n[i]=np.argmin(EEE1[:,i])\n",
    "print(np.where(n==ans)[0].size)\n",
    "print(np.argsort(np.average(EEE,axis=1)))\n",
    "n=np.zeros(50)\n",
    "for i in range (0,50):\n",
    "    n[i]=np.argsort(EEE[:,i])\n",
    "print(np.where(n==ans)[0].size)\n",
    "print(np.average(EEE,axis=1)[ans]/EEE.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 5 1 2 4 3 6 0]\n",
      "0\n",
      "[7 5 1 3 4 2 6 0]\n",
      "0\n",
      "1.0632602692407285\n",
      "1.12067711982897\n"
     ]
    }
   ],
   "source": [
    "i=21\n",
    "ans=0\n",
    "import numpy as np\n",
    "EEE1=np.load('Data/'+str(i)+'_EEE1.npy')\n",
    "EEE2=np.load('Data/'+str(i)+'_EEE2.npy')\n",
    "EEE=np.load('Data/'+str(i)+'_EEE.npy')\n",
    "Num=np.load('Data/'+str(i)+'_Numm.npy')\n",
    "print(np.argsort(np.average(EEE1,axis=1)))\n",
    "n=np.zeros(50)\n",
    "for i in range (0,50):\n",
    "    n[i]=np.argmin(EEE1[:,i])\n",
    "print(np.where(n==ans)[0].size)\n",
    "print(np.argsort(np.average(EEE,axis=1)))\n",
    "n=np.zeros(50)\n",
    "for i in range (0,50):\n",
    "    n[i]=np.argmin(EEE[:,i])\n",
    "print(np.where(n==ans)[0].size)\n",
    "print(np.average(EEE1,axis=1)[ans]/EEE1.mean())\n",
    "print(np.average(EEE,axis=1)[ans]/EEE.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 1 3 2 5 6 0 4]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "i=14\n",
    "ans=3\n",
    "import numpy as np\n",
    "EEE1=np.load('Data/'+str(i)+'_EEE1.npy')\n",
    "EEE2=np.load('Data/'+str(i)+'_EEE2.npy')\n",
    "EEE=np.load('Data/'+str(i)+'_EEE.npy')\n",
    "Num=np.load('Data/'+str(i)+'_Numm.npy')\n",
    "print(np.argsort(np.average(EEE2,axis=1)))\n",
    "n=np.zeros(50)\n",
    "for i in range (0,50):\n",
    "    n[i]=np.argmin(EEE2[:,i])\n",
    "print(np.where(n==ans)[0].size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=np.zeros(50)\n",
    "for i in range (0,50):\n",
    "    n[i]=np.argmin(EEE1[:,i])\n",
    "np.where(n==ans)[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 436.21482934,  432.49493383,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [ 521.78145401,  506.91328659,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [1521.18257015, 1545.60206728,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [ 436.21482934,  432.49493383,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [1106.02320739,  997.91719962,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [ 821.4555458 ,  817.11907371,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [ 436.21482934,  432.49493383,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

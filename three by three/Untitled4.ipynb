{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data=np.load('data.npy')\n",
    "for i in range (0,16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(data[:,:,i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0630 16:58:58.171967 140440214918976 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/con1.py:21: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0630 16:58:58.193885 140440214918976 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/con1.py:27: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0630 16:58:58.238342 140440214918976 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/convo.py:11: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0630 16:58:58.247244 140440214918976 deprecation.py:506] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/convo.py:38: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0630 16:58:58.262050 140440214918976 deprecation.py:323] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/con1.py:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0630 16:58:58.287184 140440214918976 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/con1.py:50: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0630 16:58:58.414687 140440214918976 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/con1.py:59: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0630 16:58:58.416231 140440214918976 deprecation_wrapper.py:119] From /afs/inf.ed.ac.uk/user/s18/s1883226/Downloads/experiment/Untitled Folder/con1.py:69: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 2045.4459, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 1423.6149, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 1080.3929, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 677.9493, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 716.9801, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 77.5692, Train Accuracy= 0.500\n",
      "Step 8, Minibatch Loss= 122.7204, Train Accuracy= 0.500\n",
      "Step 9, Minibatch Loss= 30.7555, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 1040.5927, Train Accuracy= 0.000\n",
      "Step 11, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 67135.7031, Train Accuracy= 0.500\n",
      "Step 2, Minibatch Loss= 44073.8906, Train Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 50641.5781, Train Accuracy= 0.625\n",
      "Step 5, Minibatch Loss= 60637.2891, Train Accuracy= 0.500\n",
      "Step 6, Minibatch Loss= 75848.4531, Train Accuracy= 0.625\n",
      "Step 7, Minibatch Loss= 60659.1016, Train Accuracy= 0.625\n",
      "Step 8, Minibatch Loss= 9000.4922, Train Accuracy= 0.625\n",
      "Step 9, Minibatch Loss= 41987.6172, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 32703.5625, Train Accuracy= 0.875\n",
      "Step 11, Minibatch Loss= 23751.0000, Train Accuracy= 0.750\n",
      "Step 12, Minibatch Loss= 43601.9219, Train Accuracy= 0.750\n",
      "Step 13, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 1.0\n",
      "Step 1, Minibatch Loss= 3014.3069, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 3, Minibatch Loss= 2415.3452, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 1407.0725, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 1219.0278, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 433525.9062, Train Accuracy= 0.375\n",
      "Step 2, Minibatch Loss= 235790.9375, Train Accuracy= 0.375\n",
      "Step 3, Minibatch Loss= 28780.4395, Train Accuracy= 0.875\n",
      "Step 4, Minibatch Loss= 88528.9688, Train Accuracy= 0.750\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 55883.9375, Train Accuracy= 0.375\n",
      "Step 7, Minibatch Loss= 90146.5859, Train Accuracy= 0.375\n",
      "Step 8, Minibatch Loss= 84638.9141, Train Accuracy= 0.375\n",
      "Step 9, Minibatch Loss= 50304.3828, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 13859.1973, Train Accuracy= 0.500\n",
      "Step 11, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.5\n",
      "Step 1, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 2, Minibatch Loss= 5004.2349, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 3226.7144, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 1357.1213, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 5497.2432, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 5067.8115, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 162618.0000, Train Accuracy= 0.750\n",
      "Step 2, Minibatch Loss= 212602.8594, Train Accuracy= 0.750\n",
      "Step 3, Minibatch Loss= 1227562.0000, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 1329948.5000, Train Accuracy= 0.500\n",
      "Step 5, Minibatch Loss= 896587.2500, Train Accuracy= 0.625\n",
      "Step 6, Minibatch Loss= 611880.6875, Train Accuracy= 0.750\n",
      "Step 7, Minibatch Loss= 473099.2500, Train Accuracy= 0.250\n",
      "Step 8, Minibatch Loss= 15271.4375, Train Accuracy= 0.875\n",
      "Step 9, Minibatch Loss= 22772.8750, Train Accuracy= 0.875\n",
      "Step 10, Minibatch Loss= 24983.2188, Train Accuracy= 0.750\n",
      "Step 11, Minibatch Loss= 121839.0625, Train Accuracy= 0.375\n",
      "Step 12, Minibatch Loss= 145675.2188, Train Accuracy= 0.625\n",
      "Step 13, Minibatch Loss= 287730.9688, Train Accuracy= 0.625\n",
      "Step 14, Minibatch Loss= 433086.0625, Train Accuracy= 0.500\n",
      "Step 15, Minibatch Loss= 393703.7188, Train Accuracy= 0.375\n",
      "Step 16, Minibatch Loss= 71085.6250, Train Accuracy= 0.875\n",
      "Step 17, Minibatch Loss= 157009.5000, Train Accuracy= 0.125\n",
      "Step 18, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 38081.4297, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 3, Minibatch Loss= 12841.5527, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 964359.6250, Train Accuracy= 0.750\n",
      "Step 2, Minibatch Loss= 790640.3750, Train Accuracy= 0.500\n",
      "Step 3, Minibatch Loss= 449643.2188, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 1425641.6250, Train Accuracy= 0.500\n",
      "Step 5, Minibatch Loss= 1336476.7500, Train Accuracy= 0.750\n",
      "Step 6, Minibatch Loss= 2283493.0000, Train Accuracy= 0.500\n",
      "Step 7, Minibatch Loss= 1065115.1250, Train Accuracy= 0.750\n",
      "Step 8, Minibatch Loss= 1710681.7500, Train Accuracy= 0.500\n",
      "Step 9, Minibatch Loss= 821270.6875, Train Accuracy= 0.625\n",
      "Step 10, Minibatch Loss= 1142364.0000, Train Accuracy= 0.500\n",
      "Step 11, Minibatch Loss= 900963.0000, Train Accuracy= 0.500\n",
      "Step 12, Minibatch Loss= 594427.0000, Train Accuracy= 0.625\n",
      "Step 13, Minibatch Loss= 223239.1406, Train Accuracy= 0.875\n",
      "Step 14, Minibatch Loss= 1244766.8750, Train Accuracy= 0.625\n",
      "Step 15, Minibatch Loss= 1528880.7500, Train Accuracy= 0.625\n",
      "Step 16, Minibatch Loss= 2250052.7500, Train Accuracy= 0.500\n",
      "Step 17, Minibatch Loss= 567772.3125, Train Accuracy= 0.875\n",
      "Step 18, Minibatch Loss= 2770145.5000, Train Accuracy= 0.000\n",
      "Step 19, Minibatch Loss= 640073.0000, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 225395.7812, Train Accuracy= 0.375\n",
      "Step 21, Minibatch Loss= 1081749.1250, Train Accuracy= 0.250\n",
      "Step 22, Minibatch Loss= 1215084.6250, Train Accuracy= 0.500\n",
      "Step 23, Minibatch Loss= 1774527.2500, Train Accuracy= 0.375\n",
      "Step 24, Minibatch Loss= 2337875.0000, Train Accuracy= 0.125\n",
      "Step 25, Minibatch Loss= 595065.3125, Train Accuracy= 0.500\n",
      "Step 26, Minibatch Loss= 291119.7188, Train Accuracy= 0.500\n",
      "Step 27, Minibatch Loss= 10120.7188, Train Accuracy= 0.875\n",
      "Step 28, Minibatch Loss= 175651.0000, Train Accuracy= 0.875\n",
      "Step 29, Minibatch Loss= 328299.5625, Train Accuracy= 0.875\n",
      "Step 30, Minibatch Loss= 2379360.0000, Train Accuracy= 0.125\n",
      "Step 31, Minibatch Loss= 1081273.3750, Train Accuracy= 0.625\n",
      "Step 32, Minibatch Loss= 1222145.8750, Train Accuracy= 0.625\n",
      "Step 33, Minibatch Loss= 1955476.8750, Train Accuracy= 0.375\n",
      "Step 34, Minibatch Loss= 1262921.5000, Train Accuracy= 0.375\n",
      "Step 35, Minibatch Loss= 342964.9375, Train Accuracy= 0.375\n",
      "Step 36, Minibatch Loss= 91118.8125, Train Accuracy= 0.875\n",
      "Step 37, Minibatch Loss= 835897.8125, Train Accuracy= 0.625\n",
      "Step 38, Minibatch Loss= 2409310.5000, Train Accuracy= 0.125\n",
      "Step 39, Minibatch Loss= 1180361.7500, Train Accuracy= 0.625\n",
      "Step 40, Minibatch Loss= 1197757.6250, Train Accuracy= 0.625\n",
      "Step 41, Minibatch Loss= 1941486.2500, Train Accuracy= 0.500\n",
      "Step 42, Minibatch Loss= 2087017.3750, Train Accuracy= 0.250\n",
      "Step 43, Minibatch Loss= 1442453.5000, Train Accuracy= 0.500\n",
      "Step 44, Minibatch Loss= 319827.1875, Train Accuracy= 0.875\n",
      "Step 45, Minibatch Loss= 1101336.8750, Train Accuracy= 0.375\n",
      "Step 46, Minibatch Loss= 409955.7500, Train Accuracy= 0.625\n",
      "Step 47, Minibatch Loss= 231521.8750, Train Accuracy= 0.625\n",
      "Step 48, Minibatch Loss= 19281.2500, Train Accuracy= 0.750\n",
      "Step 49, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 440.7448, Train Accuracy= 0.500\n",
      "Step 2, Minibatch Loss= 5277.3633, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 858.2646, Train Accuracy= 0.250\n",
      "Step 4, Minibatch Loss= 55.3358, Train Accuracy= 0.750\n",
      "Step 5, Minibatch Loss= 682.9313, Train Accuracy= 0.500\n",
      "Step 6, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 195982.6562, Train Accuracy= 0.750\n",
      "Step 2, Minibatch Loss= 157642.7500, Train Accuracy= 0.500\n",
      "Step 3, Minibatch Loss= 122934.0312, Train Accuracy= 0.375\n",
      "Step 4, Minibatch Loss= 52972.2031, Train Accuracy= 0.875\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 147863.3750, Train Accuracy= 0.750\n",
      "Step 7, Minibatch Loss= 315042.1875, Train Accuracy= 0.375\n",
      "Step 8, Minibatch Loss= 130297.4688, Train Accuracy= 0.625\n",
      "Step 9, Minibatch Loss= 17476.6406, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 79659.1250, Train Accuracy= 0.750\n",
      "Step 11, Minibatch Loss= 52809.7344, Train Accuracy= 0.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.75\n",
      "Step 1, Minibatch Loss= 2304.8662, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 3, Minibatch Loss= 5974.9272, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 2056.8303, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 944105.6875, Train Accuracy= 0.500\n",
      "Step 2, Minibatch Loss= 150289.2969, Train Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 111872.9141, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 123727.6250, Train Accuracy= 0.750\n",
      "Step 5, Minibatch Loss= 708644.8750, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 338528.0625, Train Accuracy= 0.500\n",
      "Step 7, Minibatch Loss= 110034.6875, Train Accuracy= 0.750\n",
      "Step 8, Minibatch Loss= 156634.7969, Train Accuracy= 0.500\n",
      "Step 9, Minibatch Loss= 30815.3594, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 124781.9531, Train Accuracy= 0.500\n",
      "Step 11, Minibatch Loss= 204264.1875, Train Accuracy= 0.375\n",
      "Step 12, Minibatch Loss= 74345.8047, Train Accuracy= 0.750\n",
      "Step 13, Minibatch Loss= 95240.4141, Train Accuracy= 0.875\n",
      "Step 14, Minibatch Loss= 141890.0938, Train Accuracy= 0.500\n",
      "Step 15, Minibatch Loss= 148880.6562, Train Accuracy= 0.750\n",
      "Step 16, Minibatch Loss= 97727.4141, Train Accuracy= 0.750\n",
      "Step 17, Minibatch Loss= 113907.5547, Train Accuracy= 0.500\n",
      "Step 18, Minibatch Loss= 168663.4844, Train Accuracy= 0.375\n",
      "Step 19, Minibatch Loss= 208243.3438, Train Accuracy= 0.500\n",
      "Step 20, Minibatch Loss= 149762.7188, Train Accuracy= 0.625\n",
      "Step 21, Minibatch Loss= 24695.2773, Train Accuracy= 0.750\n",
      "Step 22, Minibatch Loss= 13663.2188, Train Accuracy= 0.875\n",
      "Step 23, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.75\n",
      "Step 1, Minibatch Loss= 619.6429, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 108.9573, Train Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 6352.0073, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 5509.3564, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 3927.1826, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 2302.5193, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 1786.5673, Train Accuracy= 0.000\n",
      "Step 9, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 231981.0625, Train Accuracy= 0.750\n",
      "Step 2, Minibatch Loss= 130620.0625, Train Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 634237.9375, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 1051316.2500, Train Accuracy= 0.250\n",
      "Step 5, Minibatch Loss= 685778.0000, Train Accuracy= 0.375\n",
      "Step 6, Minibatch Loss= 454649.6250, Train Accuracy= 0.625\n",
      "Step 7, Minibatch Loss= 413121.1250, Train Accuracy= 0.750\n",
      "Step 8, Minibatch Loss= 701908.2500, Train Accuracy= 0.500\n",
      "Step 9, Minibatch Loss= 676624.9375, Train Accuracy= 0.125\n",
      "Step 10, Minibatch Loss= 287277.3125, Train Accuracy= 0.500\n",
      "Step 11, Minibatch Loss= 216295.6875, Train Accuracy= 0.625\n",
      "Step 12, Minibatch Loss= 299716.3750, Train Accuracy= 0.500\n",
      "Step 13, Minibatch Loss= 260704.2500, Train Accuracy= 0.500\n",
      "Step 14, Minibatch Loss= 173159.5625, Train Accuracy= 0.500\n",
      "Step 15, Minibatch Loss= 41453.6250, Train Accuracy= 0.625\n",
      "Step 16, Minibatch Loss= 81133.8750, Train Accuracy= 0.875\n",
      "Step 17, Minibatch Loss= 205672.1875, Train Accuracy= 0.500\n",
      "Step 18, Minibatch Loss= 63303.1875, Train Accuracy= 0.750\n",
      "Step 19, Minibatch Loss= 307797.8750, Train Accuracy= 0.375\n",
      "Step 20, Minibatch Loss= 242493.1875, Train Accuracy= 0.625\n",
      "Step 21, Minibatch Loss= 212427.0625, Train Accuracy= 0.500\n",
      "Step 22, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.375\n",
      "Step 1, Minibatch Loss= 164.8031, Train Accuracy= 0.375\n",
      "Step 2, Minibatch Loss= 210.7343, Train Accuracy= 0.375\n",
      "Step 3, Minibatch Loss= 201.0760, Train Accuracy= 0.625\n",
      "Step 4, Minibatch Loss= 567.6299, Train Accuracy= 0.125\n",
      "Step 5, Minibatch Loss= 722.6888, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 19.6405, Train Accuracy= 0.750\n",
      "Step 7, Minibatch Loss= 268.2502, Train Accuracy= 0.250\n",
      "Step 8, Minibatch Loss= 49.7554, Train Accuracy= 0.625\n",
      "Step 9, Minibatch Loss= 561.8892, Train Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 552.5653, Train Accuracy= 0.000\n",
      "Step 11, Minibatch Loss= 491.5191, Train Accuracy= 0.000\n",
      "Step 12, Minibatch Loss= 454.8532, Train Accuracy= 0.250\n",
      "Step 13, Minibatch Loss= 581.4285, Train Accuracy= 0.000\n",
      "Step 14, Minibatch Loss= 184.5374, Train Accuracy= 0.375\n",
      "Step 15, Minibatch Loss= 458.9388, Train Accuracy= 0.000\n",
      "Step 16, Minibatch Loss= 479.8976, Train Accuracy= 0.000\n",
      "Step 17, Minibatch Loss= 566.5082, Train Accuracy= 0.000\n",
      "Step 18, Minibatch Loss= 602.6160, Train Accuracy= 0.000\n",
      "Step 19, Minibatch Loss= 391.8087, Train Accuracy= 0.250\n",
      "Step 20, Minibatch Loss= 483.8021, Train Accuracy= 0.375\n",
      "Step 21, Minibatch Loss= 653.0280, Train Accuracy= 0.000\n",
      "Step 22, Minibatch Loss= 468.0433, Train Accuracy= 0.000\n",
      "Step 23, Minibatch Loss= 256.7548, Train Accuracy= 0.375\n",
      "Step 24, Minibatch Loss= 175.2159, Train Accuracy= 0.000\n",
      "Step 25, Minibatch Loss= 53.9714, Train Accuracy= 0.875\n",
      "Step 26, Minibatch Loss= 364.6946, Train Accuracy= 0.250\n",
      "Step 27, Minibatch Loss= 342.9928, Train Accuracy= 0.125\n",
      "Step 28, Minibatch Loss= 80.8571, Train Accuracy= 0.500\n",
      "Step 29, Minibatch Loss= 121.6648, Train Accuracy= 0.375\n",
      "Step 30, Minibatch Loss= 337.8220, Train Accuracy= 0.125\n",
      "Step 31, Minibatch Loss= 460.1338, Train Accuracy= 0.000\n",
      "Step 32, Minibatch Loss= 134.3549, Train Accuracy= 0.500\n",
      "Step 33, Minibatch Loss= 290.1887, Train Accuracy= 0.125\n",
      "Step 34, Minibatch Loss= 152.3781, Train Accuracy= 0.375\n",
      "Step 35, Minibatch Loss= 125.6571, Train Accuracy= 0.250\n",
      "Step 36, Minibatch Loss= 85.4550, Train Accuracy= 0.500\n",
      "Step 37, Minibatch Loss= 362.9333, Train Accuracy= 0.125\n",
      "Step 38, Minibatch Loss= 417.5580, Train Accuracy= 0.250\n",
      "Step 39, Minibatch Loss= 98.4492, Train Accuracy= 0.625\n",
      "Step 40, Minibatch Loss= 38.7099, Train Accuracy= 0.875\n",
      "Step 41, Minibatch Loss= 329.0445, Train Accuracy= 0.250\n",
      "Step 42, Minibatch Loss= 443.5073, Train Accuracy= 0.000\n",
      "Step 43, Minibatch Loss= 481.4491, Train Accuracy= 0.000\n",
      "Step 44, Minibatch Loss= 28.4404, Train Accuracy= 0.750\n",
      "Step 45, Minibatch Loss= 500.5522, Train Accuracy= 0.125\n",
      "Step 46, Minibatch Loss= 232.8313, Train Accuracy= 0.125\n",
      "Step 47, Minibatch Loss= 319.2861, Train Accuracy= 0.125\n",
      "Step 48, Minibatch Loss= 660.3589, Train Accuracy= 0.000\n",
      "Step 49, Minibatch Loss= 78.6591, Train Accuracy= 0.125\n",
      "Step 50, Minibatch Loss= 76.2624, Train Accuracy= 0.375\n",
      "Step 51, Minibatch Loss= 507.6055, Train Accuracy= 0.000\n",
      "Step 52, Minibatch Loss= 66.1636, Train Accuracy= 0.500\n",
      "Step 53, Minibatch Loss= 107.4786, Train Accuracy= 0.250\n",
      "Step 54, Minibatch Loss= 118.6285, Train Accuracy= 0.500\n",
      "Step 55, Minibatch Loss= 488.7341, Train Accuracy= 0.000\n",
      "Step 56, Minibatch Loss= 28.8212, Train Accuracy= 0.750\n",
      "Step 57, Minibatch Loss= 204.8594, Train Accuracy= 0.125\n",
      "Step 58, Minibatch Loss= 377.1505, Train Accuracy= 0.000\n",
      "Step 59, Minibatch Loss= 95.0577, Train Accuracy= 0.500\n",
      "Step 60, Minibatch Loss= 84.7758, Train Accuracy= 0.250\n",
      "Step 61, Minibatch Loss= 59.0064, Train Accuracy= 0.250\n",
      "Step 62, Minibatch Loss= 265.1661, Train Accuracy= 0.000\n",
      "Step 63, Minibatch Loss= 317.5478, Train Accuracy= 0.000\n",
      "Step 64, Minibatch Loss= 257.3232, Train Accuracy= 0.000\n",
      "Step 65, Minibatch Loss= 237.2707, Train Accuracy= 0.125\n",
      "Step 66, Minibatch Loss= 15.4206, Train Accuracy= 0.750\n",
      "Step 67, Minibatch Loss= 448.9344, Train Accuracy= 0.000\n",
      "Step 68, Minibatch Loss= 368.4581, Train Accuracy= 0.000\n",
      "Step 69, Minibatch Loss= 328.7042, Train Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 187.6353, Train Accuracy= 0.125\n",
      "Step 71, Minibatch Loss= 32.6855, Train Accuracy= 0.750\n",
      "Step 72, Minibatch Loss= 220.8741, Train Accuracy= 0.125\n",
      "Step 73, Minibatch Loss= 187.4532, Train Accuracy= 0.250\n",
      "Step 74, Minibatch Loss= 167.9942, Train Accuracy= 0.375\n",
      "Step 75, Minibatch Loss= 111.5157, Train Accuracy= 0.250\n",
      "Step 76, Minibatch Loss= 150.6874, Train Accuracy= 0.125\n",
      "Step 77, Minibatch Loss= 121.2749, Train Accuracy= 0.125\n",
      "Step 78, Minibatch Loss= 100.2311, Train Accuracy= 0.375\n",
      "Step 79, Minibatch Loss= 37.1945, Train Accuracy= 0.750\n",
      "Step 80, Minibatch Loss= 363.4123, Train Accuracy= 0.125\n",
      "Step 81, Minibatch Loss= 314.0303, Train Accuracy= 0.250\n",
      "Step 82, Minibatch Loss= 23.4119, Train Accuracy= 0.750\n",
      "Step 83, Minibatch Loss= 307.2386, Train Accuracy= 0.000\n",
      "Step 84, Minibatch Loss= 131.2816, Train Accuracy= 0.500\n",
      "Step 85, Minibatch Loss= 12.6012, Train Accuracy= 0.750\n",
      "Step 86, Minibatch Loss= 136.5025, Train Accuracy= 0.125\n",
      "Step 87, Minibatch Loss= 315.7731, Train Accuracy= 0.000\n",
      "Step 88, Minibatch Loss= 88.6087, Train Accuracy= 0.375\n",
      "Step 89, Minibatch Loss= 44.8258, Train Accuracy= 0.375\n",
      "Step 90, Minibatch Loss= 70.9474, Train Accuracy= 0.500\n",
      "Step 91, Minibatch Loss= 118.0730, Train Accuracy= 0.375\n",
      "Step 92, Minibatch Loss= 39.3002, Train Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 93, Minibatch Loss= 491.5458, Train Accuracy= 0.000\n",
      "Step 94, Minibatch Loss= 127.5550, Train Accuracy= 0.250\n",
      "Step 95, Minibatch Loss= 402.9983, Train Accuracy= 0.000\n",
      "Step 96, Minibatch Loss= 442.5068, Train Accuracy= 0.000\n",
      "Step 97, Minibatch Loss= 25.5212, Train Accuracy= 0.875\n",
      "Step 98, Minibatch Loss= 401.8961, Train Accuracy= 0.000\n",
      "Step 99, Minibatch Loss= 34.7417, Train Accuracy= 0.625\n",
      "Step 100, Minibatch Loss= 67.6914, Train Accuracy= 0.625\n",
      "Step 101, Minibatch Loss= 45.5720, Train Accuracy= 0.500\n",
      "Step 102, Minibatch Loss= 265.0473, Train Accuracy= 0.000\n",
      "Step 103, Minibatch Loss= 246.2004, Train Accuracy= 0.000\n",
      "Step 104, Minibatch Loss= 4.5206, Train Accuracy= 0.625\n",
      "Step 105, Minibatch Loss= 41.0780, Train Accuracy= 0.625\n",
      "Step 106, Minibatch Loss= 49.8143, Train Accuracy= 0.500\n",
      "Step 107, Minibatch Loss= 89.6717, Train Accuracy= 0.250\n",
      "Step 108, Minibatch Loss= 32.9655, Train Accuracy= 0.625\n",
      "Step 109, Minibatch Loss= 83.6090, Train Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 45.3160, Train Accuracy= 0.500\n",
      "Step 111, Minibatch Loss= 212.5558, Train Accuracy= 0.000\n",
      "Step 112, Minibatch Loss= 151.8605, Train Accuracy= 0.125\n",
      "Step 113, Minibatch Loss= 82.9943, Train Accuracy= 0.375\n",
      "Step 114, Minibatch Loss= 24.2400, Train Accuracy= 0.625\n",
      "Step 115, Minibatch Loss= 71.6016, Train Accuracy= 0.250\n",
      "Step 116, Minibatch Loss= 91.3342, Train Accuracy= 0.375\n",
      "Step 117, Minibatch Loss= 0.5049, Train Accuracy= 0.875\n",
      "Step 118, Minibatch Loss= 249.1911, Train Accuracy= 0.000\n",
      "Step 119, Minibatch Loss= 202.4529, Train Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 130.5936, Train Accuracy= 0.375\n",
      "Step 121, Minibatch Loss= 96.3986, Train Accuracy= 0.500\n",
      "Step 122, Minibatch Loss= 36.6689, Train Accuracy= 0.500\n",
      "Step 123, Minibatch Loss= 52.6701, Train Accuracy= 0.250\n",
      "Step 124, Minibatch Loss= 158.5804, Train Accuracy= 0.000\n",
      "Step 125, Minibatch Loss= 102.2733, Train Accuracy= 0.125\n",
      "Step 126, Minibatch Loss= 88.4405, Train Accuracy= 0.375\n",
      "Step 127, Minibatch Loss= 53.5100, Train Accuracy= 0.375\n",
      "Step 128, Minibatch Loss= 44.6327, Train Accuracy= 0.625\n",
      "Step 129, Minibatch Loss= 43.3122, Train Accuracy= 0.625\n",
      "Step 130, Minibatch Loss= 122.3841, Train Accuracy= 0.375\n",
      "Step 131, Minibatch Loss= 33.6792, Train Accuracy= 0.750\n",
      "Step 132, Minibatch Loss= 0.7722, Train Accuracy= 0.875\n",
      "Step 133, Minibatch Loss= 421.3967, Train Accuracy= 0.000\n",
      "Step 134, Minibatch Loss= 376.2363, Train Accuracy= 0.000\n",
      "Step 135, Minibatch Loss= 391.0795, Train Accuracy= 0.000\n",
      "Step 136, Minibatch Loss= 349.6110, Train Accuracy= 0.000\n",
      "Step 137, Minibatch Loss= 83.2680, Train Accuracy= 0.375\n",
      "Step 138, Minibatch Loss= 157.8686, Train Accuracy= 0.125\n",
      "Step 139, Minibatch Loss= 249.5347, Train Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 80.7141, Train Accuracy= 0.500\n",
      "Step 141, Minibatch Loss= 75.4060, Train Accuracy= 0.125\n",
      "Step 142, Minibatch Loss= 134.1888, Train Accuracy= 0.000\n",
      "Step 143, Minibatch Loss= 39.5826, Train Accuracy= 0.625\n",
      "Step 144, Minibatch Loss= 148.4802, Train Accuracy= 0.250\n",
      "Step 145, Minibatch Loss= 17.6295, Train Accuracy= 0.625\n",
      "Step 146, Minibatch Loss= 26.2100, Train Accuracy= 0.625\n",
      "Step 147, Minibatch Loss= 141.9290, Train Accuracy= 0.125\n",
      "Step 148, Minibatch Loss= 21.5078, Train Accuracy= 0.625\n",
      "Step 149, Minibatch Loss= 156.0053, Train Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 111.9350, Train Accuracy= 0.125\n",
      "Step 151, Minibatch Loss= 35.9043, Train Accuracy= 0.375\n",
      "Step 152, Minibatch Loss= 78.9214, Train Accuracy= 0.000\n",
      "Step 153, Minibatch Loss= 65.2247, Train Accuracy= 0.500\n",
      "Step 154, Minibatch Loss= 80.3286, Train Accuracy= 0.375\n",
      "Step 155, Minibatch Loss= 22.1571, Train Accuracy= 0.625\n",
      "Step 156, Minibatch Loss= 83.4957, Train Accuracy= 0.125\n",
      "Step 157, Minibatch Loss= 42.1937, Train Accuracy= 0.500\n",
      "Step 158, Minibatch Loss= 52.5680, Train Accuracy= 0.500\n",
      "Step 159, Minibatch Loss= 78.7711, Train Accuracy= 0.250\n",
      "Step 160, Minibatch Loss= 48.5221, Train Accuracy= 0.500\n",
      "Step 161, Minibatch Loss= 90.8742, Train Accuracy= 0.250\n",
      "Step 162, Minibatch Loss= 37.5870, Train Accuracy= 0.875\n",
      "Step 163, Minibatch Loss= 95.7724, Train Accuracy= 0.250\n",
      "Step 164, Minibatch Loss= 228.9920, Train Accuracy= 0.000\n",
      "Step 165, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 30714.4492, Train Accuracy= 0.750\n",
      "Step 2, Minibatch Loss= 44470.5781, Train Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 45489.6133, Train Accuracy= 0.375\n",
      "Step 4, Minibatch Loss= 48621.2656, Train Accuracy= 0.375\n",
      "Step 5, Minibatch Loss= 21976.3711, Train Accuracy= 0.500\n",
      "Step 6, Minibatch Loss= 3909.6318, Train Accuracy= 0.875\n",
      "Step 7, Minibatch Loss= 13329.5654, Train Accuracy= 0.750\n",
      "Step 8, Minibatch Loss= 32341.6875, Train Accuracy= 0.625\n",
      "Step 9, Minibatch Loss= 30999.0664, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 36774.7695, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 34143.6328, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 23492.0547, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 4032431.5000, Train Accuracy= 0.625\n",
      "Step 2, Minibatch Loss= 2862691.0000, Train Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 1069757.8750, Train Accuracy= 0.750\n",
      "Step 4, Minibatch Loss= 1051348.7500, Train Accuracy= 0.250\n",
      "Step 5, Minibatch Loss= 446020.6250, Train Accuracy= 0.625\n",
      "Step 6, Minibatch Loss= 1742597.7500, Train Accuracy= 0.375\n",
      "Step 7, Minibatch Loss= 1694370.1250, Train Accuracy= 0.500\n",
      "Step 8, Minibatch Loss= 947074.1875, Train Accuracy= 0.750\n",
      "Step 9, Minibatch Loss= 1961252.7500, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 2886436.0000, Train Accuracy= 0.125\n",
      "Step 11, Minibatch Loss= 1617635.5000, Train Accuracy= 0.250\n",
      "Step 12, Minibatch Loss= 586572.5625, Train Accuracy= 0.500\n",
      "Step 13, Minibatch Loss= 169152.4375, Train Accuracy= 0.625\n",
      "Step 14, Minibatch Loss= 180985.5625, Train Accuracy= 0.625\n",
      "Step 15, Minibatch Loss= 980121.8750, Train Accuracy= 0.375\n",
      "Step 16, Minibatch Loss= 1018214.1250, Train Accuracy= 0.500\n",
      "Step 17, Minibatch Loss= 1194414.3750, Train Accuracy= 0.375\n",
      "Step 18, Minibatch Loss= 1128244.1250, Train Accuracy= 0.375\n",
      "Step 19, Minibatch Loss= 378212.3750, Train Accuracy= 0.750\n",
      "Step 20, Minibatch Loss= 291961.6875, Train Accuracy= 0.375\n",
      "Step 21, Minibatch Loss= 62433.0000, Train Accuracy= 0.750\n",
      "Step 22, Minibatch Loss= 55144.5000, Train Accuracy= 0.625\n",
      "Step 23, Minibatch Loss= 28634.8750, Train Accuracy= 0.750\n",
      "Step 24, Minibatch Loss= 162184.5625, Train Accuracy= 0.625\n",
      "Step 25, Minibatch Loss= 167897.3750, Train Accuracy= 0.500\n",
      "Step 26, Minibatch Loss= 32366.7500, Train Accuracy= 0.875\n",
      "Step 27, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.125\n",
      "Step 1, Minibatch Loss= 35086.9805, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 15187.6230, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 11265.3066, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 6358.5039, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 4598.3560, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 21553.1406, Train Accuracy= 0.000\n",
      "Step 9, Minibatch Loss= 59.6508, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 18576.7305, Train Accuracy= 0.000\n",
      "Step 11, Minibatch Loss= 17517.8848, Train Accuracy= 0.000\n",
      "Step 12, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 303775.8125, Train Accuracy= 0.625\n",
      "Step 2, Minibatch Loss= 305614.7500, Train Accuracy= 0.875\n",
      "Step 3, Minibatch Loss= 1600084.7500, Train Accuracy= 0.375\n",
      "Step 4, Minibatch Loss= 989882.0000, Train Accuracy= 0.625\n",
      "Step 5, Minibatch Loss= 1338871.8750, Train Accuracy= 0.500\n",
      "Step 6, Minibatch Loss= 872693.5000, Train Accuracy= 0.625\n",
      "Step 7, Minibatch Loss= 438324.5625, Train Accuracy= 0.750\n",
      "Step 8, Minibatch Loss= 181159.6250, Train Accuracy= 0.750\n",
      "Step 9, Minibatch Loss= 168084.3750, Train Accuracy= 0.625\n",
      "Step 10, Minibatch Loss= 178581.8125, Train Accuracy= 0.500\n",
      "Step 11, Minibatch Loss= 301440.8750, Train Accuracy= 0.500\n",
      "Step 12, Minibatch Loss= 192397.5000, Train Accuracy= 0.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13, Minibatch Loss= 369979.7500, Train Accuracy= 0.375\n",
      "Step 14, Minibatch Loss= 31128.5000, Train Accuracy= 0.625\n",
      "Step 15, Minibatch Loss= 76035.5000, Train Accuracy= 0.625\n",
      "Step 16, Minibatch Loss= 131980.5000, Train Accuracy= 0.625\n",
      "Step 17, Minibatch Loss= 404119.3750, Train Accuracy= 0.375\n",
      "Step 18, Minibatch Loss= 248799.4375, Train Accuracy= 0.500\n",
      "Step 19, Minibatch Loss= 93960.6250, Train Accuracy= 0.875\n",
      "Step 20, Minibatch Loss= 46362.2500, Train Accuracy= 0.875\n",
      "Step 21, Minibatch Loss= 3211.6875, Train Accuracy= 0.625\n",
      "Step 22, Minibatch Loss= 107096.3750, Train Accuracy= 0.625\n",
      "Step 23, Minibatch Loss= 344409.5625, Train Accuracy= 0.375\n",
      "Step 24, Minibatch Loss= 337074.1875, Train Accuracy= 0.500\n",
      "Step 25, Minibatch Loss= 471207.1875, Train Accuracy= 0.625\n",
      "Step 26, Minibatch Loss= 818238.6875, Train Accuracy= 0.500\n",
      "Step 27, Minibatch Loss= 440652.6250, Train Accuracy= 0.750\n",
      "Step 28, Minibatch Loss= 648974.8125, Train Accuracy= 0.625\n",
      "Step 29, Minibatch Loss= 763480.1250, Train Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 424342.3125, Train Accuracy= 0.625\n",
      "Step 31, Minibatch Loss= 309446.0000, Train Accuracy= 0.625\n",
      "Step 32, Minibatch Loss= 248350.9375, Train Accuracy= 0.625\n",
      "Step 33, Minibatch Loss= 193591.4375, Train Accuracy= 0.625\n",
      "Step 34, Minibatch Loss= 49704.8125, Train Accuracy= 0.875\n",
      "Step 35, Minibatch Loss= 40486.0000, Train Accuracy= 0.875\n",
      "Step 36, Minibatch Loss= 40266.3125, Train Accuracy= 0.500\n",
      "Step 37, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 2, Minibatch Loss= 1608.9143, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 2383.4766, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 12961.7373, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 1983.5165, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 431.1926, Train Accuracy= 0.125\n",
      "Step 9, Minibatch Loss= 18.4828, Train Accuracy= 0.875\n",
      "Step 10, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 387074.3125, Train Accuracy= 0.625\n",
      "Step 2, Minibatch Loss= 311738.4062, Train Accuracy= 0.750\n",
      "Step 3, Minibatch Loss= 289400.6250, Train Accuracy= 0.250\n",
      "Step 4, Minibatch Loss= 517430.6875, Train Accuracy= 0.500\n",
      "Step 5, Minibatch Loss= 1389331.6250, Train Accuracy= 0.500\n",
      "Step 6, Minibatch Loss= 1191039.7500, Train Accuracy= 0.625\n",
      "Step 7, Minibatch Loss= 774363.1250, Train Accuracy= 0.750\n",
      "Step 8, Minibatch Loss= 2092747.2500, Train Accuracy= 0.375\n",
      "Step 9, Minibatch Loss= 2241596.7500, Train Accuracy= 0.125\n",
      "Step 10, Minibatch Loss= 1220929.2500, Train Accuracy= 0.250\n",
      "Step 11, Minibatch Loss= 34494.0312, Train Accuracy= 0.875\n",
      "Step 12, Minibatch Loss= 76352.0000, Train Accuracy= 0.750\n",
      "Step 13, Minibatch Loss= 211524.3438, Train Accuracy= 0.125\n",
      "Step 14, Minibatch Loss= 168791.2188, Train Accuracy= 0.750\n",
      "Step 15, Minibatch Loss= 231327.1562, Train Accuracy= 0.750\n",
      "Step 16, Minibatch Loss= 158227.0781, Train Accuracy= 0.625\n",
      "Step 17, Minibatch Loss= 256292.9688, Train Accuracy= 0.750\n",
      "Step 18, Minibatch Loss= 490876.6875, Train Accuracy= 0.750\n",
      "Step 19, Minibatch Loss= 1430673.5000, Train Accuracy= 0.375\n",
      "Step 20, Minibatch Loss= 727608.3125, Train Accuracy= 0.500\n",
      "Step 21, Minibatch Loss= 1013033.9375, Train Accuracy= 0.375\n",
      "Step 22, Minibatch Loss= 447062.5000, Train Accuracy= 0.625\n",
      "Step 23, Minibatch Loss= 300703.1562, Train Accuracy= 0.750\n",
      "Step 24, Minibatch Loss= 684707.1875, Train Accuracy= 0.250\n",
      "Step 25, Minibatch Loss= 213554.4688, Train Accuracy= 0.750\n",
      "Step 26, Minibatch Loss= 90422.6719, Train Accuracy= 0.875\n",
      "Step 27, Minibatch Loss= 95401.6406, Train Accuracy= 0.875\n",
      "Step 28, Minibatch Loss= 302498.0625, Train Accuracy= 0.625\n",
      "Step 29, Minibatch Loss= 379254.9062, Train Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 200842.5469, Train Accuracy= 0.625\n",
      "Step 31, Minibatch Loss= 65611.9688, Train Accuracy= 0.625\n",
      "Step 32, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.125\n",
      "Step 1, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 2, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 10307.1875, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 5186.7642, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 4143.1807, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 968771.1875, Train Accuracy= 0.375\n",
      "Step 2, Minibatch Loss= 214869.4375, Train Accuracy= 0.125\n",
      "Step 3, Minibatch Loss= 419086.0000, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 1106606.7500, Train Accuracy= 0.250\n",
      "Step 5, Minibatch Loss= 935055.2500, Train Accuracy= 0.250\n",
      "Step 6, Minibatch Loss= 263196.6875, Train Accuracy= 0.750\n",
      "Step 7, Minibatch Loss= 472362.9688, Train Accuracy= 0.125\n",
      "Step 8, Minibatch Loss= 70216.2656, Train Accuracy= 0.750\n",
      "Step 9, Minibatch Loss= 82236.0469, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 71496.5938, Train Accuracy= 0.750\n",
      "Step 11, Minibatch Loss= 158142.9375, Train Accuracy= 0.625\n",
      "Step 12, Minibatch Loss= 19521.3750, Train Accuracy= 0.750\n",
      "Step 13, Minibatch Loss= 207338.2812, Train Accuracy= 0.625\n",
      "Step 14, Minibatch Loss= 100527.4688, Train Accuracy= 0.750\n",
      "Step 15, Minibatch Loss= 76484.8281, Train Accuracy= 0.750\n",
      "Step 16, Minibatch Loss= 104161.8750, Train Accuracy= 0.750\n",
      "Step 17, Minibatch Loss= 11908.6875, Train Accuracy= 0.625\n",
      "Step 18, Minibatch Loss= 220406.5312, Train Accuracy= 0.375\n",
      "Step 19, Minibatch Loss= 76796.4531, Train Accuracy= 0.875\n",
      "Step 20, Minibatch Loss= 121581.2344, Train Accuracy= 0.750\n",
      "Step 21, Minibatch Loss= 96857.0938, Train Accuracy= 0.750\n",
      "Step 22, Minibatch Loss= 392803.3750, Train Accuracy= 0.500\n",
      "Step 23, Minibatch Loss= 573055.5625, Train Accuracy= 0.625\n",
      "Step 24, Minibatch Loss= 645322.2500, Train Accuracy= 0.375\n",
      "Step 25, Minibatch Loss= 719600.8125, Train Accuracy= 0.375\n",
      "Step 26, Minibatch Loss= 536199.6250, Train Accuracy= 0.250\n",
      "Step 27, Minibatch Loss= 13259.0000, Train Accuracy= 0.750\n",
      "Step 28, Minibatch Loss= 63073.1719, Train Accuracy= 0.875\n",
      "Step 29, Minibatch Loss= 75616.7969, Train Accuracy= 0.500\n",
      "Step 30, Minibatch Loss= 6702.5312, Train Accuracy= 0.750\n",
      "Step 31, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.125\n",
      "Step 1, Minibatch Loss= 7440.5723, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 6021.3926, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 3617.8457, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 894331.2500, Train Accuracy= 0.500\n",
      "Step 2, Minibatch Loss= 690983.0625, Train Accuracy= 0.750\n",
      "Step 3, Minibatch Loss= 1274774.7500, Train Accuracy= 0.375\n",
      "Step 4, Minibatch Loss= 691064.6875, Train Accuracy= 0.625\n",
      "Step 5, Minibatch Loss= 283426.2812, Train Accuracy= 0.750\n",
      "Step 6, Minibatch Loss= 249091.4844, Train Accuracy= 0.750\n",
      "Step 7, Minibatch Loss= 55825.6875, Train Accuracy= 0.750\n",
      "Step 8, Minibatch Loss= 49303.4688, Train Accuracy= 0.625\n",
      "Step 9, Minibatch Loss= 126393.7500, Train Accuracy= 0.750\n",
      "Step 10, Minibatch Loss= 302989.1250, Train Accuracy= 0.750\n",
      "Step 11, Minibatch Loss= 804649.5000, Train Accuracy= 0.625\n",
      "Step 12, Minibatch Loss= 1315531.0000, Train Accuracy= 0.500\n",
      "Step 13, Minibatch Loss= 1138724.8750, Train Accuracy= 0.625\n",
      "Step 14, Minibatch Loss= 1016005.2500, Train Accuracy= 0.625\n",
      "Step 15, Minibatch Loss= 1015416.3750, Train Accuracy= 0.625\n",
      "Step 16, Minibatch Loss= 1406436.5000, Train Accuracy= 0.375\n",
      "Step 17, Minibatch Loss= 1004104.0000, Train Accuracy= 0.375\n",
      "Step 18, Minibatch Loss= 673098.5625, Train Accuracy= 0.375\n",
      "Step 19, Minibatch Loss= 132091.3750, Train Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 2, Minibatch Loss= 3908.5664, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 3249.1484, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 2298.5469, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 3659.0750, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 569405.1875, Train Accuracy= 0.375\n",
      "Step 2, Minibatch Loss= 217413.8594, Train Accuracy= 0.500\n",
      "Step 3, Minibatch Loss= 88082.8906, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 80568.3594, Train Accuracy= 0.625\n",
      "Step 5, Minibatch Loss= 113670.1016, Train Accuracy= 0.625\n",
      "Step 6, Minibatch Loss= 119148.6797, Train Accuracy= 0.625\n",
      "Step 7, Minibatch Loss= 364273.0312, Train Accuracy= 0.375\n",
      "Step 8, Minibatch Loss= 242741.4531, Train Accuracy= 0.500\n",
      "Step 9, Minibatch Loss= 150039.5938, Train Accuracy= 0.625\n",
      "Step 10, Minibatch Loss= 96156.8984, Train Accuracy= 0.625\n",
      "Step 11, Minibatch Loss= 14151.6953, Train Accuracy= 0.750\n",
      "Step 12, Minibatch Loss= 36140.0781, Train Accuracy= 0.750\n",
      "Step 13, Minibatch Loss= 143934.4375, Train Accuracy= 0.500\n",
      "Step 14, Minibatch Loss= 2409.7344, Train Accuracy= 0.875\n",
      "Step 15, Minibatch Loss= 49575.2031, Train Accuracy= 0.500\n",
      "Step 16, Minibatch Loss= 21509.0859, Train Accuracy= 0.875\n",
      "Step 17, Minibatch Loss= 72449.9141, Train Accuracy= 0.500\n",
      "Step 18, Minibatch Loss= 98991.6328, Train Accuracy= 0.625\n",
      "Step 19, Minibatch Loss= 341800.5000, Train Accuracy= 0.125\n",
      "Step 20, Minibatch Loss= 23222.4062, Train Accuracy= 0.875\n",
      "Step 21, Minibatch Loss= 138099.8281, Train Accuracy= 0.500\n",
      "Step 22, Minibatch Loss= 66689.5234, Train Accuracy= 0.750\n",
      "Step 23, Minibatch Loss= 35708.3359, Train Accuracy= 0.875\n",
      "Step 24, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 1.0\n",
      "Step 1, Minibatch Loss= 1186.6237, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 1017.4322, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 202.2271, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 255.6328, Train Accuracy= 0.500\n",
      "Step 5, Minibatch Loss= 804.3416, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 685.9291, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 343.2699, Train Accuracy= 0.250\n",
      "Step 8, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 801605.5625, Train Accuracy= 0.250\n",
      "Step 2, Minibatch Loss= 351327.1250, Train Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 159524.2812, Train Accuracy= 0.750\n",
      "Step 4, Minibatch Loss= 261744.5938, Train Accuracy= 0.625\n",
      "Step 5, Minibatch Loss= 88898.4062, Train Accuracy= 0.750\n",
      "Step 6, Minibatch Loss= 141936.0312, Train Accuracy= 0.375\n",
      "Step 7, Minibatch Loss= 134113.6562, Train Accuracy= 0.250\n",
      "Step 8, Minibatch Loss= 152995.5000, Train Accuracy= 0.125\n",
      "Step 9, Minibatch Loss= 89843.6797, Train Accuracy= 0.500\n",
      "Step 10, Minibatch Loss= 102797.7891, Train Accuracy= 0.500\n",
      "Step 11, Minibatch Loss= 108744.8281, Train Accuracy= 0.250\n",
      "Step 12, Minibatch Loss= 22717.1719, Train Accuracy= 0.250\n",
      "Step 13, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 2, Minibatch Loss= 17475.2441, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 18268.1758, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 14994.1309, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 16012.8408, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 14162.5547, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 10647.7363, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 1447591.1250, Train Accuracy= 0.500\n",
      "Step 2, Minibatch Loss= 1377437.6250, Train Accuracy= 0.125\n",
      "Step 3, Minibatch Loss= 327016.6875, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 48678.0312, Train Accuracy= 0.375\n",
      "Step 5, Minibatch Loss= 257101.9688, Train Accuracy= 0.750\n",
      "Step 6, Minibatch Loss= 746733.2500, Train Accuracy= 0.375\n",
      "Step 7, Minibatch Loss= 1099883.0000, Train Accuracy= 0.125\n",
      "Step 8, Minibatch Loss= 891173.1875, Train Accuracy= 0.250\n",
      "Step 9, Minibatch Loss= 673513.7500, Train Accuracy= 0.250\n",
      "Step 10, Minibatch Loss= 243804.2812, Train Accuracy= 0.625\n",
      "Step 11, Minibatch Loss= 244186.8438, Train Accuracy= 0.250\n",
      "Step 12, Minibatch Loss= 64577.0156, Train Accuracy= 0.750\n",
      "Step 13, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 30700.7188, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 26576.0898, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 21066.6309, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 18146.1152, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 12580.4141, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 9933.4609, Train Accuracy= 0.000\n",
      "Step 8, Minibatch Loss= 11334.8320, Train Accuracy= 0.000\n",
      "Step 9, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 1360714.5000, Train Accuracy= 0.625\n",
      "Step 2, Minibatch Loss= 823414.5000, Train Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 515448.0000, Train Accuracy= 0.500\n",
      "Step 4, Minibatch Loss= 281534.0000, Train Accuracy= 0.500\n",
      "Step 5, Minibatch Loss= 892067.6250, Train Accuracy= 0.375\n",
      "Step 6, Minibatch Loss= 578203.8125, Train Accuracy= 0.625\n",
      "Step 7, Minibatch Loss= 706567.3750, Train Accuracy= 0.500\n",
      "Step 8, Minibatch Loss= 614517.5000, Train Accuracy= 0.625\n",
      "Step 9, Minibatch Loss= 721947.2500, Train Accuracy= 0.250\n",
      "Step 10, Minibatch Loss= 350148.1875, Train Accuracy= 0.625\n",
      "Step 11, Minibatch Loss= 158051.0938, Train Accuracy= 0.750\n",
      "Step 12, Minibatch Loss= 345039.4375, Train Accuracy= 0.250\n",
      "Step 13, Minibatch Loss= 81994.7812, Train Accuracy= 0.375\n",
      "Step 14, Minibatch Loss= 232453.6250, Train Accuracy= 0.750\n",
      "Step 15, Minibatch Loss= 289840.0000, Train Accuracy= 0.500\n",
      "Step 16, Minibatch Loss= 147507.1562, Train Accuracy= 0.875\n",
      "Step 17, Minibatch Loss= 93265.3438, Train Accuracy= 0.750\n",
      "Step 18, Minibatch Loss= 181113.5000, Train Accuracy= 0.625\n",
      "Step 19, Minibatch Loss= 137841.7812, Train Accuracy= 0.375\n",
      "Step 20, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.875\n",
      "Step 1, Minibatch Loss= 1960.9492, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 1246.9478, Train Accuracy= 0.000\n",
      "Step 3, Minibatch Loss= 4020.6860, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 2936.1108, Train Accuracy= 0.000\n",
      "Step 5, Minibatch Loss= 33.2072, Train Accuracy= 0.875\n",
      "Step 6, Minibatch Loss= 1188.4899, Train Accuracy= 0.000\n",
      "Step 7, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 138743.8281, Train Accuracy= 0.250\n",
      "Step 2, Minibatch Loss= 323656.0000, Train Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 223979.5469, Train Accuracy= 0.750\n",
      "Step 4, Minibatch Loss= 514992.1562, Train Accuracy= 0.375\n",
      "Step 5, Minibatch Loss= 212800.0938, Train Accuracy= 0.625\n",
      "Step 6, Minibatch Loss= 184958.5938, Train Accuracy= 0.750\n",
      "Step 7, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Testing Accuracy: 0.75\n",
      "Step 1, Minibatch Loss= 21056.8867, Train Accuracy= 0.000\n",
      "Step 2, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 3, Minibatch Loss= 19607.7266, Train Accuracy= 0.000\n",
      "Step 4, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 11555.6113, Train Accuracy= 0.000\n",
      "Step 6, Minibatch Loss= 0.0000, Train Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 671199.3750, Train Accuracy= 0.625\n",
      "Step 2, Minibatch Loss= 66765.8750, Train Accuracy= 0.875\n",
      "Step 3, Minibatch Loss= 478146.0625, Train Accuracy= 0.375\n",
      "Step 4, Minibatch Loss= 485281.7500, Train Accuracy= 0.375\n",
      "Step 5, Minibatch Loss= 122838.1250, Train Accuracy= 0.500\n",
      "Step 6, Minibatch Loss= 391680.0938, Train Accuracy= 0.625\n",
      "Step 7, Minibatch Loss= 557979.0000, Train Accuracy= 0.250\n",
      "Step 8, Minibatch Loss= 272197.3750, Train Accuracy= 0.750\n",
      "Step 9, Minibatch Loss= 1133814.2500, Train Accuracy= 0.375\n",
      "Step 10, Minibatch Loss= 427606.3125, Train Accuracy= 0.625\n",
      "Step 11, Minibatch Loss= 490836.3750, Train Accuracy= 0.625\n",
      "Step 12, Minibatch Loss= 272937.7500, Train Accuracy= 0.500\n",
      "Step 13, Minibatch Loss= 129821.5000, Train Accuracy= 0.875\n",
      "Step 14, Minibatch Loss= 459778.1875, Train Accuracy= 0.625\n",
      "Step 15, Minibatch Loss= 591729.2500, Train Accuracy= 0.500\n",
      "Step 16, Minibatch Loss= 800932.1250, Train Accuracy= 0.500\n",
      "Step 17, Minibatch Loss= 1134348.1250, Train Accuracy= 0.500\n",
      "Step 18, Minibatch Loss= 801882.8750, Train Accuracy= 0.500\n",
      "Step 19, Minibatch Loss= 557827.1250, Train Accuracy= 0.625\n",
      "Step 20, Minibatch Loss= 209069.1250, Train Accuracy= 0.750\n",
      "Step 21, Minibatch Loss= 104122.0469, Train Accuracy= 0.875\n",
      "Step 22, Minibatch Loss= 162827.3750, Train Accuracy= 0.625\n",
      "Step 23, Minibatch Loss= 45940.1875, Train Accuracy= 0.875\n",
      "Step 24, Minibatch Loss= 108211.5312, Train Accuracy= 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25, Minibatch Loss= 106430.7188, Train Accuracy= 0.875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4f787d3e3d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mfcon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_fcon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0manswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ans.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_fcon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/experiment/Untitled Folder/fcon.py\u001b[0m in \u001b[0;36mtrain_fcon\u001b[0;34m(pic, weight1, weight2, ans, n, a, bs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgentest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic3_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/experiment/Untitled Folder/pic_n.py\u001b[0m in \u001b[0;36mpic3_2\u001b[0;34m(pic, weight1, weight2, a)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/experiment/Untitled Folder/prepare.py\u001b[0m in \u001b[0;36mprep\u001b[0;34m(pic, weight1, weight2, a)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Max Pooling (down-sampling)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mI1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxpool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mI1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mI1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5577\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5578\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5579\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1341\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "A=np.zeros((8,2,50))\n",
    "B=np.zeros((8,2,50))\n",
    "N=np.zeros(50)\n",
    "for i in range (0,50):\n",
    "    n=0\n",
    "    from con1 import train_cov\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    data=np.load('data.npy')\n",
    "    #from loadone1 import load_sample as load\n",
    "    w1=np.zeros((5,5,1,3))\n",
    "    w2=np.zeros((5,5,3,6))\n",
    "    m=np.array([0,1,2])\n",
    "    #M12,a12=load(data[:,:,m,12])\n",
    "    w1[:,:,:,:],w2[:,:,:,:],Num=train_cov(data[:,:,m,n],300,3,8)\n",
    "    if Num==1:\n",
    "        from fcon import train_fcon\n",
    "        answer=np.load('ans.npy')\n",
    "        A[:,:,i],B[:,:,i],N[i]=train_fcon(data[:,:,:,n].reshape(28,28,16),w1[:,:,:,:].reshape(5,5,1,3,1),w2[:,:,:,:].reshape(5,5,3,6,1),answer[n],50,3,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:,:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('A_0.npy',A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
